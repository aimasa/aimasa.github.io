<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[TensorFlow实现cnn踩坑点]]></title>
    <url>%2F2019%2F12%2F25%2FTensorFlow%E5%AE%9E%E7%8E%B0cnn%E8%B8%A9%E5%9D%91%E7%82%B9%2F</url>
    <content type="text"><![CDATA[因为是新手，所以跟着网上的教程用tensorflow框架实现了CNN模型，并且开始了训练。在实现过程中经历了很多的坑，今天记录一下在实现过程中遇到过的坑。 教程博客 数据预处理我一直觉得数据处理只是简单的对数据进行数据加载，然后清洗（去掉停用词、标点符号、转义字符—比如\n以及空格等冗余数据） 其实，要做的处理并不止这些。 标签处理在预处理中需要把不同文本对应的标签转换为one-hot类型： 12345678def dense_to_one_hot(self, labels_dense, num_classes): """Convert class labels from scalars to one-hot vectors.""" num_labels = labels_dense.shape[0] index_offset = np.arange(num_labels) * num_classes labels_one_hot = np.zeros((num_labels, num_classes)) temp = index_offset + labels_dense.ravel() labels_one_hot.flat[temp] = 1 return labels_one_hot 在后面隐藏层输出结果与对应正确标签计算时候是需要的。 因为后面： 1234567with tf.name_scope("output"): W = tf.Variable(tf.truncated_normal([self.num_filters_total, self.num_classes]), name="W") b = tf.Variable(tf.constant(0.1, shape=[self.num_classes]), name="b") if l2_reg_lambda: W_l2_loss = tf.contrib.layers.l2_regularizer(l2_reg_lambda)(W) tf.add_to_collection("losses", W_l2_loss) self.scores = tf.nn.xw_plus_b(self.h_drop, W, b, name="scores") # (self.h_drop * W + b) self.predictions = tf.argmax(self.scores, 1, name="predictions") # 找出分数中的最大值，就是预测值 全连接输出时候，里面会通过tf.nn.xw_plus_b()计算得到的不同种类对应得到的score和以one-hot表示的标签下标值进行softmax计算误差，也就是loss值。 12losses = tf.nn.softmax_cross_entropy_with_logits_v2(self.input_y, self.scores)# softmax_cross_entropy_with_logits_v2第一个是对应标签的labels值，第二个logits值是预测分数，会自动转为对应的标签值进行计算 文本处理文本处理除掉上面说过的去停用词去标点符号去转义字符等，还需要把文本处理成机器可读取的模式，就是把文本变成数字。 我刚开始对这个的理解就是把文本转换为对应的词向量，再喂进模型，结果发现，并不是这样。 如果直接把词向量做词嵌入处理，这样会导致工程浩大（因为会有很多重复的词出现在文档里，在喂进模型前要把对应的词向量矩阵捣鼓出来，这样的话，就会消耗计算机大量的内存，降低速率。）所以我们会先把清洗后的文本转换成对应的文本下标的ID 12vocab_processor =learn.preprocessing.VocabularyProcessor(normal_param.max_document_length)x = np.array(list(vocab_processor.fit_transform(x_texts))) 【注：x_texts是已经经过清洗的数据，x就是x_texts对应的下标矩阵】 然后传入cnn模型中word embeding部分，找到对应的词向量，进行后续操作。 123456with tf.device('/cpu:0'), tf.name_scope("embedding"): self.W = tf.Variable(tf.random_uniform([self.vocab_size, self.embedding_size], -1.0, 1.0)) # 随机化W，得到维度是self.vocab_size个self.embedding_size大小的矩阵，随机值在-1.0-1.0之间 self.embedding_chars = tf.nn.embedding_lookup(self.W, self.input_x) # 从id(索引)找到对应的One-hot encoding self.embedding_chars_expanded = tf.expand_dims(self.embedding_chars, -1) # 增加维度 W相当于词袋模型，每个词都是个独立的个体，所以通过tf.variable设置随机变量，然后再根据前面处理好的下标过来找到不同的词对应的embeding。 因为是词袋模型，所以不好的地方在于，会丢失上下文的关系，造成准确度偏低的情况。 所以会有词预处理模型，比如Word2vec、最近特别热门的Bert这些模型，都会想办法获取词的上下文关系，得到对应的词向量，增加预测结果的准确性。 模型搭建在搭建CNN模型的过程中也碰到过一些问题，因为是新手，看着论文，也不知道如何下手去搭建这个模型，所以跟着教程才写了出来，在讨论碰到的问题之前，先总结一下经验。 先不提python语法问题，python是个很好的东西，对新手来说，有很多库，上手很快，是个很优美的语言。特别是在你了解到它的面向对象的特性的时候，它的优美实现会让你瞬间爱上它，反正我还没学会python。它是面向对象，我是面向百度谷歌。 接下来要说的是tensorflow框架了，TensorFlow框架是个坑，它升级到2.0版本，和1.0版本有很多不兼容的地方，但因为是新出的2.0，普及性还不是很广，出了问题翻遍它官方的issue都不一定能找到答案，所以我配合我的cuda版本装了TensorFlow1.13.1。其实这个因果关系不是特别紧密，我只是想吐槽它升级版本顺便改了改语法，让我初学者翻了一下午的资料，才发现为啥教程上是这样写没问题，我这样写就有问题了。 回到正文。 在用代码搭建CNN模型中，作者用了tf.name_scope(&quot;&quot;)把这个实现分成了词嵌入、卷积-池化、dropout、输出、loss值计算、准确值计算这六个部分 tf.name_scope(&quot;&quot;)：它给我感觉就是把复杂的网络分开来，变成几个小的模块，不会因为网络复杂了，而数据混乱没有条理，导致出错。实际上和我想的差不多吧。 loss绝对值增大当时loss值的绝对值越来越大，并没有收敛的趋势，我找了很久的问题，在学长的帮助下才发现出在这里： 1losses = tf.nn.softmax_cross_entropy_with_logits_v2(self.input_y, self.scores) 这是第一个坑， softmax_cross_entropy_with_logits_v2第一个是对应标签的labels值，第二个logits值是预测分数，会自动转为对应的标签值进行计算出相应的loss值。 讲到这里，不得不提及一下softmax是什么了，参考博客博客里面给出了相关公式，是将每个类别给出的分数通过softmax进行计算，把分值均转换为正数，通过$S{i} = \frac{e^{i}}{\sum{j}e^{j}}$这个公式，把分值最高的值凸显出来，同时将输出结果映射到(0,1)之间，转换成概率。 按照论文里面的情况来讲，全连接后进行反向传播的详细步骤是： 通过激活函数得到预测值 将预测值和期望值放在一起求出误差值 反向传播时候，将误差值代入公式求偏导运算，调整参数。 而 $\triangledown w$ 除了有判断梯度应该下降上升的作用以外，还有个作用就是为参数调整幅度做参考（对，可以这样说），因为如果预测值与实际值的误差越大，那么在反向传播训练的过程中，各种参数调整的幅度就要更大，从而使训练更快收敛。来自博客 通过softmax计算出的值，而，loss值是由损失函数算出来的，这里使用交叉熵函数作为我们的损失函数。 对tf运行的理解12self.input_x = tf.placeholder(tf.int32, [None, sequence_length], name="input_x")self.input_y = tf.placeholder(tf.float32, [None, num_classes], name="input_y") tf和平常代码不一样，日常代码都是先赋值，再进行运算，而tf是先定义运算，再进行初始化赋值，就像上面这两行代码一样，这两行代码是预定义了input_x和input_y的值，然后再在后面 1step, summaries, loss, accuracy = sess.run([global_step, dev_summary_op, cnn_init.loss, cnn_init.accuracy], feed_dic) 把定义好feed_dic的值，喂进初始化后的cnn模型中，再返回[global_step, dev_summary_op, cnn_init.loss, cnn_init.accuracy]里面的值（cnn_init就是初始化后的CNN模型） global_step, dev_summary_op和后面的值不一样，不是从模型里面输出的值， 模型存取在程序的运行中，会因为各种问题导致程序突然中止，所以我想要运行到一定时间就自动保存一个正在学习的数据模型，再次运行时候，如果已经有保存了的模型，就加载出来。 12345678checkpoint_dir = os.path.abspath(os.path.join(out_dir, "checkpoint"))checkpoint_prefix = os.path.join(checkpoint_dir, "model")if not os.path.exists(checkpoint_dir): os.makedirs(checkpoint_dir)saver = tf.train.Saver(tf.global_variables())ckpt = tf.train.latest_checkpoint(checkpoint_dir)if ckpt: saver.restore(sess, ckpt) print("CNN restore from the checkpoint &#123;0&#125;".format(ckpt)) 继续训练后，运行了好几遍，发现并没有办法加载已有模型继续训练，究其原因，发现，问题出在session初始化上面。tf.Session.run中间的初始化参数不是和我想的那样随便加的TT。 12sess.run(tf.global_variables_initializer())sess.run(tf.local_variables_initializer()) 参考博文 一个是初始化全局变量，但模型中的局部变量并没有初始化，所以，就再加上sess.run(tf.local_variables_initializer())初始化局部变量。 电脑性能限制因为实验室不是专门做深度学习这块，所以没有较好的设备去完成实验，目前实验设备有： CPU Intel(R) Core(TM) i7-7700 CPU @ 3.60GHz 基准速度: 3.60 GHz 插槽: 1 内核: 4 逻辑处理器: 8 GPU 1块 NVIDIA GeForce RTX 2060 SUPER 专用 GPU 内存 8.0 GB 共享 GPU 内存 8.0 GB GPU 内存 16.0 GB 内存 16.0 GB 磁盘 1 (D: F: G: E:) WDC WD10EZEX-21M2NA0 容量: 932 GB 已格式化: 932 GB 系统磁盘: 否 页面文件: 是 读取速度 199 KB/秒 写入速度 41.0 KB/秒 活动时间 56% 平均响应时间 6.2 毫秒 目前硬件上面临的有几个困难： GPU利用率过低，不知道如何优化 读取文档的速度过慢，优化方法下面介绍 其实总结一下就是，硬件设备性能低，没法加快程序运行速度。 优化运行方案因为内存的不足，所以在学长的建议下，我把我需要输入的数据进行分段处理，这样一来能快速看到效果，二来被打断的话，不需要重新加载那么庞大的数据继续跑，三来我电脑性能限制，我没法一次性跑那么多数据。其实第三点才是最重要的。 这就要来说说python中yield的语法了。 yield相当于return，不同的是，它不会结束程序的运行，而是让程序在经过yield的处理后，回到开始的循环，继续向下执行。可能这样干说不太能很好的表达，所以我写一段。 12345678910def batch_iter(a, b, num_foreach): for i in range(num_foreach): c = a + b yield cif __name__ == "__main__": batch = batch_iter(1,2，3) for b in batch: t = b print(t) 输出： 123333 就是迭代器，里面batch_iter这个方法就是迭代时候会使用的方法，然后迭代完c就是输出的值。 根据这个语法的特性，我改进了一下代码： 12345678batches = process_data_init.batch_iter(normal_param.batch_size, normal_param.num_epochs)for batch, dev_data, dev_label, is_save in batches: x_batch, y_batch = zip(*batch) # print("y_batch", y_batch) train_step(x_batch, y_batch, train_summary_write) current_step = tf.train.global_step(sess, global_step) if current_step % normal_param.evaluate_every == 0: print("\nEvaluation:") dev_step(dev_data, dev_label, writer=dev_summary_writer) 把数据集的读取改到迭代时候读取。 123456789101112131415161718192021222324def batch_iter(self, batch_size, num_epochs, shuffle=True): '''迭代器''' # num = 1 # data = np.array(data) # data_size = len(data) # num_batches_per_epoch = int((data_size - 1) / batch_size) + 1 echo_part_num = len(self.all_text_path) // normal_param.num_database for epoch in range(num_epochs): print("epoch:", epoch, "/", num_epochs) for part_n in range(normal_param.num_database): is_save = False train_data, train_label, dev_data, dev_label, vocal_size_train = self.deal_data(part=echo_part_num,n_part=part_n) data = list(zip(train_data, train_label)) data = np.array(data) data_size = len(data) num_batches_per_epoch = int((data_size - 1) / batch_size) + 1 if shuffle: shuffle_indices = np.random.permutation(np.arange(data_size)) shuffle_data = data[shuffle_indices] else: shuffle_data = data for batch_num in range(num_batches_per_epoch): start_idx = batch_num * batch_size end_idx = min((batch_num + 1) * batch_size, data_size) if batch_num + 1 == num_batches_per_epoch: is_save = True yield shuffle_data[start_idx:end_idx], dev_data，dev_label,is_save 调参根据数据集大小以及过拟合情况，适当调整了batch_size的大小和学习率的大小、dropout的大小以及迭代的次数： 12345batch_size = 64num_epochs = 50dropout_keep_prob = 0.5#学习率设置：1e-3optimizer = tf.train.AdamOptimizer(1e-3) 结果数据集我用的是THUCNew1,里面有14个class，将前三个class抽取出来，并且每个类别中的数据以10:1的比例抽取，所以实验数据集有6,472个文件数据，实验中使用TensorBoard可视化数据，结果如下： 神经网络流程图可视化 验证集的loss曲线图： 验证集的acc的曲线： 训练集的acc曲线： 训练集的loss曲线：]]></content>
      <categories>
        <category>nlp自然语言处理</category>
        <category>CNN语言模型</category>
      </categories>
      <tags>
        <tag>nlp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[手写字体识别走过的坑]]></title>
    <url>%2F2019%2F12%2F04%2F%E6%89%8B%E5%86%99%E5%AD%97%E4%BD%93%E8%AF%86%E5%88%AB%E8%B5%B0%E8%BF%87%E7%9A%84%E5%9D%91%2F</url>
    <content type="text"><![CDATA[运行的代码是：哈工大大佬毕设代码 因为数据集他们没放出来，所以我选用的是中科院的手写数据集，特别有名的那个HWDB：数据集trn，数据集tst 其实这里也算是记录用TensorFlow实现图片处理经过的坑。名字而已，无需计较 开门第一坑：缺少验证集自己写了个脚本，以3:1的比例从trn中抽取出验证集。【这些数据是要处理一下转换为图片的，网上很多教程，去搜就行了】因为很简单，所以不多说，进入第二坑 开门第二坑：tf.data.TFRecordDataset()的使用1tf.data.TFRecordDataset(filename) 我傻了吧唧的以为，这个可以直接把地址列表输入进去，它会自动按地址去读取那些对应的图片，事实证明我错的离谱……这个只会读取存有TFRecord文件地址的列表……所以才会报错：record被损坏…… 这个TFRecordDataset里面的filename只能是TFRecord类型文件的地址==。 所以现在先进行数据预处理。 TFRecord是一种将图像数据和标签放在一起的二进制文件，适合以串行的方式读取大批量数据，虽然它的内部格式复杂，但是它可以很好地利用内存，方便地复制和移动，更符合TensorFlow执行引擎的方式。该句来源 代码参考博客 关于代码中的tf.python_io.TFRecordWriter(path, options=None)，括号中间的path是填写转换好的内容的存储地址的,option是用来定义TFRecord文件保存的压缩格式的，是TFRecordOptions对象。[注意哦，TensorFlow的v2.0版本和v2.0以下版本的语法不同哟~反正我觉得TensorFlowv2.0的bug有点多，不敢用。而且我看了一下别人提交的push，好多是修改语法的……emmm还是等它稳定点，再试着用用吧。] 将普通图片数据转换成TFRecord格式数据需要注意的一点就是：读取TFRecord文件的时候，读取字典的key是要根据转换成TFRecord格式时候的字典的key对应上的。 【==我对tfrecord的理解有问题，需要修改== 好，接着进入第三坑。【暂缓 对TensorFlow不了解的坑1y = tf.nn.dropout(x, dropout) 其中 x是输入的，需要dropout进行概率屏蔽的矩阵 dropout是概率，需要屏蔽哪些]]></content>
      <categories>
        <category>图像处理</category>
        <category>手写识别</category>
      </categories>
      <tags>
        <tag>图像处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CNN论文笔记]]></title>
    <url>%2F2019%2F11%2F20%2FCNN%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[阅读CNN for sentence classification的笔记，记录一下。 对词向量的解释： Word vectors, wherein words are projected from a sparse, 1-of-V encoding (here V is the vocabulary size) onto a lower dimensional vector space via a hidden layer, are essentially feature extractors that encode semantic features of words in their dimensions. 本质是特征提取器，对词在其维度上的语义特征进行编码。 介绍CNN应用领域挺广的，比如计算机视觉方面，音频识别方面，还有在自然语言处理方面。这里主要讲的是CNN在自然语言处理里面的运用以及一些知识点。 模型架构在这篇论文里是一个简单的CNN模型，它只是一个简单的四层模型架构，分别有输入层、卷积层、池化层、全连接层。如下图所示： 【图截取自该论文，我就不自己画了】 输入层这一层是将词语向量化，我的理解是把词语转换成0或1表示，现在用的比较多的词向量化工具是word2Vec。论文中用word2Vec对输入数据进行了两次word embeding，形成了两个通道（channel），一个进行卷积，一个通过反向传播进行微调一些参数（我目前理解的是调整权重和偏重，就是论文中的$f(w*x_{i:i+h-j} + b)$中的$w$和$b$，其中$w$是权重，它是随机初始化的，然后再根据loss的值进行反向传播微调，适应训练的参数类型，从而达到理想的分类效果，偏重就是$b$，以调整差值。根据反向传播的不断调整，再对结果进行筛选，得到最优的$w$和$b$值。 卷积层这一层是用来提取输入参数的特征的，通过卷积，去提取特征。根据filter的高度，选择多少个词连接在一起与对应的filter进行卷积运算。 在卷积层中，filter对词向量做滑动取词计算，如果filter的高度$h$为$n$的话，那么和filter运算的分别是： 第一次运算：$x_{1:n}=x{1}\oplus x\{2}…\oplus x_{n}$ 第二次运算：$x_{2:n}=x_{2}\oplus x_{2}…\oplus x_{n+1}$ …… 第x次运算：$x_{x:n}=x_{x}\oplus x_{x+1}…\oplus x_{n+x-1}$ 注：如果$n+x-1 &lt; len(输入参数)$，则继续运算，如果$n+x-1 = len(输入参数)$则结束运算，如果$n+x-1 &gt; len(输入参数)$，那么会对其做padding处理，padding有两种处理方式，一种是VALID(不足舍弃)，另一种是SAME(不足补零) 【小声逼逼：一点都不想画图，因为感觉好麻烦哦，所以用公式表示啦 其中，$x{i}$是指第$i$个词（word），其中 $x{1:n}=x{1}\oplus x{2}…\oplus x{n}$是$x{1}$到$x_{n}$的词向量的连接（普通的连接哦）。 卷积运算的话就是用对应的权重和对应的拼接词汇向量相乘，再加上$b$偏移量，以此为参数放入选择好的激活函数中运算，从而得到对应的特征。就是：$f(w*x_{i:i+h-1}+b)$ 很多博客都没有说过卷积运算是干么的，这里我对比着图像处理中的卷积运算讲讲咯。 图像处理中，用CNN进行分类计算，分类嘛，比如鸟类和鸟类的图片，只要图片上出现了鸟类，那就意味着这张图片我们可以把它归类为鸟类图片，但是，图片上出现鸟类的位置总不会一成不变，所以我们就要根据鸟类的特征去寻找图片上的鸟类，所以我们通过filter去一堆格子一堆格子的去搜寻，去比对，去寻找图片上可能出现的鸟类的局部特征，再通过分配不同的权重给搜寻结果，最后设置阈值，计算概率，以此判断这张图片是不是鸟类的图片。 语言处理也是一样的，它通过filter不同的高度，去寻找可能出现的词汇结构，再分配不同的权重，以此得到这个文本是不是这个类别的文本。【上下文相似的词其语义也相似———这是出自一篇经典论文】 池化层这一层是用来挑选出各种filter的最明显的特征，一般都是用max_feature来挑选，是吧是吧，简单粗暴。然后如果还想继续加层的话，就可以在池化层后，接上卷积层，再接上池化层，以此循环迭代。 全连接层这一层可以看成分类器，它的公式是：$y=w*z+b$，其中$z$当然是所有filter中的所有的最大特征值咯。最后这个$y$就被代入到激活函数里头$a = f(y)$。得出的值就是对应的属于不同类别的概率值，这些概率值就是全连接层的输出结果。 在计算出了概率值之后，根据预期结果（$\hat{y}$）和实际结果$a$计算出loss值（一般都是用$E = \frac{1}{2}\sum_{i}^{n}(\hat{y}-a)^{2}$这个公式计算出偏移值）这样就可以通过反向传播，去调整权重值和偏差值。 反向传参还记得上面论文中说过，CNN在句子分类中，使用的是两个chennal，一个是静态chennal，一个是动态chennal，动态的 chennal是用来从全连接层反向传播调整参数的，静态的chennal是用来向传参，计算分类概率的。 反向传参的方法就是求导，从全连接层往输入层去反向推导调整权重值和偏差值，之前一直没能理解为什么反向求导时候怎么调整权重值，现在在这里把我目前的理解，讲一遍，然后如果理解错了，大家能够指正一下： $w_{后} = w_{初} - \triangledown w$ $\triangledown w = \eta \ast \frac{\partial E}{\partial a}\ast \frac{\partial a}{\partial y}\ast \frac{\partial y}{\partial w}$ 【这里只是意思意思的写那么几个公式，就是求偏导数。 当 $\triangledown w$ 为0的时候，就意味着$w$的值已经被调整到预期（最佳）值了，就不会继续调整下去了，而为什么调整$w_{后}$要用 $w{前}$ 去减去偏导值呢？因为偏导后，得到当下的斜率值，如果是正数，说明$w\{后}$的值需要减掉 $\triangledown w $ 值得到，如果是负数，就说明$w_{后}$的值需要加上 $\triangledown w $ 值得到。除了有这个原因，如果预测值与实际值的误差越大，那么在反向传播训练的过程中，各种参数调整的幅度就要更大，从而使训练更快收敛。来自博客 而里面的$\eta$是代表学习率，这个是自己设置的，是用来控制梯度下降的步长（这里可以看看吴恩达老师视频的梯度下降的这块），学习率太大，步长太长，就会很容易跳过让$w$能够等于最佳值的点，学习率太小，步长太小，就会下降速度太慢emmm，可以联想一下，数据不够，下降太慢==】 讲到这里，不得不提及一下softmax是什么了，参考博客博客里面给出了相关公式，是将每个类别给出的分数通过softmax进行计算，把分值均转换为正数，通过$S{i} = \frac{e^{i}}{\sum{j}e^{j}}$这个公式，把分值最高的值凸显出来，同时将输出结果映射到(0,1)之间，转换成概率。 按照论文里面的情况来讲，全连接后进行反向传播的详细步骤是： 通过激活函数得到预测值 将预测值和期望值放在一起求出误差值 反向传播时候，将误差值代入公式求偏导运算，调整参数。 而 $\triangledown w$ 除了有判断梯度应该下降上升的作用以外，还有个作用就是为参数调整幅度做参考（对，可以这样说），因为 激活函数分别有relu、tanh、sigmoi，这三种函数，一般，tanh、sigmoi会被用在全连接层，relu被用在卷积层。 激活函数的作用是把卷积后的结果压缩到某一个固定的范围，这样可以一直保持一层一层下去的数值范围是可控的。———-摘自博客 实验参数$l_{2}$范式 = 3 filter window 的h分别有：3、4、5 每个高有100个feather map batch= 50 总结这就是一篇实验报告，CNN通过不同长度的filter去搜索句子中的特征，这样的话就避免了特征遗漏的现象，然后明显化重要特征，再通过全连接层分类。这样的话有个缺点就是无法联系上下文去判断词语在文中的意义，就是无法语义理解。因为中文一词多义，所以这样分类肯定会有误差的。所以nlp比图像处理难太多了。 啊，自己跟着网上的教程手动撸了CNN代码，对训练过程以及喂数据过程有了个大体的了解，因为电脑的性能问题，我不得已把数据集分批读取再丢进模型里面处理，不知道是不是这个原因，导致loss值为负值，而且准确度奇低，目前还在探索，等有了结果会再写一篇心得，标志着CNN的学习告一段落。 参考资料反向传播 CNN for sentence classification]]></content>
      <categories>
        <category>nlp自然语言处理</category>
        <category>CNN语言模型</category>
      </categories>
      <tags>
        <tag>nlp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[统计学习（一）之监督学习]]></title>
    <url>%2F2019%2F11%2F20%2F%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"></content>
      <categories>
        <category>统计学习</category>
        <category>监督学习</category>
      </categories>
      <tags>
        <tag>统计学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[k个一组翻转链表]]></title>
    <url>%2F2019%2F10%2F16%2Fk%E4%B8%AA%E4%B8%80%E7%BB%84%E7%BF%BB%E8%BD%AC%E9%93%BE%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[题目给你一个链表，每 k 个节点一组进行翻转，请你返回翻转后的链表。 k 是一个正整数，它的值小于或等于链表的长度。 如果节点总数不是 k 的整数倍，那么请将最后剩余的节点保持原有顺序。 示例 : 给定这个链表：1-&gt;2-&gt;3-&gt;4-&gt;5 当 k = 2 时，应当返回: 2-&gt;1-&gt;4-&gt;3-&gt;5 当 k = 3 时，应当返回: 3-&gt;2-&gt;1-&gt;4-&gt;5 说明 : 你的算法只能使用常数的额外空间。你不能只是单纯的改变节点内部的值，而是需要实际的进行节点交换。 心得写这道题目可以用递归，但对递归不太了解，所以明天打算写一下递归的专题，暂时不在这道题上耗时间了，等递归用的顺手的时候再回来写它。 学到的点：1、计算时间复杂度，虽然我在一个大循环里面包了两个不同的小循环，但是时间复杂度加在一起，一共是$f(3l-\frac{l}{k})$,并不是我想的会复杂度很高。 2、要理清楚ListNode的存储结构，不然容易出现指向地址的值产生循环的情况。 思路注：里面pre和corr默认使用0-&gt;xxxxxx如此，虽然画的是直接指向需要转换的链表的头指针，但是他们默认是.next指向。 我没太看仔细看网上的思路，跟着自己的想法写了这个，用语言不知道要怎么表达，干脆放图好了： 在上图中，先考虑只改变ListNode链表首的翻转变动。$k = 1$的时候链表不做改动，$k = 2$的时候两两交换，$k = 3$的时候就把$k=2$时候翻转好的链表作为一个整体，再和指向的第三个链表做一次两两交换，$k=4$就可以把$k=3$的已经转换好的链表看做一个整体，再与指向的第四个链表做一次两两交换，以此类推。 这样就可以发现可以根据$k$数量的做一次循环了，这个循环的复杂度只有$f(k)$，需要的指针如下所示： 指针end永远都是跟在second的后面，指向链表尾部，second指向end的前一个的原因就是上面说的将前一部分看做一个整体，和后面指向的数字进行两两交换，first-&gt;second就是那个整体，end是那个后面指向的数字。所以first永远都是指在要交换的链表头（就是比如图上1-&gt;2-&gt;3-&gt;4时候，$k=3$，第一次要对1-&gt;2-&gt;3交换，那first指向链表中存储1的位置，当前面三个交换完之后，对下一组进行交换，那么first就应该指向4，因为它是下一组的链表之首。） pre.next这个指针我用来存储头节点，到最后可以通过输出它，而输出已经被翻转好的链表。 但是，因为end指针会一直和first指针进行交换，所以pre.next指针指向的地址只会一直跟着first，而无法将转换好的链表完整输出： 所以我加了一个corr指针去跟踪这个翻转后的完整的链表，让corr指向翻转好的链表地址。 这样，就得到正确的结果了。 为了知道有多少段链表需要我去进行翻转，而不用临时判空等操作浪费时间，所以在用循环知道了链表会有多长之后，整除$k$，知道了有多少段链表需要翻转，然后再整合上面的思路。 优化emm我觉得递归的话可能效率更高？因为时间都浪费在让occr这个指针去跟踪更新的链表了。 题目来源leedcode 参考代码参考代码]]></content>
      <categories>
        <category>算法</category>
        <category>k个一组翻转链表</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>leedcode算法题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[爬虫心得]]></title>
    <url>%2F2019%2F10%2F15%2F%E7%88%AC%E8%99%AB%E5%BF%83%E5%BE%97%2F</url>
    <content type="text"><![CDATA[因为毕业设计的缘故，网上没有现成的数据库，所以要自己想办法去爬取数据。所以 毕业设计step1: 书写爬虫爬取文本 之前试着写了一个爬漫画的爬虫练手（书写思路另会写一条博客详细说明），那时候是对页面漫画的内容进行爬取，但是这次写的爬虫是对页面html的信息进行爬取。 拟使用的库是requests_html和PyQuery，但是PyQuery这个单独的库好像就能满足我的需求。 其中 1from pyquery import PyQuery as pq 从PyQuery导入pyquery的方法模块。 1pq(link) 这句话的意思是获取这个link对应的页面的html文件。但是我这样写的时候却出现了乱码。 要根据网站的编码方式再去进行解码，所以我直接去获取这个网址对应的html信息是会返回乱码的。所以要把这句话改成： 1pq(link,encoding="") 现在我们就需要知道网站编码格式是什么了，我们打开link对应的那个网站页面，点击f12看它的页面元素（位置一般在&lt;head&gt;这个标签里面）： 由此可知，encoding=&quot;gb2312&quot;]]></content>
      <categories>
        <category>爬虫</category>
        <category>爬取html信息</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[两两交换链表中的节点]]></title>
    <url>%2F2019%2F10%2F14%2F%E4%B8%A4%E4%B8%A4%E4%BA%A4%E6%8D%A2%E9%93%BE%E8%A1%A8%E4%B8%AD%E7%9A%84%E8%8A%82%E7%82%B9%2F</url>
    <content type="text"><![CDATA[题目给定一个链表，两两交换其中相邻的节点，并返回交换后的链表。 你不能只是单纯的改变节点内部的值，而是需要实际的进行节点交换。 示例: 给定 1-&gt;2-&gt;3-&gt;4, 你应该返回 2-&gt;1-&gt;4-&gt;3. 这题的话用之前的思路也是行得通的，就是两两交换的思路可以通过while进行循环，然后两两节点换位置，类似于普通参数换位置，因为它可以分解成一个个重复的小问题，所以这题还能用递归去解决。 因为我递归总是不太熟，所以在这里特地写了个笔记。 分析把这个题目的大问题划分成一个个重复的子问题（对链表头进行节点互换），然后再限定条件，找到出口点（节点不能为空，节点的.next不能为空） 然后根据这个思路把代码表示出来。 在leedcode网站中，标准题解中对递归解释是这样的：递归写法要观察本级递归的解决过程，形成抽象模型，因为递归本质就是不断重复相同的事情。而不是去思考完整的调用栈，一级又一级，无从下手。如图所示，我们应该关注一级调用小单元的情况，也就是单个f(x)。 参考网站力扣 参考代码代码]]></content>
      <categories>
        <category>算法</category>
        <category>两两交换链表中的节点</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>leedcode算法题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Http协议]]></title>
    <url>%2F2019%2F09%2F25%2FHttp%E5%8D%8F%E8%AE%AE%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Lezhin爬虫使用]]></title>
    <url>%2F2019%2F09%2F08%2Flezhincomic%2F</url>
    <content type="text"><![CDATA[Lezhin爬虫使用方法lezhin爬虫配置文件介绍 配置文件模板123456789101112131415161718192021222324#需要爬的漫画信息[comic_info]comic_chinese_name = 我的哥哥我的老师comic_name = mybromyssamseries_id_first = 25series_id_last = 25; ---------------------------------; 需要存放的文件路径以及压缩格式[folder_info]zip_type = zipfolder_name_header = H:/; ----------------------------------; 账号登录网站后得到的必要信息[comic_request_info]access_token = comic_id = lezhin_cookie = ;------------------------------------;下载完一话漫画下第二话需要等待时间[spare_time]spare_time = 10 注：配置文件后缀名为 .ini，也可以是.config 小白使用方法 该脚本打包成的exe使用环境为 window10（我觉得window系列的系统都能用它，我没试过，因为我的电脑是window10，所以我这里标注的使用环境仅为window10） 新建配置文件在自己电脑里（文件名格式：xxx.ini 或 xxx.config 。ps：没试过用中文的文件名，你们可以试试。） 运行之后，输入配置文件地址 中断运行的话按ctrl+c 开发者使用方法 下载源码，里面缺失的python包都能通过pip install xxx下载得到。 新建配置文件在自己电脑里（文件名格式：xxx.ini 或 xxx.config 。ps：没试过用中文的文件名，你们可以试试。） 入口地址为main.py。当然run.py里面也有入口，emmm我自己写着调试的，可以不用管它。 运行后会要求输入配置文件地址，按配置文件在自己电脑里存放的位置输入即可。 只能爬取自己已经购买了的漫画，或者网站确定为免费的漫画。 打包后的脚本并未开放。 配置参数详解：comic_name、comic_id点进去之后就能在浏览器的路径上找到对应漫画的comic_name 接着往下拉，按下F12点，进想要下载的漫画的第一话（随便哪话都能找到以下信息） ========================================================================================================= 重点分割线 ====================================================================================================== 点开NetWork这栏 找到红框中的链接内容，点开之后会在旁边弹出一个小框 在这个小框中，划拉到header这栏最下面，会看到Query xxxx，里面alias就是配置文件里对应的comic_name，_的值就是配置文件里的comic_id【ps:comic_id是我命名有问题，我也不知道_是代表什么。】 lezhin_cookie在header这栏中间会看到cookie，这个值是lezhin_cookie access_token按F5刷新，切换按钮到红框指定的位置，根据下图的指示，能够找到配置文件中access_token对应的值。 【因为如果哪天爬不到文件，有一个原因是cookie失效，或者access_token失效，那时候就需要重复一遍获取cookie和access_token的步骤去更新它们】 comic_chinese_name、series_id_first、series_id_last、zip_type、folder_name_header、spare_time这些参数都是自己可以随便定义的。 comic_chinese_name：自己定义的漫画的中文名 series_id_first、series_id_last：想要下载漫画的集数范围。例：如果想要下载该漫画1-15集，那么series_id_first=1，series_id_last=15 ;如果只想下载15集，那么series_id_first = 15，series_id_last=15 zip_type：想压缩成的格式。例：zip_type = zip，文件则被压缩成zip格式 folder_name_header：想要存储的地址前缀。例：想要把我的哥哥我的老师漫画全部存在D:/comic里面，然后folder_name_header = D:/comic，运行此脚本，会在D:/comic里面生成一个我的哥哥我的老师这个总文件夹，里面会有你下载的漫画集数（下载下来的图片是分集装好）。 spare_time：爬完上一话，继续爬下一话时候的间隔时间。因为怕爬取漫画过快，被检测发现是用了脚本在爬，所以加了一个spare_time，可以spare_time=0，但是可能会有被封号的风险哟。spare_time=1，就意思是间隔时间为1s。 eg: alias : myxxxx =&gt; comic_name = myxxxx 接着把自己的配置文件在本地的存放位置在程序开始时填一下，如：配置文件名为：lezhin.config，放在电脑的D:/configfile这个文件夹下面，运行程序，出现配置文件路径：的字样时候，输入D:/配置文件/lezhin.config。好了，回车，开始爬数据了，如果突然闪退，可以看log里面的记录。 总结这个脚本对我来说现阶段最麻烦的就是cookie和access_token这两个参数需要手动获取。emmm看看能不能改进吧。 因为是在闲暇时候摸鱼写出来的脚本，可能会有很多不足，欢迎大家给我提issue。 爬虫代码lezhin爬虫 注：禁止用此爬虫爬下来的漫画进行二次贩卖！！！！！！！！！！请尊重他人版权！！！！！！！！！！！！！！！！此爬虫仅做学习用途！！！！！！！！！！！！！注：禁止用此爬虫爬下来的漫画进行二次贩卖！！！！！！！！！！请尊重他人版权！！！！！！！！！！！！！！！！此爬虫仅做学习用途！！！！！！！！！！！！！]]></content>
      <categories>
        <category>爬虫</category>
        <category>漫画</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python语法记录]]></title>
    <url>%2F2019%2F08%2F21%2Fpython%E8%AF%AD%E6%B3%95%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[这是在学习python时候碰到的一些语法问题，先记下来，方便日后使用 numpy相关记录1power(vector2 - vector1, 2) power是numpy这个类的一个运算函数，是用来计算次方的，上面那行代码意思是计算$(vector2 - vector1)^{2}$,所以power(x,y)是计算$\,x^{y}\,$这个公式的. 1sum(power(vector2 - vector1, 2)) sum也是numpy这个类的一个运算函数，但是在上式中vector是一个二维数组（可以这样说，是n行两列的矩阵中取的第一行），num(x,y)运算是$x + y$，所以里面就是power(vector2 - vector1, 2)计算出来的数组里面的第一行第一列和第二行第二列的数值相加。（等有机会试试sum的括号里放多行两列数组） pandas相关记录read_csv()：默认返回值是DataFrame 而加上了chunksize=xxx这个参数之后返回值就变成了：TextFileReader 在试运行文本处理的程序时候需要进行数据预处理，作者说是先在本机几条数据看看效果，所以我通过加参数chunksize把数据分块成小块这样，注意：并不是单纯的分割出来前多少条数据。 12import pandas as pdtest_data = pd.DataFrame(pd.read_csv('G:/Data using/new_data/new_data/test_set.csv',chunksize= 1000).get_chunk(1)) 这是取分块成功后的第一块（就是前一千条哦）。是从1开始计数的。 G:/Data using/new_data/new_data/test_set.csv这是我存放数据的地址。 ​ 除掉这种pd.DataFrame().get_chunk(1)的办法还有拼接的办法： 12import pandas as pdtest_data = pd.concat(pd.read_csv('G:/Data using/new_data/new_data/test_set.csv',chunksize= 1000), ignore_index=True) requests_htmlcollection相关记录collection.OrderedDict()是按放入元素的先后顺序进行排序。（有序字典） 普通语法cls()：让我感觉像是封装，就是把一些参数经过处理然后封装起来。 unicodedata.normalize() 第一个参数指定字符串标准化的方式。 NFC表示字符应该是整体组成(比如可能的话就使用单一编码)，而NFD表示字符应该分解为多个组合字符表示。 unicodedata.category(chr) 把一个字符返回它在UNICODE里分类的类型。具体类型如下： Code Description [Cc] Other, Control [Cf] Other, Format [Cn] Other, Not Assigned (no characters in the file have this property) [Co] Other, Private Use [Cs] Other, Surrogate [LC] Letter, Cased [Ll] Letter, Lowercase [Lm] Letter, Modifier [Lo] Letter, Other [Lt] Letter, Titlecase [Lu] Letter, Uppercase [Mc] Mark, Spacing Combining [Me] Mark, Enclosing [Mn] Mark, Nonspacing [Nd] Number, Decimal Digit [Nl] Number, Letter [No] Number, Other [Pc] Punctuation, Connector [Pd] Punctuation, Dash [Pe] Punctuation, Close [Pf] Punctuation, Final quote (may behave like Ps or Pe depending on usage) [Pi] Punctuation, Initial quote (may behave like Ps or Pe depending on usage) [Po] Punctuation, Other [Ps] Punctuation, Open [Sc] Symbol, Currency [Sk] Symbol, Modifier [Sm] Symbol, Math [So] Symbol, Other [Zl] Separator, Line [Zp] Separator, Paragraph [Zs] Separator, Space 使用一个类，然后用__init__去初始化它，再返回值，相当于返回了一个封装好了的对象 1state_dict = kwargs.get('state_dict', None) 这是args和*kwargs的使用方法。如果未给出该值则state_dict值为None 参考 sys.version_info[0]可以得到python的版本 Python getattr() 函数 pow(n) 是计算n次方的 参考博客pandas TextFileReader to DataFrame pandas官方文档]]></content>
      <categories>
        <category>python语法</category>
        <category>各大库的琐碎语法记录</category>
      </categories>
      <tags>
        <tag>python语法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[toString()和new String()]]></title>
    <url>%2F2019%2F08%2F19%2Fjava%E7%9A%84%E8%BD%AC%E6%8D%A2String%2F</url>
    <content type="text"><![CDATA[用byte[]转换成String类型的时候，我用了(byte[]).toString()去转换，然后返回的结果居然是xxx@xxxx这个字符串，然后我很懵，点进源码才明白原因。 123public String toString() &#123; return getClass().getName() + "@" + Integer.toHexString(hashCode());&#125; 这是把类的类名加上“@”加上做的hashcode值转换成字符串返回输出，byte[]是个数组，是一个对象，所有的对象都是object的子类，所以数组可以使用object的方法，在object的方法里有toString()这个方法，但在没有被复写的情况下使用它，就会生成getClass().getName() + &quot;@&quot; + Integer.toHexString(hashCode())这个字符串。 所以我们用new String()的方式去转换byte[]值，将其变成String字符串输出。 123public String(byte bytes[]) &#123; this(bytes, 0, bytes.length);&#125; 1234public String(byte bytes[], int offset, int length) &#123; checkBounds(bytes, offset, length); this.value = StringCoding.decode(bytes, offset, length);&#125; 这是这两种方法的输出结果 参考博客数组相关概念 关于object的子类]]></content>
      <categories>
        <category>java语法</category>
        <category>toString()和new String()</category>
      </categories>
      <tags>
        <tag>java语法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[电话号码的字母组合]]></title>
    <url>%2F2019%2F08%2F05%2F%E7%94%B5%E8%AF%9D%E5%8F%B7%E7%A0%81%E7%9A%84%E5%AD%97%E6%AF%8D%E7%BB%84%E5%90%88%2F</url>
    <content type="text"><![CDATA[给定一个仅包含数字 2-9 的字符串，返回所有它能表示的字母组合。 给出数字到字母的映射如下（与电话按键相同）。注意 1 不对应任何字母。 题目来源 解答方法这个题目暴力破解的话至少要双重循环，更甚，然后我在这题里面学习了一下怎么用递归。 关于递归递归的话就是把一个庞大的问题细化成一个细小的问题，当然，这个庞大的问题的必须是可以重复的，机械的问题。 我特地去找了一下递归的说明： 明确递归终止条件：就是让递归及时终止，这样递归就不会一直一直执行下去 给出递归终止时的处理办法：终止时候需要执行什么，这也是需要写的。 提取重复的逻辑，缩小问题规模 里面重要的还是对递归问题进行提取重复逻辑。 因为我对递归不是很了解，所以我打算在这记一下我跟着官方题解弄懂的怎么缩小大的问题规模 分析逻辑假设输入的数字是“23“，然后”2“分支出去”abc“，三个支，再由”abc“分支，每个支都会连接到3里面的每个分支。 这就是可以被提取出来的重复逻辑。 可以从“2”中的分支递归。我们先把重复逻辑提取出来，重复的逻辑就是把数字对应的字母分支开来，然后继续分支下去，如此循环往复。 所以就用到了for循环，先对分支的顶端进行处理，也就是“2”分出来的“abc”三个分支。 我们要把结果存储到list列表里面，那么在递归结束后，要把输出的结果add进list中 流程就变成了这样： 【注：里面有错别字：是==第一个循环==】 这样就能把这个分支用递归的办法全部遍历一遍了。 也就是：我从第一层开始就对“2”指向的全部字母进行一个循环，循环中我再对跟在“2”后面的“3”指向的字母再次进行一个循环（也就是循环中进行递归），在循环的过程中，如果“3”后面还跟有其他数字的话，那我继续对“3”后面跟着的数字指向的字母进行循环，但如果“3”是最后一个数字的话，我把“3”指向的字母遍历完就可以返回上一层递归了，直到最后返回到最顶层，返回最终的结果。 参考文献关于递归的特点以及注意点 代码实现]]></content>
      <categories>
        <category>算法</category>
        <category>电话号码的字母组合</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>leedcode算法题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[三数之和]]></title>
    <url>%2F2019%2F07%2F22%2F%E4%B8%89%E6%95%B0%E4%B9%8B%E5%92%8C%2F</url>
    <content type="text"><![CDATA[给定一个包含 n 个整数的数组 nums，判断 nums 中是否存在三个元素 a，b，c ，使得 a + b + c = 0 ？找出所有满足条件且不重复的三元组。 注意：答案中不可以包含重复的三元组。 例如, 给定数组 nums = [-1, 0, 1, 2, -1, -4]， 满足要求的三元组集合为： 1234[ [-1, 0, 1], [-1, -1, 2]] 力扣（LeetCode） 先排序（java里面有Arrays.sort()这个方法进行排序，不过我自己用的是自己写的二分排序对这个数组进行的排序） 排完序，就能够更方便的去查找满足条件并且不重复的三元组了。 我们对三元组进行与两元组查找相似的操作，不过三元组多了一个元素而已。 所以先介绍两元组的和的查找办法 两元组相加办法因为现在这个数组是经过排序预处理的数组，所以接下来的查找中，left指向的数字和right指向的数字相加，比预计和要大的话，那么left就要向左边移动一位，就是left--；如果比预计和小的话，那么right要往右边移动一位，就是right++。 因为题目中要求的二元组是不能有重复的元素存在，所以在指针移动的过程中，我们要去对指针指向的数据进行判断，如果right和left指向的下一个元素与自己指向的上一个元素相同的时候，可以直接跳过，无需再次进行计算。（两点确定一条直线） 代码示例 三元组相加办法三元组比两元组多了一个元素，在两元组查找的基础上，再添加一层循环。 也就是一个最初的循环，然后在那个循环里面开始两元组的查找办法。有个需要注意的要点就是：三元组里面可能会出现的重复。 当我们对初始数据进行预处理（排序）后，相同元素会排在一块。所以需要避免相同三元组出现的话，就需要保证每次遍历的元素都是独一无二的，这是建立在二元组基础上的三元组需要注意的地方。 代码示例 四元组相加办法四元组又比三元组多了一个元素 所以又在外层加了一层循环语句，为了让复杂度小于o($n^{3}$)，我们对循环进行了一些操作，又叫剪枝。 剪枝把可能会产生重复四元组的情况去掉了，也把可能在对四元组的其中一个元素做循环，但没有能和这个元素产生结果的情况去掉了。 emm，也就是假如是[-1,0,1,2,-1,-4]这个数组我想要的目标值是0，但当我最外层循环指向-4时候，第二层循环，加上第三层循环都不可能能够找到-4和哪三个数相加得到0的时候，我就需要在预判断时候，就能够跳出循环，以避免产生更多的不必要的运算。 所以，剪枝我的办法是 123456789if(i &gt; 0 &amp;&amp; nums[i] == nums[i - 1]) &#123;continue;&#125;if(nums[i] + nums[i + 1] + nums[i + 2] + nums[i + 3] &gt; target) &#123; break;&#125;if(nums[i] + nums[n] + nums[n - 1] + nums[n - 2] &lt; target) &#123; continue;&#125; 预判断最外层指定的元素可不可能是想要的四元组的成员之一。 或者预判断最外层和次外层指定的两个元素可不可能和另外两个元素产生想要的四元组。 同时剪枝还需要去重： 1if(i &gt; 0 &amp;&amp; nums[i] == nums[i - 1]) &#123;continue;&#125; 判断当前指向的这个元素是不是这个指针上一个地方指向的是同一个元素，如果是，那指向下一个元素。这个去重是三层循环都必须需要的步骤，这样可以安全的去掉可能产生一样的四元组的可能。 四元组之和代码示范]]></content>
      <categories>
        <category>算法</category>
        <category>三数之和</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[整数反转]]></title>
    <url>%2F2019%2F07%2F18%2F%E6%95%B4%E6%95%B0%E5%8F%8D%E8%BD%AC%2F</url>
    <content type="text"><![CDATA[给出一个 32 位的有符号整数，你需要将这个整数中每位上的数字进行反转。 示例 1: 输入: 123 输出: 321 示例 2: 输入: -123 输出: -321 示例 3: 输入: 120 输出: 21 注意: 假设我们的环境只能存储得下 32 位的有符号整数，则其数值范围为 [−231, 231 − 1]。请根据这个假设，如果反转后整数溢出那么就返回 0。 力扣（LeetCode） 这个我先把整数转成string形式，然后再重新把这个字符串拼接，最后输出的字符串转换成整数即可，不过要先转换成long类型整数，再转换成int类型，不然会溢出的。 官方给的解答是： 对该整数循环进行整除10，直到最后结果为零才停止循环，在和该数除以10的余数相加，中途记住判断是否溢出即可。 因为太简单，直接放代码把。 代码]]></content>
      <categories>
        <category>算法</category>
        <category>整数反转</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[z字形变换]]></title>
    <url>%2F2019%2F07%2F18%2Fz%E5%AD%97%E5%BD%A2%E5%8F%98%E6%8D%A2%2F</url>
    <content type="text"><![CDATA[将一个给定字符串根据给定的行数，以从上往下、从左到右进行 Z 字形排列。 比如输入字符串为 “LEETCODEISHIRING” 行数为 3 时，排列如下： L C I R E T O E S I I G E D H N 之后，你的输出需要从左往右逐行读取，产生出一个新的字符串，比如：”LCIRETOESIIGEDHN”。 力扣（LeetCode） 我用暴力破解，z形输出了输入的字符串，结果发现看错了题目……只是要我z形排序。 然后官方题解特别简洁 它先是创建了一个列表，这个列表的长度代表了z字形需要被分成的行数（n = 3时候list.length = 3） 列表里面装的元素类型是stringBuffer，把每行会被输出的内容拼接在一起，如图： flag就是一个布尔（Boolean）值，用来判断z字形输出的走向，应该往上走还是往下走。它控制的是list存储里面应该往上存储还是向下存储，换句话来说就是list&lt;StringBuffer&gt;.get(i)中的i是增加还是还是减少。 最后再把里面的list里面的stringBuffer循环输出进行拼接，最后返回正确的值。 所以超简单，但是我就是没想到。 代码代码]]></content>
      <categories>
        <category>算法</category>
        <category>z字形变换</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[正则匹配]]></title>
    <url>%2F2019%2F07%2F08%2F%E6%AD%A3%E5%88%99%E5%8C%B9%E9%85%8D%2F</url>
    <content type="text"><![CDATA[看代码时候看到正则这块，而且我对它也一直搞不明白，这次干脆写篇博客，让自己对它理解更深一点。 关于对一些正则公式的理解(?:pattern):在我参考的博客里面解释的是非获取匹配，也就是只负责匹配，但不会获取匹配结果进行输出，提升了效率 \s：匹配空白字符 \t：制表符 \r：回车符 \n：换行符 []:括号里面代表或 *:跟在字符后面代表可以有0个或多个这个字符 ?：表达前面的表达式可以出线0次或1次 (?&lt;=exp)：匹配最左边的exp表达式能匹配的值。eg:remember (?&lt;=re) 返回的结果就是member 参考博客关于正则的公式的解析 关于正则公式的匹配]]></content>
      <categories>
        <category>java语法</category>
        <category>正则匹配</category>
      </categories>
      <tags>
        <tag>java语法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HMM隐马尔可夫模型]]></title>
    <url>%2F2019%2F07%2F03%2FHMM%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[emm学长让我看看命名实体识别，解释牵涉到HMM隐马尔可夫模型和条件随机场，我先看看，顺便记笔记，写博客。 关于熵（Entropy）熵在这里被用来表征系统的无序程度，熵越大，系统越无序。 负熵是物质系统有序化，组织化，复杂化状态的一种度量。 参考资料隐马尔可夫模型解释]]></content>
      <categories>
        <category>算法</category>
        <category>隐马尔可夫模型</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mockito使用]]></title>
    <url>%2F2019%2F06%2F24%2FMockito%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[关于Mockito的使用，跟着文档边看边试着那些用法。 来一段从官网搞出来的话 Mockito is a mocking framework that tastes really good. It lets you write beautiful tests with a clean &amp; simple API. Mockito doesn’t give you hangover because the tests are very readable and they produce clean verification errors. 翻译 Mockito是一个体感非常好的mocking框架，它能够让你用简洁干净的API写出漂亮的测试方法…… 好了后面的不翻译了，我看了一下，简而言之就是这个测试框架非常好用，特别好用，快来用吧 Mockito使用创建mock对象刚开始我是mock()一个对象： UserPersonService mockedUserPerson = Mockito.mock(UserPersonService.class); ps:其中UserPersonService是我想调通的service类。 然后发现可以用@Mock然后private这个类，然后就很方便的创建了一个Mock对象了： @Mock private UserPersonService userPersonService; 验证行为这里就是验证方法是否真的被调用，或者调用了多少次。 List mockedList = mock(List.class); //using mock object 使用mock对象 mockedList.add(&quot;one&quot;); mockedList.clear(); //verification 验证 verify(mockedList).add(&quot;one&quot;); verify(mockedList).clear(); 里面是验证 做测试桩打桩就是对调用的方法给它模拟返回值。然后再后面对这个方法进行调用，输入与之前设定的一样的输入值时候，如果那个方法响应了就会把自己之前模拟的返回值返回出来。这时候我们就能用输出到控制台语句去观摩一下是不是自己预期设定的结果。 LinkedList mockedList = mock(LinkedList.class); //stubbing // 测试桩 when(mockedList.get(0)).thenReturn(&quot;first&quot;); when(mockedList.get(1)).thenThrow(new RuntimeException()); 这是官网给出来的使用方法，里面当mockedList.get(0)时候返回的是自己设定好的first这个值，然后mockedList.get(1)时候返回的就是自己设定好的抛异常new RuntimeException() 当然，如果自己没有对某个输入参数进行打桩的话，输出就会默认null。 这个方法也就是看能不能调通这个方法，看是否会响应，会的话就会输出期望值，还能查看这个方法被调用了多少次。 使用心得我试着用@Mock去注解一个类，然后打桩，但是发现打完桩，还是不能返回我打桩时候设定的返回值。 然后问大佬们，他们给我说用@MockBean，之后就成功了，所以在看@Mock和@MockBean两个注解的区别 @Mock它们允许模拟类或接口，并记录和验证其上的行为。 将字段标记为模拟。 允许速记模拟创建。最小化重复的模拟创建代码。使测试类更具可读性。使验证错误更容易阅读，因为字段名称用于标识模拟。 @MockBean就是对不需要验证的类加上这个注解，然后它会自动将这个类代入测试的controller中的被@Autowired注解的类。然后返回自己打桩时候设置的值 Not only will @MockBean provide you with a mock, it will also add that mock as a bean (as the name suggests) within the ApplicationContext, and override any existing beans either by name or by type ————————摘自博文]]></content>
      <categories>
        <category>spring相关</category>
        <category>Mockito使用</category>
      </categories>
      <tags>
        <tag>spring相关</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习之线性回归]]></title>
    <url>%2F2019%2F06%2F21%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8B%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%2F</url>
    <content type="text"><![CDATA[在机器学习中，我听了吴恩达老师的几节课，一节是来介绍机器学习里面的监督学习，监督学习里面以回归分析和分类为代表，然后吴恩达老师介绍了回归算法，在此做笔记。 会用到的表达符号： m：培训的样本的数量（prince in 1000’s有47列:m=47） x：输入变量，也称为‘特征’(Size in feet^2) y：输出变量，也叫‘目标变量’（prince in 1000’s） ‘#’ ：训练样本的“个数”缩写 $\theta_{i}\,=\,$：模型参数 回归算法计算函数最小值：求导 = 0（因为求某数导是求的在当前这个数时候的切线斜率，只有在数值达到峰值时候，切线斜率才会为0） 回归算法分线性回归和非线性回归，这里先讨论线性回归。 线性回归就是一条直线，有两个未知数（x和y） 公式：$h{\theta }(x)=\theta {0}x+\theta_{1}$ 拟合拟合就是把平面上的点,用一条光滑的曲线连接起来,因为这条曲线有无数种可能,就有了各种拟合方法. 拟合误差（即总残差） 绝对值的导数不存在的推导函数可导必要条件是：在此点连续(也就是左连续必须和右连续相同) 这里是别人对绝对值的导数可能不存在而写出的证明： 最小二乘法最小二乘法是一种数学优化技术，就是可以求到一些未知的数据，并且使这些求得的数据和实际数据间的误差的平方和为最小 损失函数（loss function）就是真实值和理论值的偏差。 因为实际应用中会受到诸多因素的制约 效用函数百度里说：效用函数通常是用来表示消费者在消费中所获得的效用与所消费的商品组合之间数量关系的函数，以衡量消费者从消费既定的商品组合中所获得满足的程度。 残差平方和百度里解释的是：把数据点和它和回归直线上的预估点的差异数据称为残差，然后，所有的残差的平方和被称为残差平方和。它表示随机误差的效应，一组数据的残差平方和越小，它的拟合度也就越好。 拟合就是自己通过方程拟出来的曲线和已知的数据相吻合，这个过程叫做拟合 代价函数在单变量线性回归函数（例）：$h{\theta }(x)=\theta {0}x+\theta{1}$中的$\theta{1}$和$\theta_{0}$(就是模型参数)这两个未知数可以有很多种组合，从而得出不同的线性函数，拟合出不同的曲线。 但是为了能够让拟合出来的曲线和已知数据尽最大程度吻合，挑选$\theta{1}$和$\theta{0}$很重要。 所以就有了求平均误差的公式：$J(\theta {0} \,,\, \theta {1} \, )=\frac{1}{2m}\sum{i=1}^{m}(h{\theta }(x^{(i)})-y^{(i)}))^{2}$ 这个公式是用来衡量设置出来的$\theta{1}$和$\theta{0}$的值拟合的曲线和真实的数据的吻合度，所以这个公式得出来的结果越小越好。 其中的$\frac{1}{2}$这是在尝试减小平均误差 于是其中：minimize $J(\theta {0} \,,\, \theta {1} \, )$，就是这个线性函数的代价函数 参考资料拟合解释 绝对值的导数不存在的原因 [参考视频为吴恩达老师的机器学习的入门视频]]]></content>
      <categories>
        <category>算法</category>
        <category>机器学习</category>
        <category>线性回归算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[最长回文串]]></title>
    <url>%2F2019%2F06%2F18%2F%E6%9C%80%E9%95%BF%E5%9B%9E%E6%96%87%E4%B8%B2%2F</url>
    <content type="text"><![CDATA[终于弄懂了最长回文串，在做题的时候，总是在暴力破解的思路里出不去，总想着两个for循环，空间复杂度为o($n^{2}$)然后解题思路里面讲了Manacher’s algorithm这个算法，把复杂度降低到了o(n)。 首先看张图（我为了图方便，都先预处理了字符串，不是按官方给的判断回文子串的奇偶方法） 上面那行是我用暴力破解用的时间，下面那行是用Manacher’s algorithm这个算法花的时间，可以很明显的看到emm差距。 （想说一点[题外话]：记得老师说以空间换时间和以时间换空间的这句话，所以我们需要在时间和空间中找到一个平衡点以达到我们想要的效率） 暴力破解这个算法很简单，就是简单粗暴的双循环，接着判断是不是回文串，再判断是不是最长的回文串。 我用的是先预处理字符串，在字符串中间加入”#”号，字符串首尾也加上这个 eg：abcd =====&gt; #a#b#c#d# 这样就能保证字符串长度一定为奇数了（如果字符串原长3，那么就需要插入4个”#”，那么奇数加偶数一定是奇数了） 然后根据循环到的位置，扩散开来判断是否是回文串，是的话同时记录长度和下标，就能够寻找到最长的回文串了。 Manacher’s algorithm预处理首先预处理字符串，让字符串保证长度为奇数eg：aba =====&gt; #a#b#a# 主要思路先假设当前最长回文串 里面的p[i]是指当前回文串的半径（其实p[i] - 1就是当前回文串的真实长度） 所以，p[j]是最后得出最长回文串的关键。 所以我们需要求出p[j]（ci的位置就是为p[i]服务的） 先假设ci是当前最长回文串的中心点，那么由它开始往外扩展，判断这个最长回文串里面是否有新的回文串，如果有的话，首先判断新的回文串是不是被这个最大回文串包含了。 从j=0开始往后遍历，同时开始判断当前最长的回文串，然后ci的位置根据最长回文串的最右边界的位置而开始发生改变。 接着就要开始讨论关于j的位置处于最长回文串的笼罩范围内的情况了： 这里列举的是j存在的回文串处于最长回文串笼罩的范围内的情况。 在这里我们没有必要去一个个比较去判断在最长回文串内的i的情况，我们可以直接对j对应ci的另一边的j的映射（我们称为i，i = 2* ci - j）i的p[i]的长度，如果p[i]的回文串长度如上图所示的话，那么p[j]=p[i],然后跳出循环，去遍历下一个j 除了刚刚那种情况，那就还有剩下的一种情况了：j存在的回文串长于最长回文串笼罩的范围内的情况 其中j的回文子串的右边比ci所对应的回文串的最右边长（如图），那么我们就需要判断一下j对应的i的回文字符串有多长，所以首先我们要知道l的长度，因为对应的i的那个部分是回文字符串，所以在没有超出ci的最长回文串的最右边界的部分，j的那段一定是回文字符串，所以我们就需要在基于l长度的回文字符串的基础下，继续往后比较。 如果j的回文串的最右边界超出了ci原本对应的最长回文串的边界 那么就令ci的值变成j的值。 当然，在对ci做改变时候，要记住随时记录p[j]的值，并且随时记录p[j]里面的最大值。 结尾所以最后就根据p[j]的最大值找到对应的字符子串，这个子串就是最大回文串 参考资料参考官方资料 本文代码]]></content>
      <categories>
        <category>算法</category>
        <category>最长回文串</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[寻找两个有序数组的中位数]]></title>
    <url>%2F2019%2F06%2F10%2F%E5%AF%BB%E6%89%BE%E4%B8%A4%E4%B8%AA%E6%9C%89%E5%BA%8F%E6%95%B0%E7%BB%84%E7%9A%84%E4%B8%AD%E4%BD%8D%E6%95%B0%2F</url>
    <content type="text"><![CDATA[给定两个大小为 m 和 n 的有序数组 nums1 和 nums2。 请你找出这两个有序数组的中位数，并且要求算法的时间复杂度为 O(log(m + n))。 你可以假设 nums1 和 nums2 不会同时为空。 nums1 = [1, 3] nums2 = [2] 中位数是：2.0 我自己的解法是用的归并排序，先把两个有序数组排好序放到另一个数组中，再用位运算找到中位，求解，然后结果是运行速度极慢。 就去看了官方的结题思路 因为官方有直接的答案，我就在这写写我的理解(ps：其中一些公式什么的是直接从官网复制黏贴来的，图片也是直接截的，手打太费事了)【简要概述】： 结题思路把nums1和nums2都分成两个部分，然后nums1左边的部分和nums2左边的部分，nums1右边的部分nums2右边的部分放在一块，最后左边的部分总数要和右边部分的总数一样多,如下图： 根据这张图里面的左边和右边的部分，我们假设已知$\,i\,$和$\,m\,$还有$\,n\,$的值，然后用公式把$\,j\,$表示出来,其中： $len(left_part)=len(right_part)$ $\max(\text{left_part}) \leq \min(\text{right_part})max(left_part)≤min(right_part)$ 为了保证数据不溢出，所以要保证nums1的长度要小于nums2，这样先对nums1选中i的指向位置后，根据公式算出j的时候就不会发生j指向的nums2数据溢出了。 这个题目的本质就是，把这两个数组统一分成两部分，前面那个部分都要比后面的部分小，所以，我们必须确保： B[j−1]≤A[i] 以及 $\text{A}[i-1] \leq \text{B}[j],A[i−1]≤B[j]$ 然后i和j的算法公式： $ i=0∼m, j=\frac{m+n+1}{2}−i$ 所以，得出i和j之后，我们就可以根据nums1[]和nums2[]这两个有序数组的大小去寻找中位数了。 其中m+n+1是为了保证中位数落在分割线的左边，如果中位数在中位线的右边的话，很容易因为数据溢出而报错。 因为很多时候，i会等于nums1[].lenth()，或者j会等于nums2[].lenth()，所以我们在循环保证i的指向是我们想要的地方之后（或者刚好溢出后），进入判断环节。 如果i等于nums1[].lenth()，那么则意味着j的指向的数字是我们所需要的中位数之一（之所以说是之一，是因为这两个数组长度加在一起是奇数，不然i是不会等于nums1[].lenth()），j也是这样。 如果i等于0的时候，那么意味着j现在指向的就是中位数，而不需要继续去寻找中位数了。j等于0的时候也是如此。（i或者j指向0，这种情况在两个数组长度为奇数或者偶数的情况下都会出现） 讲的有点零散，所以我决定直接把代码连接放出来！见官网 和我github上面的代码实现 题目来源力扣（LeetCode）]]></content>
      <categories>
        <category>算法</category>
        <category>寻找两个有序数组的中位数</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringCloud学习]]></title>
    <url>%2F2019%2F06%2F05%2FSpringCloud%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[之前我写的代码都是单架构模式，就是把多个功能放在同一个应用里面，就像之前写的小程序后台一样 修改了部分代码，就得整体再重新打包编译，没有修改的部分，甚至不需要使用到这部分代码的功能也因为重新打包编译而全部不能使用…… 所以要通过分布式和集群的方式把单架构模式改造一下 微服务概念一个springboot就是一个微服务，而且这个springboot做的事情很单一。在我的理解里面，就是把之前的一个整体的分层架构的springboot分成controller、service、dao这三个部分， 微服务注册虽然把springboot分了三部分，但这三部分应该怎么建立连接，相互之间应该怎么进行联络，所以就要引入一个微服务注册中心的概念了。这个微服务注册中心在 springcloud 里就叫做 eureka server, 通过它把就可以把微服务注册起来，以供将来调用。 微服务访问一个服务通过微服务注册中心定位并访问另外一个微服务。 分布式概念博客里介绍：本来一个spring boot就能完成的任务现在分布在多个spring boot里面做。就是不同的部分的微服务可以由不同的团队去开发，耦合度低。 集群就是同样的功能，但是用的端口不一样，如果8080挂了，我可以用8081这个端口的这个功能的微服务，这叫高可用==。 参考博客Spring Cloud入门（对这篇博客做的笔记）]]></content>
      <categories>
        <category>Spring Cloud学习（一）</category>
        <category>微服务的概念</category>
      </categories>
      <tags>
        <tag>Spring Cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springBootTest注入失败]]></title>
    <url>%2F2019%2F06%2F05%2FspringBootTest%E6%B3%A8%E5%85%A5%E5%A4%B1%E8%B4%A5%2F</url>
    <content type="text"><![CDATA[在用测试测dao层时候，虽然都有用注解:dao层用注解@Repository标记，Test类里面注入用@Autowired标记。 但是还是显示注入失败。 查了半天方法，最后去了spring boot的运行类里面加上了指定包扫描@ComponentScan(basePackages = {“扫描的包的共有的包名部分”}) 然后刚刚发现，之所以扫不出来是因为我包名的命名错误]]></content>
      <categories>
        <category>spring相关</category>
        <category>Test</category>
        <category>SpringBootTest注入失败</category>
      </categories>
      <tags>
        <tag>运行error</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[态势感知]]></title>
    <url>%2F2019%2F05%2F31%2F%E6%80%81%E5%8A%BF%E6%84%9F%E7%9F%A5%2F</url>
    <content type="text"><![CDATA[在找研究方向时候，有人推荐我看看态势感知，所以记个笔记 我对态势感知的理解就是：对网络里来往的流量进行分析，排除噪声，通过各种手段通过分析得出安全情况，然后进行防护。 网络安全态势感知NSSA（network security situation awareness） 态势感知 态势是各种状态的综合，是一个整体和全局的概念。它强调的是系统和系统对象之间的关系,下图是态势感知的系统要素内容（我jio的就是单纯的流程，就是从收集到的原始数据，然后进行处理得到的数据，再从这些数据里面用技术去分析，得到相关不同的进行了的活动，再去针对不同的活动进行不同的分析，最后的状态评估，进行预测，不同的活动会对系统中的各个对象产生的作用）]]></content>
      <categories>
        <category>态势感知相关</category>
        <category>态势感知</category>
      </categories>
      <tags>
        <tag>态势感知</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一种基于结构划分概率的口令攻击方法]]></title>
    <url>%2F2019%2F05%2F10%2F%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%E7%BB%93%E6%9E%84%E5%88%92%E5%88%86%E6%A6%82%E7%8E%87%E7%9A%84%E5%8F%A3%E4%BB%A4%E6%94%BB%E5%87%BB%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[这是一种基于结构划分概率的口令攻击方法研究，里面牵涉到了上下文无关文法 它分析了现在存储用户口令的方法，然后优化了对口令的攻击方法，节约了很多时间 论文大体介绍现在的系统大部分是保存口令的Hash值，用户登录时候，会通过单向函数（单向函数给定输入值进行输出很简单，但是很难从输出值去推算回输入值）对输入的口令进行运算，再把得到的Hash值去和存储的哈希值进行对比，如果相等，那么就登录成功了。 也有一些系统是采用加盐值（就是给你的密码加一串随机数，然后再进行哈希运算，得出一串哈希值，这样对于去破解密码的人来说，运算量很大，很难被破解）的方法去进一步保证系统的安全性。 因为攻击难度提高了，所以攻击者换了个角度，开始从人对口令的记忆方面去思考攻击方法，提高攻击效率。 这篇论文是重在考虑基于口令划分概率的口令攻击方法。它和另一个方法相比提高了百分之二十到百分之三十的命中率 这个方法也具有学习功能，能够根据攻击结果更新使用的字典，提高攻击效率。 近来口令分析简介 结合词典，根据刚开始定义的变形规则去改变刚开始的单词，生成口令。 但是变形规则简单，数量有限，要人工自己编写 口令搜索空间有限，它依赖于已经有的字典和变形规则，变形规则简单，虽然可以根据攻击者自己想变形规则去形成复杂口令，但效率不高。 基于马尔科夫链的时间存储折中攻击 （没看） 基于概率上下文无关文法口令攻击方法 用概率上下文无关文法去定义口令结构，就分块定义，然后对每个块的密码内容进行概率排序，然后产生半终端结构（就是比如我分块是A、B、C、D三个块，A概率最大的值是1，那么按A概率排的半终端结构就是1BCD） 各个块进行概率排序，然后各个按概率大小组合在一起，形成的结构再按概率插入队列 有了更多的变形规则，搜索空间更大了 据统计，高概率的具体结构长度大部分都小于等于3（就分的块小于等于分出了三个块） 命中率低（但相对于前面的，已经提高了命中率） 口令结构分析详细数据表明，大部分人都会把口令只划分为一个部分（也就是比较单一）当然还有少部分会使用其他结构 对口令按具体结构进行初次划分时候，不会把口令结构划分的很小。 根据数据分析，虽然结构长的口令比较难被攻击者猜测出来，但是很少有用户会选择结构长的口令。 基于结构划分概率的方法所以该文决定对高概率的口令组合结构根据用户习惯进行再次划分 主要步骤： 预处理 口令攻击阶段 预处理 具体结构：就是根据用户设置的口令而划分的结构（没有被处理过的那种） 抽取子结构：就是从具体结构中划分出来的小结构再分类别归类，从而形成了抽取子结构。eg:A（字母）、D（数字），具体结构是：ADAD =&gt; {AA，DD}（分类别归类），其中抽取子结构为：$\bar{A}\, =\, AA\,$ 再对具体结构根据它对应的抽取子结构进行归类，再计算该结构的使用概率。 论文中使用了一种概率统计方法： $p\, =\frac{NUM{ss{i}}} {NUM{es{j}}}$ 其中分母表示的是具有这个抽取子结构的数目，分子是对应的具有此划分子结构数目（就是对具体子结构分类别归类后，不同结构组成同一抽取子结构的结构） $\,ss{i}\,$表示第i个划分子结构,$\,es{j}\,$表示二对应的第j个抽取子结构. 由论文总结的数据可以得知：用户口令单一结构的组成占大多数。 参考文献[1] 邹静,林东岱,郝春辉.一种基于结构划分概率的口令攻击方法[J].计算机学报,2014,37(05):1206-1215.]]></content>
      <categories>
        <category>数学导论</category>
        <category>上下文无关文法</category>
        <category>论文赏析（只有赏）</category>
      </categories>
      <tags>
        <tag>数学导论</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[学习爬虫（一）：安装selenium和ChromeDriver]]></title>
    <url>%2F2019%2F05%2F10%2F%E5%AD%A6%E4%B9%A0%E7%88%AC%E8%99%AB%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9A%E5%AE%89%E8%A3%85selenium%E5%92%8CChromeDriver%2F</url>
    <content type="text"><![CDATA[关于爬虫的学习，先从selenium这个库开始学。 关于selenium先是 pip install selenium 安装完这个，我以为就odk了，然后在pycharm编译器里面跟着网上给的代码敲了一段 from selenium import webdriver browser = webdriver.Chrome() browser.get(&#39;https://www.baidu.com&#39;) 结果报错了 This inspection detects names that should resolve but don&#39;t. Due to dynamic dispatch and duck typing, this is possible in a limited but useful number of cases. Top-level and class-level items are supported better than instance items. 大体意思就是模块不存在，然后我以为是pip install时候出错了，就回去再pip install一遍，结果发现，还是没有用。 然后上网找解决方案，跟着网上的教程去看了pycharm这个IDE里面设置的python环境的路径： File &gt; settings &gt; project:xxxxxxx(你导入pycharm的文件夹) &gt; project Interpreter 就发现我pip install下载下来的selenium库地址和之前设置在IDE里面python环境的地址不一样，所以没法找到selenium这个模块。 然后去对这个IDE里面的python路径进行更改。 更改 点show all…… 接着 找到对应python-pip的相关python目录所在地，然后更改IDE依赖环境目录。 查找目录所在地我是再次pip install selenium，然后看到了selenium存的位置，再根据这个位置找到相关信息。 ChromeDriver我弄好了，发现不再显示该模块不存在的信息了之后，运行了一遍，发现还是报错了。 Service chromedriver unexpectedly exited 出现了这个报错信息。 装插件所以我去安装chromedriver驱动下载地址 下载好了之后，解压，再新建一个文件夹，里面只放解压出来的exe文件，再去控制面板里面配置环境path 然后再运行，成功调出了Chrome浏览器，并且让它自动进入百度搜索页面。 browser.get()browser.get()括号里面的字符串必须填写完整的网址，不然会显示无效网址的错误提示。 参考资料参考资料]]></content>
      <categories>
        <category>爬虫、python</category>
        <category>安装selenium和ChromeDriver</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git出错（一）]]></title>
    <url>%2F2019%2F05%2F09%2Fgit%E5%87%BA%E9%94%99%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[报错：src refspec master does not match any 操作过程git init git commit -m &quot;first commit&quot; git remote add origin git@github.com:aimasa/xxxxxxxx git push -u origin master 然后再回车的时候，git bash就报错了 src refspec master does not match any 原因我没有提交任何内容，我的本地库（.git）是空的，所以第一次push是提交一个空项目，里面没有任何东西，所以报错了 解决方法把代码提交到本地，然后再推送一次 git add . git commit -m &quot;xxxx&quot; git push -u origin master 推送成功]]></content>
      <categories>
        <category>git</category>
        <category>git出错</category>
        <category>src refspec master does not match any.</category>
      </categories>
      <tags>
        <tag>git出错</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[七牛云把测试域名替换成已备份域名]]></title>
    <url>%2F2019%2F05%2F08%2F%E4%B8%83%E7%89%9B%E4%BA%91%E6%8A%8A%E6%B5%8B%E8%AF%95%E5%9F%9F%E5%90%8D%E6%9B%BF%E6%8D%A2%E6%88%90%E5%B7%B2%E5%A4%87%E4%BB%BD%E5%9F%9F%E5%90%8D%2F</url>
    <content type="text"><![CDATA[之前把图片放在七牛云的图床上，结果因为我的测试域名到期了，一定要绑定一个域名，才能继续用。接着我去阿里云买了个服务器，绑定了一个域名，并且去做了备案【千万考虑清楚，因为我买的是学生机，所以比较便宜。然后开始在思考我为什么那么冲动，买了服务器不知道干啥用，好浪费,所以打算开始学爬虫……】 step进入控制台去对域名进行绑定 进入了控制台，然后点击绑定域名。 输入已经备案好了的域名，选择http协议，如果选择https的话就要花钱（购买证书把大概） 提示：里面已备份域名填你的二级域名就好了。 然后其他的我都是默认设置，最后点创建。 创建完了之后，点进融合SDN去找管理域名 然后把鼠标移到我标红的这块会有“复制CNAME”，点击。 接着就去购买的服务器那里对这个二级域名进行解析 登录进阿里云，点进管理控制台，进入域名，点击域名列表 然后在你购买的那个域名旁边点解析 点击添加记录 按照图示填写信息。 再然后就等你的 状态变成成功了。 再然后去你博客配置文件里面更改之前的配置： 把我马克了的地方改成你二级域名，就好了。 二级域名比如你购买的域名是aimasa.com，那么你的二级域名就可以是：{自定义}.aimasa.com。但是这只是一般称谓，一般叫它子域名，因为按维基百科上来说，一级域名是顶级域名，是域名的最后一个部分，二级域名是靠近顶级域名的左边一个部分。然后以此类推可以推出三级域名，四级域名等等。 参考资料二级域名是什么的博客，我觉得解释的比大多数博客好太多了]]></content>
      <categories>
        <category>hexo更新配置</category>
        <category>七牛云把测试域名替换成已备份域名</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java打包供maven使用]]></title>
    <url>%2F2019%2F04%2F28%2Fjava%E6%89%93%E5%8C%85%E4%BE%9Bmaven%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[因为之前老师说好的说让我自己试试怎么对项目打包，然后把包封装成相关依赖，这样可以直接在maven里面添加依赖，然后对包进行调用。 把项目打包用的是fatjar对项目进行的打包，又快又方便。 我用的是eclipse4.4版本，对项目右键会有build FatJar的选项，然后点进去，选择好生成jar包的位置【注意：包存放的文件夹名中间不能有空格，不然包转成依赖语句会报错】，然后jar包就生成了。 把包转换成依赖首先win+R进入cmd命令行，然后cd到该jar包存放的位置，再然后输入以下命令行 mvn install:install-file -Dfile=jar包的位置 -DgroupId=上面的groupId -DartifactId=上面的artifactId -Dversion=上面的version -Dpackaging=jar —————————————————-摘自博客 然后回车，一顿操作猛如虎，再新建一个项目，添加： &lt;dependency&gt; &lt;groupId&gt;com.qrcode&lt;/groupId&gt;&lt;!--DgroupId等于的参数值--&gt; &lt;artifactId&gt;qr&lt;/artifactId&gt;&lt;!--DartifactId等于的参数值--&gt; &lt;version&gt;0.1&lt;/version&gt;&lt;!--Dversion等于的参数值--&gt; &lt;/dependency&gt; 参考资料博客]]></content>
      <categories>
        <category>java语法</category>
        <category>java打包供maven使用</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[java版本太低]]></title>
    <url>%2F2019%2F04%2F28%2Fjava%E7%89%88%E6%9C%AC%E5%A4%AA%E4%BD%8E%2F</url>
    <content type="text"><![CDATA[导入一个本来是没有语法错误的项目，然后IDE到处报错，说是jdk版本太高，要更改成低版本。 对着被导入的项目点击右键-&gt; properties-&gt;java build path 然后双击JRE System Library，然后更换jre的版本号（和本地装的jre的版本号一致） 然后成功]]></content>
      <categories>
        <category>运行error</category>
        <category>java版本太低</category>
      </categories>
      <tags>
        <tag>运行error</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vim的使用心得]]></title>
    <url>%2F2019%2F04%2F23%2Fvim%E7%9A%84%E4%BD%BF%E7%94%A8%E5%BF%83%E5%BE%97%2F</url>
    <content type="text"><![CDATA[因为最近不是b站后台源码被泄露了嘛，然后它用的是go语言，我又不想在windows系统里面装go语言的IDE，然后就在虚拟机里面配置go语言的环境，过程中在里面我用到了一些对vim的操作，在这里特地记录一下。 插入直接按s键，然后又可以插入，也可以对其中的内容进行修改。 保存并且推出 保存：按住esc键，然后输入:w 退出：按住esc键，然后输入:q 保存且退出：按住esc键，然后输入:wq 目前只用到了这些操作方法，所以暂时如此记录]]></content>
      <categories>
        <category>ubuntu的使用</category>
        <category>vim的使用心得</category>
      </categories>
      <tags>
        <tag>关于ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于maven]]></title>
    <url>%2F2019%2F04%2F18%2F%E5%85%B3%E4%BA%8Emaven%2F</url>
    <content type="text"><![CDATA[之前一直只是单纯的知道maven是用来加载库的，然后去代码里面调用它。里面&lt;/dependencies&gt;这里面是存放需要被调用的库的依赖。但是maven里面包括的内容除了还有别的，所以就去查了一些资料，然后总结在这。 Maven 主要帮助用户完成以下 3 个方面的工作： 生命周期管理，便捷的构建过程； 依赖管理，方便引入所需依赖 Jar 包； 仓库管理，提供统一管理所有 Jar 包的工具； ————-(摘自博客) 在建了一个maven项目之后，会发现在项目里面有一个pom.xml文档 什么是pom项目对象模型或POM是Maven的基本工作单元。 它是一个XML文件，其中包含有关Maven用于构建项目的项目和配置详细信息的信息。 它包含大多数项目的默认值。 这方面的例子是：target是构建目录;构建源目录是src / main / java; src / test / java是测试源目录。执行任务时，Maven在当前目录中查找POM。 它读取POM，获取所需的配置信息，然后执行目标。 maven install时候，会自动把pom里面添加的依赖下载下来。 maven的生命周期maven内部有三个构建生命周期：分别是：clean, default, site 我在那个博客里面找到了这张展示default构建生命周期核心阶段的图： 当执行mvn install时候，maven就会自动执行生命周期中的validate, compile, test, package, verify, install这些阶段，并将 package 生成的包发布到本地仓库中。 Maven 将构建过程定义为 default lifecycle 阶段和插件的关系就像上面说的那样，maven把构建过程定义成default lifecycle，并且将它里面的一个个阶段划分为phase，但是这些phase只是规定执行顺序，对于每个阶段做什么工作，就要看pom.xml里面的插件（plugins）了。 pom.xml里面有这么个元素叫，它是用来把phase和做的目标绑定在一起，当要执行某个时候，就会调用插件来完成绑定的目标，一个阶段里面可以绑定好多个目标，也可以不绑定目标。 但是不配置也可以，因为maven有默认的。 在输出日志里面，会有一系列的 插件(plugin):版本号:(phase) 输出，可以根据日志里面的这种输出去观察哪些阶段会调用插件去完成那些了。 依赖在里面的依赖一般都是这种形式出现： &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; 关于maven整体| groupId|一般用该项目的组织或团体的域名来标识，例如:org.apache.maven.plugins | | artifactId | 代表唯一的工程名 | |version| 版本号| |packaging| 标识打包的类型，例如有:jar, war, tar | |dependencies| 该工程内依赖的其他 jar 包| 远程仓库如果 Maven 在中央仓库中也找不到依赖的库文件，它会停止构建过程并输出错误信息到控制台。为避免这种情况，Maven 提供了远程仓库的概念，它是开发人员自己定制仓库，包含了所需要的代码库或者其他工程中用到的 jar 文件。 我的理解就是可以通过这个repositories节点，去访问给出的url地址上的这个仓库，去下载自己需要的库，因为这个库在可能是自己的远程仓库里面，就没法从中央仓库里面下载到这个库，所以就使用这个节点，里面配置各种你可能需要用到的远程库。 &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-snapshots&lt;/id&gt; &lt;name&gt;Spring Snapshots&lt;/name&gt; &lt;url&gt;https://repo.spring.io/snapshot&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; Maven 依赖搜索顺序当我们执行 Maven 构建命令时，Maven 开始按照以下顺序查找依赖的库： 步骤 1 － 在本地仓库中搜索，如果找不到，执行步骤 2，如果找到了则执行其他操作。 步骤 2 － 在中央仓库中搜索，如果找不到，并且有一个或多个远程仓库已经设置，则执行步骤 4，如果找到了则下载到本地仓库中已被将来引用。 步骤 3 － 如果远程仓库没有被设置，Maven 将简单的停滞处理并抛出错误（无法找到依赖的文件）。 步骤 4 － 在一个或多个远程仓库中搜索依赖的文件，如果找到则下载到本地仓库已被将来引用，否则 Maven 将停止处理并抛出错误（无法找到依赖的文件）。 ———————————摘自极客学院maven教程 关于${xxx.version}一般，会经常看到官网上放出的写maven依赖中有个语句是 &lt;version&gt;${xxx.version}&lt;version&gt; 但是maven总是报错，是因为你这里没有指明这个添加的依赖的版本，maven是不会自动给你找到相关依赖的最新版本的包并且去下载的，所以你需要在里面加上 &lt;xxx.version&gt;1.3.0.Final&lt;/xxx.version&gt; 这样的话，就是${xxx.version}的值就是对应给出的1.3.0.Final了。 参考资料maven入门 maven生命周期 极客学院maven教程]]></content>
      <categories>
        <category>maven</category>
      </categories>
      <tags>
        <tag>maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[开始学习spring（五）：连接数据库]]></title>
    <url>%2F2019%2F04%2F17%2F%E5%BC%80%E5%A7%8B%E5%AD%A6%E4%B9%A0spring%EF%BC%88%E4%BA%94%EF%BC%89%EF%BC%9A%E8%BF%9E%E6%8E%A5%E6%95%B0%E6%8D%AE%E5%BA%93%2F</url>
    <content type="text"><![CDATA[因为这边都用的是jooq框架来对数据库进行操作，然后我就开始学jooq框架惹==。我暑假还是想好好的活着，不想再像上个暑假一样痛苦。 不过刚开始接触这个框架，坑也没少踩，我会在下面分别列出来。 用的是maven 第一步：装依赖在jooq的官网看，首先第一步，在pom中要加上这三个依赖 &lt;dependency&gt; &lt;groupId&gt;org.jooq&lt;/groupId&gt; &lt;artifactId&gt;jooq&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.jooq&lt;/groupId&gt; &lt;artifactId&gt;jooq-meta&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.jooq&lt;/groupId&gt; &lt;artifactId&gt;jooq-codegen&lt;/artifactId&gt; &lt;/dependency&gt; jooq ：核心包，CRUD（增删查改）核心类所在大本营。 jooq-meta ：数据管理和操作的核心代码。 jooq-codegen ：负责数据库代码生成，主要负责JOOQ的代码生成功能。 第二步：加插件 &lt;plugin&gt; &lt;groupId&gt;org.jooq&lt;/groupId&gt; &lt;artifactId&gt;jooq-codegen-maven&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;generate&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.39&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;configuration&gt; &lt;jdbc&gt; &lt;driver&gt;com.mysql.jdbc.Driver&lt;/driver&gt; &lt;url&gt;jdbc:mysql://localhost:3306/exercise_test?useSSL=true&lt;/url&gt; &lt;user&gt;root&lt;/user&gt; &lt;password&gt;&lt;/password&gt; &lt;/jdbc&gt; &lt;generator&gt; &lt;database&gt; &lt;name&gt;org.jooq.util.mysql.MySQLDatabase&lt;/name&gt; &lt;includes&gt;.*&lt;/includes&gt; &lt;excludes&gt;&lt;/excludes&gt; &lt;inputSchema&gt;exercise_test&lt;/inputSchema&gt; &lt;forcedTypes&gt; &lt;forcedType&gt; &lt;userType&gt;java.util.Date&lt;/userType&gt; &lt;converter&gt;com.example.util.DateConverter&lt;/converter&gt; &lt;types&gt;datetime&lt;/types&gt; &lt;/forcedType&gt; &lt;/forcedTypes&gt; &lt;/database&gt; &lt;target&gt; &lt;!-- The destination package of your generated classes (within the destination directory) --&gt; &lt;packageName&gt;com.example.pojo&lt;/packageName&gt; &lt;!-- The destination directory of your generated classes --&gt; &lt;directory&gt;/src/main/java&lt;/directory&gt; &lt;/target&gt; &lt;generate&gt; &lt;pojos&gt;true&lt;/pojos&gt; &lt;daos&gt;true&lt;/daos&gt; &lt;deprecated&gt;false&lt;/deprecated&gt; &lt;/generate&gt; &lt;/generator&gt; &lt;/configuration&gt; &lt;/plugin&gt; 这一部分是用来生成数据库映射代码的插件。 里面是对数据库的信息进行配置： &lt;configuration&gt; &lt;jdbc&gt; &lt;driver&gt;com.mysql.jdbc.Driver&lt;/driver&gt; &lt;url&gt;jdbc:mysql://localhost:3306/exercise_test?useSSL=true&lt;/url&gt; &lt;user&gt;root&lt;/user&gt; &lt;password&gt;&lt;/password&gt; &lt;/jdbc&gt; &lt;generator&gt; &lt;database&gt; &lt;name&gt;org.jooq.util.mysql.MySQLDatabase&lt;/name&gt; &lt;includes&gt;.*&lt;/includes&gt;&lt;!--点后面的所有文件--&gt; &lt;excludes&gt;&lt;/excludes&gt; &lt;!--映射的数据库的架构名（就是你的表是放在哪个架构下的）--&gt; &lt;inputSchema&gt;exercise_test&lt;/inputSchema&gt; &lt;forcedTypes&gt; &lt;forcedType&gt; &lt;userType&gt;java.util.Date&lt;/userType&gt; &lt;converter&gt;com.example.util.DateConverter&lt;/converter&gt; &lt;types&gt;datetime&lt;/types&gt; &lt;/forcedType&gt; &lt;/forcedTypes&gt; &lt;/database&gt; &lt;target&gt; &lt;!-- 你数据库映射出来的表打算放在代码里面的哪个包下 --&gt; &lt;packageName&gt;com.example.pojo&lt;/packageName&gt; &lt;!-- 这个包是应该在哪个class下面 --&gt; &lt;directory&gt;/src/main/java&lt;/directory&gt; &lt;/target&gt; &lt;generate&gt; &lt;pojos&gt;true&lt;/pojos&gt; &lt;daos&gt;true&lt;/daos&gt; &lt;deprecated&gt;false&lt;/deprecated&gt; &lt;/generate&gt; &lt;/generator&gt; &lt;/configuration&gt; 这里面配置这段就是把数据库中的表映射出来的。 &lt;forcedTypes&gt; &lt;forcedType&gt; &lt;userType&gt;java.util.Date&lt;/userType&gt; &lt;converter&gt;com.example.util.DateConverter&lt;/converter&gt; &lt;types&gt;datetime&lt;/types&gt; &lt;/forcedType&gt; &lt;/forcedTypes&gt; 这段代码是用来映射时间戳的，其中 &lt;converter&gt;com.example.util.DateConverter&lt;/converter&gt; 是放有映射方法的包，没有放映射方法的话，那这段无效==。可以按ctrl进去，查看这个包，如果无法查看的话，那么说明这个包不是需要的。 数据库的架构放张图就很详细了： 出错地方这样配置完成后，我的这个项目名旁边跟了一个红×，所以就右键项目，选中maven，出现子目录，选中update project，点击，如果配置没有错误的话，红×会自然消失。 然后就是maven install的问题了，显示BUILD FAILED失败，里面有一句话，翻译过来是问我有没有配置错jdk，所以我就去perferences里面的 java-&gt;install JREs看了看里面的包是不是配置的jdk包，如果不是，点击add-&gt;Standard VM-&gt;next-&gt;选择jdk的包 再然后maven install就没有再出问题了，同时，也将我数据库里的表转换成了pojo的包里的java类了。 参考资料参考博客]]></content>
      <categories>
        <category>spring相关</category>
        <category>连接数据库</category>
      </categories>
      <tags>
        <tag>spring相关</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[开始学习spring（四）：Junit测试]]></title>
    <url>%2F2019%2F04%2F10%2F%E5%BC%80%E5%A7%8B%E5%AD%A6%E4%B9%A0spring%EF%BC%88%E5%9B%9B%EF%BC%89%EF%BC%9AJunit%E6%B5%8B%E8%AF%95%2F</url>
    <content type="text"><![CDATA[跟着博客开始学怎么用Junit对写出的部分代码进行单元测试。 实例跟着它给的代码： @RunWith(SpringJUnit4ClassRunner.class) @SpringBootTest(classes=MockServletContext.class) @WebAppConfiguration public class DemoApplicationTests { private MockMvc mvc; @Before public void Setup() throws Exception { mvc = MockMvcBuilders.standaloneSetup(new exampleController()).build(); } @Test public void contextLoads() throws Exception{ mvc.perform(MockMvcRequestBuilders.get(&quot;/&quot;).accept(MediaType.APPLICATION_JSON)) .andExpect(status().isOk()) .andExpect(content().string(equalTo(&quot;index&quot;))).andDo(print()); } } 但是很奇怪的是一直在 .andExpect(content().string(equalTo(&quot;index&quot;))).andDo(print()); 这个部分报错，说The method content()/equalTo() is ambiguous for the type DemoApplicationTests 结果我发现在我直接敲入这段代码时候，eclipse会直接帮忙自动导入对应的包： import static org.hamcrest.CoreMatchers.equalTo; import static org.hamcrest.Matchers.equalTo; import static org.springframework.test.web.client.match.MockRestRequestMatchers.content; import static org.springframework.test.web.servlet.result.MockMvcResultMatchers.content; 里面会有不同包里面的同名称的类文件，在这里我们选用： import static org.hamcrest.Matchers.equalTo; import static org.springframework.test.web.servlet.result.MockMvcResultMatchers.content; 讲解初始化MockMvcBuilders这个是用来构造MockMvc的构造器，主要是有两种实现，分别是StandaloneMockMvcBuilder和DefaultMockMvcBuilder一种是独立安装和集成Web环境测试（此种方式并不会集成真正的web环境，而是通过相应的Mock API进行模拟测试，无须启动服务器）。 较新版的Spring Boot取消了@SpringApplicationConfiguration这个注解，用@SpringBootTest就可以了 集成web环境测试MockMvcBuilders.webAppContextSetup(WebAppContext webAppContext):指定的webAPPContext会从上下文中去获取相应的控制器并得到相应的MockMvc 怎么获取呢？所以就在测试的程序前面加上@ContextConfiguration(classes = xxx.class)（xxx.class是自己定义的配置类，继承WebMvcConfigurerAdapter 这个类的类，新版spring boot不用继承这类再去使用了，会报错，它改成直接用接口形式implements这个类，并且去使用，还有一个方法来着去使用这个类，但是我忘了，可以直接谷歌一下，WebMvcConfigurerAdapter配置类其实是Spring内部的一种配置方式，采用JavaBean的形式来代替传统的xml配置文件形式进行针对框架个性化定制，它是对需要进行拦截的地方是要使用的拦截器配好对）。 （拦截器是什么：拦截器相当于把一部分会需要经常改动的代码提取出来，然后对一些固有操作执行前进行拦截，去运行在不同情况下需要运行的代码。减少代码的冗余度，提高重用率。也就是AOP的一种运用。） 如果没有@ContextConfiguration是会报错的。 @WebAppConfiguration：测试环境使用，用来表示测试环境使用的ApplicationContext将是WebApplicationContext类型的；value指定web应用的根； @Autowired WebApplicationContext wac:注入web环境的applicationContext容器； 然后通过MockMvcBuilders.webAppContextSetup(this.wac).build();创建一个MockMvc去测试。 独立测试方式这个MockMvcBuilders.standaloneSetup(Object… controllers)可以通过参数去指定一组或者一个控制器，而不需要上下文获取了。 只需两个步骤：创建相应的控制器，然后注入相应的依赖；通过MockMvcBuilders.standaloneSetup(Object… controllers).bulid()去获取一个MockMvc去测试。 RequestBuilderRequestBuilder这个是用来存放模拟输入的命令的。比如在这里我要测试控制层的输出结果是不是我想要的，然后我会用RequestBuilder.get/post/put…(/网址/).param()…这样去模拟数据输入，进而测试程序有没有错误。 request = get(&quot;/users/&quot;); RequestBuilder执行完这一步之后，里面会存放如下参数： 可以从图中看到里面有我刚开始设置进去的网址”/users”,然后其他值设置之类地方都是显示null，或者[]或者{}。 关于content().string(equalTo(xxx))跟着敲完对控制层的测试类之后，一直报错，我debug发现，不是程序里面的问题，是我参数出的问题。 我里面的参数不是少了对字符串的外标的双引号，就是字符串的排列顺序不对 我设置的返回值是对User实例化后的字符串的值的返回 public class User { private String name; private long id; private Integer age; } 里面按照顺序需要：name 、 id 、 age这个顺序返回值，然后碰到字符串时候，需要上标双引号，但是因为本身我就是设置它需要根据我给出的字符串去比较是不是我想要的结果，所以在content().string(equalTo(xxx))里面，xxx这个字符串中的双引号需要转义字符：\” content().string(equalTo(&quot;[{\&quot;name\&quot;:\&quot;nana\&quot;,\&quot;id\&quot;:1,\&quot;age\&quot;:12}]&quot;))).andDo(print()) 测试部分perform：执行一个RequestBuilder请求，会自动执行SpringMVC的流程并映射到相应的控制器执行处理； andExpect：添加ResultMatcher验证规则，验证控制器执行完成后结果是否正确； andDo：添加ResultHandler结果处理器，比如调试时打印结果到控制台； andReturn：最后返回相应的MvcResult；然后进行自定义验证/进行下一步的异步处理； accept：接收的返回的信息格式，这里是接收的是json类型数据。 ContentResultMatchers content()：得到响应内容验证器； 参考资料关于拦截器讲解比较详细的博客 关于测试部分讲解详细的博客]]></content>
      <categories>
        <category>spring相关</category>
        <category>Junit测试</category>
      </categories>
      <tags>
        <tag>spring相关</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[开始学习spring（三）：注解2]]></title>
    <url>%2F2019%2F04%2F08%2F%E5%BC%80%E5%A7%8B%E5%AD%A6%E4%B9%A0spring%EF%BC%88%E4%B8%89%EF%BC%89%EF%BC%9A%E6%B3%A8%E8%A7%A32%2F</url>
    <content type="text"><![CDATA[虽然明白注解是怎么一回事了，但是还是好奇它的反射机制是怎么实现的，所以谷歌了一下，之后可能会试着自己看看源码。 注：在 Spring 中，构成应用程序主干并由Spring IoC容器管理的对象称为bean。bean是一个由Spring IoC容器实例化、组装和管理的对象。 关于IoC(控制反转) RequestMapping这个是用来处理请求地址映射的注解，它的注解有六个属性： valuevalue：指定请求的实际地址 method： 指定请求的method类型， GET、POST、PUT、DELETE等； consumes：指定处理请求的提交内容类型（Content-Type），例如application/json, text/html; produces: 指定返回的内容类型，仅当request请求头中的(Accept)类型中包含该指定类型才返回； params： 指定request中必须包含某些参数值是，才让该方法处理。 headers： 指定request中必须包含某些指定的header值，才能让该方法处理请求。 Service对服务类进行注解标记，让@componentScan将这些类装载注入到Spring的bean容器中，或者如果没有@ComponentScan这个注解的话，spring会自动去扫描Application这个类所在的包列表下面的类，如果含有@Service标注，那么被看做是服务类被装入spring的bean容器里面。 Repository@Repository标记该类为数据层，Dao层。 Controller@Controller层用于标记该类为控制层。 Autowired———————-摘自博客等我用了一遍再回来补充。 @ResponseStatus@ResponseStatus这个注解是做异常处理的，然后可以自定义异常。当我们的Controller抛出异常，并且没有被处理的时候，他将返回HTTP STATUS 为指定值的 HTTP RESPONSE.]]></content>
      <categories>
        <category>spring相关</category>
        <category>注解</category>
        <category>spring注解</category>
      </categories>
      <tags>
        <tag>spring相关</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[开始学习spring（三）：注解]]></title>
    <url>%2F2019%2F04%2F04%2F%E5%BC%80%E5%A7%8B%E5%AD%A6%E4%B9%A0spring%EF%BC%88%E4%B8%89%EF%BC%89%EF%BC%9A%E6%B3%A8%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[因为spring Boot项目里面一直要用到注解，所以我特地开了一篇文章来介绍元注解和自定义注解。关于@ResponseMapping这类经常用到的注解可能会零开一篇去写。 现有的spring提供了大量的注解，而且点进去会发现它的源码很短，注解中用到的Annotations元注解其实只是元数据，和业务逻辑一点关系都没有，既然和业务逻辑没有关系，那么就必须有人来实现这些逻辑。Annotations仅仅提供它定义的属性(类/方法/包/域)的信息. 当我们使用Java的标注Annotations(例如@Override)时，JVM就是一个用户，它在字节码层面工作。 bean 是组件的意思。 元注解一共有以下个元注解 @Document @Target @Retention @Inherited @Target它是用来约束注解的使用范围的，可以用ElementType类型去给它定义使用范围，一下是它的源代码： public enum ElementType { /** Class, interface (including annotation type), or enum declaration */ TYPE, /** Field declaration (includes enum constants) */ FIELD, /** Method declaration */ METHOD, /** Formal parameter declaration */ PARAMETER, /** Constructor declaration */ CONSTRUCTOR, /** Local variable declaration */ LOCAL_VARIABLE, /** 用于另外一个注解上 */ ANNOTATION_TYPE, /** Package declaration */ PACKAGE, /** * Type parameter declaration * * @since 1.8 */ TYPE_PARAMETER, /** * Use of a type * * @since 1.8 */ TYPE_USE } 如果这个注解中@Target没有被申明，那么意思是它可以被应用在任何元素之上。 @Retention这个元注解是用来约束注解的生命周期的。里面有三个状态，一个是源码级别（source）、一个是类文件级别（class）、还一个是运行时级别（runtime） source ： 注解将被编译器丢弃（这个类型的注解信息只保留在源码里面，源码经过编译后，注解信息会被丢弃，不会保留在编译好的class里面。）如java内置注解：@Override、@SuppressWarnning等 class ： 注解在class文件里可用，但是会被vm（虚拟机）抛弃（这个类型的注解信息只会保存在源码里面和class文件里面，在运行时候，不会载入虚拟机里面），当注解没有定义Retention的时候，会默认是class，如java内置注解： runtime ： 注解信息将在运行期（JVM）中也保留，因此可以通过反射机制读取注解的信息。（源码、class文件和虚拟机中都有注解的信息。）如SpringMvc中的@Controller、@Autowired、@RequestMapping等，如java内置注解：@Deprecated(用于标明已经过时的方法或类)等。 @Documented@Documented 被修饰的注解会生成到javadoc中 @Inherited可以让注解被继承，但这并不是真的继承，只是通过使用@Inherited，可以让子类Class对象使用getAnnotations()获取父类被@Inherited修饰的注解。 关于自定义注解里面的一些语句String name() default &quot;&quot;;//指定义了name这个属性，默认是空字符串。 声明注解类型时候，不能用包装类型，只能用基本类型去声明 @Target({ElementType.TYPE}) @Retention(RetentionPolicy.RUNTIME) @Documented @Component public @interface Controller { @AliasFor(annotation = Component.class) String value() default &quot;&quot;; } 因为上面除掉元注解外还有@component，说明@controller这个注解属于@component这个注解 我们定义了自己的注解并将其应用在业务逻辑的方法上。所以就需要我们写一个用户程序调用我们的注解。这里需要使用反射机制。 参考资料我觉得写得很详细的 注解是什么]]></content>
      <categories>
        <category>spring相关</category>
        <category>注解</category>
        <category>注解大体简介</category>
      </categories>
      <tags>
        <tag>spring相关</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二分排序法]]></title>
    <url>%2F2019%2F04%2F03%2F%E4%BA%8C%E5%88%86%E6%8E%92%E5%BA%8F%E6%B3%95%2F</url>
    <content type="text"><![CDATA[这是很久前写的一篇博文，现在转移了地址，就一起把这篇博文转过来。 二分排序法书上的讲解用的是借抓扑克牌这个模式讲的 二分法排序public class B { public void BinarySort(int[] a) { for (int i = 1; i &lt; a.length; i++) { int tmp = a[i]; int left = 0; int right = i - 1; while (left &lt;= right) { int mid = (right + left)&gt;&gt;1; if (a[mid] &gt; tmp) { right = mid - 1; } else { left = mid + 1; } } for (int j = i - 1; j &gt;= left; j--) { a[j + 1] = a[j]; } a[left] = tmp; } } } public class test { public static void main(String[] args) { int[] a= {1,24,5,6,3,2,7,8,2}; B b=new B(); b.BinarySort(a); for(int i=0;i&lt;a.length;i++){ System.out.println(a[i]);} } } 就是先从低位开始排序，从i=1开始大循环，从已经排好序的left和right中折中取中间数，然后再和还未排序的数字进行比较大小，如果是大于中间数的话那么更改left指向位置（指向中间数后一个数据），依次循环，如果right小于left的话终止比较（这样就不会忘记把right指向的数据和需要排序的数据进行比较）。接着就插入，像插入排序那样进行数据交换，把这个未排序的数字插入该插入的地方。 ps:求left和right之间的mid的等式是：（left+right）&gt;&gt;1！]]></content>
      <categories>
        <category>算法</category>
        <category>二分排序法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MavenInstall错误类型（一）]]></title>
    <url>%2F2019%2F04%2F03%2FMavenInstall%E9%94%99%E8%AF%AF%E7%B1%BB%E5%9E%8B%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[工具：STS 在Maven Install加载pom.xml里面添加的依赖时候，结果出了错误：Failed to execute goal org.apache.maven.plugins:maven-surefire-plugin:2.22.1 我百度了一会，各种方法都试过，却没有用，结果发现是我之前点击Spring Boot App这里让这个项目运行起来了，但是却没有关闭，然后再点击Maven Install，所以报错了。]]></content>
      <categories>
        <category>运行error</category>
        <category>Maven Install错误类型：Failed to execute goal org.apache.maven.plugins:maven-surefire-plugin:2.22.1</category>
      </categories>
      <tags>
        <tag>Maven Install error</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[开始学习spring（二）：试图搭建一个相关项目]]></title>
    <url>%2F2019%2F04%2F02%2F%E5%BC%80%E5%A7%8B%E5%AD%A6%E4%B9%A0spring%EF%BC%88%E4%BA%8C%EF%BC%89%EF%BC%9A%E8%AF%95%E5%9B%BE%E6%90%AD%E5%BB%BA%E4%B8%80%E4%B8%AA%E7%9B%B8%E5%85%B3%E9%A1%B9%E7%9B%AE%2F</url>
    <content type="text"><![CDATA[看了很多东西，但是概念太多了，脑壳痛，所以先搭一个spring Boot的项目，运行一下，再深入学习一下。在别人推荐下我用的是STS（Spring Tool Suite）去搭建的这个项目。 新建项目 在新建-&gt;project里面的弹出框选择Spring Starter Project去新建一个project。 然后我箭头指的地方是我做过些许改动的地方，接着点击Next。 再在红色框框框住的地方选择自己想要的插件，这样maven会自动在pom.xml里面自动填写相关代码去下载需要的配件的安装包，最后点击Finish，就完成了新建spring Boot的任务。 添加代码让项目成功运行在src/main/java下面新建一个类，命名为xxxcontroller.java，然后在这个类里面写上如下代码： @Controller public class exampleControl { @RequestMapping(&quot;/&quot;) public String Index(Locale locale, Model model) { Date date = new Date(); DateFormat dateFormat = DateFormat.getDateTimeInstance(DateFormat.LONG, DateFormat.LONG, locale); String formatDate = dateFormat.format(date); model.addAttribute(&quot;serverTime&quot;,formatDate); return &quot;Index&quot;; } 然后再在src/main/resources/templates里面新建一个HTML文件：index.html &lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;Insert title here&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h3&gt;Spring Boot and Spring MVC&lt;/h3&gt; &lt;P th:text=&quot;&#39;The time on the server is &#39; + ${serverTime}&quot;&gt;&lt;/P&gt; &lt;/body&gt; &lt;/html&gt; 接着得记住去原项目根目录下的pom.xml里面添上这样一行: &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt; &lt;/dependency&gt; Thymeleaf是一个XML/XHTML/HTML5模板引擎，用来渲染页面的。Thymeleaf的主要目标在于提供一种可被浏览器正确显示的、格式良好的模板创建方式，因此也可以用作静态建模。之后就才显示 不然会显示： 在正在运行时的状态下，修改代码是不会直接反馈到浏览器上显示的，所以得停止运行，再重启。 运行后出现page no find默认情况下spring boot只会扫描启动类当前包和以下的包，在如果配置正确，但是还是没有运行出现自己想要的界面的情况下，可能有原因是在Application.class这个类扫描时候没有扫描到你的controller控制类，所以你可以在你的Application.class这个类里面@SpringBootApplication下面加上@componentscan(controller所在的包。) @SpringBootApplication@componentscan(basePackages = “com.didispace.*”) 关于该项目用到的注解@Controller根据代码中给出的解释就是，带了这个注释的类就是控制器，允许通过类路径扫描自动检测实现类，通常与@ResponseMapping这类注释结合使用。 我刚刚谷歌了一下这方面的知识，用@Controller其实大部分是用来返回字符串，或者是字符串匹配的模板名称，即直接渲染视图，和HTML结合使用的，但是这个前提前后端配合度要高。（单用@Controller并且不做别的处理的话，返回的字符串没有对应的HTML页面的话，就会报错，出现Whitelabel Error Page这个页面） 在@Controller这个注解里面的@AliasFor@Retention(RetentionPolicy.RUNTIME) @Target(ElementType.METHOD) @Documented public @interface AliasFor { /** * Alias for {@link #attribute}. * &lt;p&gt;Intended to be used instead of {@link #attribute} when {@link #annotation} * is not declared &amp;mdash; for example: {@code @AliasFor(&quot;value&quot;)} instead of * {@code @AliasFor(attribute = &quot;value&quot;)}. */ @AliasFor(&quot;attribute&quot;) String value() default &quot;&quot;; /** * The name of the attribute that &lt;em&gt;this&lt;/em&gt; attribute is an alias for. * @see #value */ @AliasFor(&quot;value&quot;) String attribute() default &quot;&quot;;} 就相当于value的用法和attribute的用法是一样的，值也是一样的，在这里来给注解的属性起别名，使它们互为别名，意义相同 返回字符串对应的html@Controller public class exampleControl { @RequestMapping(&quot;/&quot;) public String Index(Locale locale, Model model) { Date date = new Date(); DateFormat dateFormat = DateFormat.getDateTimeInstance(DateFormat.LONG, DateFormat.LONG, locale); String formatDate = dateFormat.format(date); model.addAttribute(&quot;serverTime&quot;,formatDate); return &quot;index&quot;; } } 返回json格式数据如果想用@Controller这个注释可以返回json的话，就要在返回json的方法前面加上@ResponseBody，这样就会在浏览器页面输出json的格式。 user类： public class User { private String name; public void setName(String name) { this.name = name; } public String getName() { return this.name; } } controller层： @Controller public class exampleControl { @RequestMapping(&quot;/&quot;) @ResponseBody public User userTest() { User user = new User(); user.setName(&quot;haha&quot;); return user; } } @RestController这个注解和@Controller不一样，是由@Controller和@ResponseBody合在一起的，返回的是一个对象（字符串也可，json格式数据也可等等），其实和@Controller放在类上面，然后在需要返回json格式数据的方法上面加一个@ResponseBody的效果一样，只是一个是整体，一个是局部。（这个可以返回Restful风格—-我也不知道什么风格，但是看到还要配置才能用，所以等以后用到了再来补吧。） 结果输出 参考资料关于@Controller和@RestController关于spring boot的学习]]></content>
      <categories>
        <category>spring相关</category>
        <category>搭建项目（初级）</category>
      </categories>
      <tags>
        <tag>spring相关</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[开始学习spring（一）：关于一些基础知识点]]></title>
    <url>%2F2019%2F04%2F02%2F%E5%BC%80%E5%A7%8B%E5%AD%A6%E4%B9%A0spring%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9A%E5%85%B3%E4%BA%8E%E4%B8%80%E4%BA%9B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E7%82%B9%2F</url>
    <content type="text"><![CDATA[现在正式开始学spring了，在此打卡（4.2） 什么是POJOsPOJO, or Plain Old Java Object, is a normal Java object class (that is, not a JavaBean, EntityBean etc.) POJO（plain Old Java Object）它是一个正规的、简单的java对象，包含了业务逻辑处理和持久化逻辑等，但不是JavaBean、EntityBean等，不具有任何特殊角色和不继承不实现任何其他java框架的类或接口。 POJO里面是可以包含业务逻辑处理和持久化逻辑，也可以包含类似与JavaBean属性和对属性访问的set和get方法的。 代码示例： package com.demo.spring; public class DbHello { //简单的Java类，称之为POJO，不继承，不实现接口 private DictionaryDAO dao; public void setDao(DictionaryDAO dao) { this.dao = dao; } } 什么是javabean一种特殊又简单的类， 这个类必须具有一个公共的(public)无参构造函数； 所有属性私有化（private）； 私有化的属性必须通过public类型的方法（getter和setter）暴露给其他程序，并且方法的命名也必须遵循一定的命名规范。 这个类应是可序列化的。（比如可以实现Serializable 接口，用于实现bean的持久性） EJB是什么Enterprise JavaBean又叫企业级JavaBean(听说很老了，以后如果用到的话再回来补。) 依赖注入（DI）就是减少依赖。里面牵涉到了依赖倒置（IoC）（这个和设计模式相关，我会找个时间把设计模式的笔记补上。） 参考资料关于POJOs关于javabean]]></content>
      <categories>
        <category>spring相关</category>
        <category>基础指示点</category>
      </categories>
      <tags>
        <tag>spring相关</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo博客上传图片]]></title>
    <url>%2F2019%2F03%2F29%2Fhexo%E5%8D%9A%E5%AE%A2%E4%B8%8A%E4%BC%A0%E5%9B%BE%E7%89%87%2F</url>
    <content type="text"><![CDATA[因为之前用插件在本地导入图片到博客上这个方法因为别的缘故，不能很稳定的让图片插入进去……这就要从我开始装数学公式的插件说起了，反正我不想再折腾了，听说本地导入图片的方法也会导致项目过大然后会受github项目仓库的限制，所以我干脆卸载了本地导入图片的这个插件，换成了用七牛云去在线导入图片。当然这个过程不太顺畅。特此记录一下。 准备工作去七牛云注册了一个账号（前不久他们特地打电话过来关怀一下注册了账号就不见人影的我，我还嘚瑟的和他们说我不用你们的产品，真香） 然后百度教程 开始下载插件 npm install hexo-qiniu-sync --save 然后去！！！！hexo下面的_config.yml里面加上qiniu的配置！！！！是hexo下面不是next下面 #plugins: #- hexo-qiniu-sync（这部分要删掉的，不然会报错） qiniu: offline: false sync: true bucket: bucket_name # 你在七牛上面设置的存储图片的存储空间的名字 access_key: AccessKey # 你在七牛上面账号的密钥管理的key secret_key: SecretKey # 你在七牛上面账号的密钥管理的key dirPrefix: static #自动在你七牛的那个存储空间里面新建一个这个文件夹，听说是加个文件夹比较好 urlPrefix: http://7xqb0u.com1.z0.glb.clouddn.com/static local_dir: xxx # 当你hexo qiniu s时候，这个文件夹的东西会自动上传到你七牛云里头创建的static文件夹里面。 update_exist: true image: folder: images extend: js: folder: js css: folder: css 好了，其他详细的说明下面有指路辽== 插入图片我用的是 {% qnimg xxx.png %} 这种语法，其他的我不想看辽，目前也用不到。 上传图片到七牛云先去博客本地生成的存图的文件夹（上面有注解），然后博客文里面对它进行引用。然后上传图片去七牛云本地时候，就用： hexo qiniu s 这个语法即可。 参考资料我觉得很详细的教程]]></content>
      <categories>
        <category>hexo更新配置</category>
        <category>hexo插入图片</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[为Next主题添加统计阅读量的功能以及开评论]]></title>
    <url>%2F2019%2F03%2F29%2F%E4%B8%BANext%E4%B8%BB%E9%A2%98%E6%B7%BB%E5%8A%A0%E7%BB%9F%E8%AE%A1%E9%98%85%E8%AF%BB%E9%87%8F%E7%9A%84%E5%8A%9F%E8%83%BD%E4%BB%A5%E5%8F%8A%E5%BC%80%E8%AF%84%E8%AE%BA%2F</url>
    <content type="text"><![CDATA[需要准备工作我先在leancloud注册了一个账号，用来统计阅读量和去Next主题里设置开放评论用。 具体步骤开放评论注册完这个账号，然后创建项目（企业开发的话要钱，所以选择个人开发）。接着去Next主题里面设置 valine: enable: true appid: # your leancloud application appid你点进你leancloud账号里新建的项目里面，然后点进设置，会看到项目自动生成的appid，然后复制过来 appkey: # your leancloud application appkey它的位置就在appid下面一行 notify: false # mail notifier , https://github.com/xCss/Valine/wiki通知 verify: false # Verification code验证码（评论前要输入的） placeholder: Just go go # comment box placeholder评论框提示你输入的话语 avatar: mm # gravatar style默认头像 guest_info: nick,mail # custom comment header评论前要输入的信息 pageSize: 10 # pagination size一页默认展示的评论数 然后就能开评论了，因为我刚开始设置输入错了appid和appkey，出现了402错误（反正会提示你哪错了，就不做解释辽。） 给评论加上邮件通知这个是跟着这个博客的方法来的，虽然之前的博客教我怎么用leancloud自带的邮件通知功能去提醒别人评论已回复，但是说是因为是正在开发的功能，还不太稳定，同时还会被要求开验证码，觉得很不方便，所以我换了个博客跟着用第三方的邮件提醒功能。 因为过程有些繁琐，我也只是跟着它的方法来的，所以就只在这放个链接好了。这是个开源项目。 添加统计阅读量功能在你新建的项目的存储里面，新建一个叫Counter的class，ACL权限选择无限制，里面的appid和appkey和上面获取的是一样的，在这里就不讲是怎么去获取的了。 # Show number of visitors to each article. # You can visit https://leancloud.cn get AppID and AppKey. leancloud_visitors: enable: true app_id: #AppID app_key: #AppKey 参考资料参考博客(添加统计阅读量功能) 参考博客(添加统计阅读量功能) 参考博客(让博客支持评论功能) 第三方邮件回复自带定时器]]></content>
      <categories>
        <category>hexo更新配置</category>
        <category>添加统计阅读量以及打开评论</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[bitSet源码解读]]></title>
    <url>%2F2019%2F03%2F14%2FbitSet%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB%2F</url>
    <content type="text"><![CDATA[因为最近在看二维码相关，在github上拉下来的代码里面有用到bitSet库，所以在试着看源码。看了一段时间，发现就算理清了逻辑结构也不明白什么意思，所以就去网上查了一下bitSet是做什么的。 都说bitSet是用来对大量的数据进行整理，减少内存负担（我是这样理解的），bitSet是用长整型对数据进行存储，比起用二进制用int对数据进行存储的方法相比，确实可以减少许多内存【这里对内存概念不是很清楚，日后补全。 部分源码分析定义好的关键词(大概可以这样叫)/* * bitSet被打包为字的数组 * word的大小选择完全取决于它的性能 */ private final static int ADDRESS_BITS_PER_WORD = 6; private final static int BITS_PER_WORD = 1 &lt;&lt; ADDRESS_BITS_PER_WORD; private final static int BIT_INDEX_MASK = BITS_PER_WORD - 1; /* Used to shift left or right for a partial word mask */ private static final long WORD_MASK = 0xffffffffffffffffL; 这是该方法中定义的参数，其中ADDRESS_BITS_PER_WORD=6是指在java中long型是占8个字节，64bit（$\,2^{6}\,=\,64byte\,$）所以对应的二进制就是6. private long[] words; private transient int wordsInUse = 0;//已使用的范围的下标 private transient boolean sizeIsSticky = false;//表示用户是使用默认的words的大小(64bit)还是自定义 关于wordIndex的定义这里是bit下标对应的word下标的计算过程： private static int wordIndex(int bitIndex) { return bitIndex &gt;&gt; ADDRESS_BITS_PER_WORD; } bitSet的构造函数(里面有对words这个数组的定义)其中，bitSet的构造函数是： public BitSet(int nbits) { // nbits can&#39;t be negative; size 0 is OK if (nbits &lt; 0) throw new NegativeArraySizeException(&quot;nbits &lt; 0: &quot; + nbits); initWords(nbits); sizeIsSticky = true; } private void initWords(int nbits) { words = new long[wordIndex(nbits-1) + 1]; } 这是在初始化时候给bitSet中的long[] words分配大小时候，就会调用这个构造函数，但是如果初始化时候去输入long[] 这个数组的话，相当于直接定义long[] words这个数组。 private BitSet(long[] words) { this.words = words; this.wordsInUse = words.length;//这里wordsInUse表示的是定义的数组的长度，如果没有定义长度的话，那么这个值默认为零。 checkInvariants(); } 然后还有无参构造，这个就是用默认的数组大小64bit public BitSet() { initWords(BITS_PER_WORD); sizeIsSticky = false; } bitSet的clear方法(对words这个数组进行清零)其中wordsInUse在源码中出现频率非常高，这个参数是用来记录word数组中已经使用了的个数。 public void clear(int bitIndex) { if (bitIndex &lt; 0) throw new IndexOutOfBoundsException(&quot;bitIndex &lt; 0: &quot; + bitIndex); int wordIndex = wordIndex(bitIndex);//计算这个bit下标实际上是第几个word(Long) if (wordIndex &gt;= wordsInUse) //如果这个下标不在wordsInUse范围内，那么返回，因为没有必要进行别的操作了。 return; words[wordIndex] &amp;= ~(1L &lt;&lt; bitIndex); //把words[wordIndex]中的值设置为false（就是清零）因为&lt;&lt;这是左移。取反后就全是零了，再进行与运算，就相当于设置该bitIndex这个位为false，也就是将该位清零。 recalculateWordsInUse(); checkInvariants(); } 关于和clear对应的set方法(对words这个数组进行赋值)这是set函数，就是把bitIndex的对应的位置设置为true，然后返回设置了true的地方的下标： public void set(int bitIndex) { if (bitIndex &lt; 0) throw new IndexOutOfBoundsException(&quot;bitIndex &lt; 0: &quot; + bitIndex); int wordIndex = wordIndex(bitIndex); expandTo(wordIndex);//判断是否需要扩容，如果需要，则进行扩容 words[wordIndex] |= (1L &lt;&lt; bitIndex); // 把这个bitIndex位设置为true checkInvariants(); } 关于clear每次最后都要用到的recalculateWordsInUse()方法更新wordsInUse，判断实际存储大小。 private void recalculateWordsInUse() { //遍历words这个数组，直到找到一个是true的地方 int i; for (i = wordsInUse-1; i &gt;= 0; i--) if (words[i] != 0) break; wordsInUse = i+1; // 就是让wordsInUse的大小更改为实际单词存储量 } clear和set方法中都会出现的checkInvariants()方法判断这个word数组是否溢出，是否需要抛出异常。 private void checkInvariants() { assert(wordsInUse == 0 || words[wordsInUse - 1] != 0); assert(wordsInUse &gt;= 0 &amp;&amp; wordsInUse &lt;= words.length); assert(wordsInUse == words.length || words[wordsInUse] == 0); } 克隆方法clone()public Object clone() { if (! sizeIsSticky) trimToSize(); try { BitSet result = (BitSet) super.clone(); result.words = words.clone(); result.checkInvariants(); return result; } catch (CloneNotSupportedException e) { throw new InternalError(e); } } 参考深克隆和浅克隆 trimToSize()方法当word的长度或者内容是自定义的情况下则调用的 private void trimToSize() { if (wordsInUse != words.length) { words = Arrays.copyOf(words, wordsInUse);//把实际用的数据拷贝出来放进words里面 checkInvariants(); } } get()方法public boolean get(int bitIndex) { if (bitIndex &lt; 0) throw new IndexOutOfBoundsException(&quot;bitIndex &lt; 0: &quot; + bitIndex); checkInvariants(); int wordIndex = wordIndex(bitIndex); return (wordIndex &lt; wordsInUse) &amp;&amp; ((words[wordIndex] &amp; (1L &lt;&lt; bitIndex)) != 0);//判断数据是否是在使用范围内，该bitIndex位是否为0. } 就是前面的先是判断下标是否在存储完数据使用过的范围内，如果不在就无效。再判断bitIndex对应的数据位是否是零，如果都是的话返回true。 参考网站对bitSet内存存储方法进行详细介绍，但其他的写的不太明了 举例说明了bitSet的用法，内容详细 对bitSet源码中的重要方法进行解读 简要介绍了bitSet里面的类]]></content>
      <categories>
        <category>java语法</category>
        <category>bitSet部分源码解读</category>
      </categories>
      <tags>
        <tag>java语法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java的~、|、、>>>、^]]></title>
    <url>%2F2019%2F03%2F14%2Fjava%E7%9A%84%2F</url>
    <content type="text"><![CDATA[在看BitSet的源码的时候，我看到了这样一段代码 words[wordIndex] &amp;= ~(1L &lt;&lt; bitIndex); 其中~(1L&lt;&lt;bitIndex)我不太明白这是什么意思，所以谷歌了一下,就顺便查了一下日常容易被我弄错的逻辑运算符的用法。 其中 ~：是按位取反运算符 如：~(10010010)=01101101 所以这句的意思是在1L左移bitIndex位后，对words[wordIndex]这个第一个bit的位清零 容易混淆的逻辑运算符顺便解释一下|这个的意思 |：这个是按位或运算 &gt;&gt; 是带符号右移，若左操作数是正数，则高位补“0”，若左操作数是负数，则高位补“1”. &lt;&lt; 左移，不管正负数左移时候，最高位都不用管，只需要在后面补零就可以了，和&lt;&lt;&lt;不带符号左移一样，所以就没有不带符号左移 &gt;&gt;&gt; 是无符号右移，无论左操作数是正数还是负数，在高位都补“0” 计算机都是用补码存储数据的。所以当一个数带符号右移或者左移，就是单纯的对该数进行除乘。 所以在带符号右移或者左移时候，为了保证数字在这个安全的距离能够得出想要的正确结果（乘除2的标准结果），所以int设置的可活动的位移是32，就是左右移32位时候，就会恢复数字的原本值，long设置的可活动位移是64. emmmm感觉我语言讲述的不是很清楚，所以附上例子把。 public class test { public static void main(String[] args) { long a=-5; System.out.println((a &lt;&lt; 64)); // output: -5 } } 这是long的情况，接下来我放int的例子： public class test { public static void main(String[] args) { int a=-5; System.out.println((a &lt;&lt; 32)); // output: -5 } } 恩，就是这样，我是这样理解的。 关于^^这个是异或运算符。 参考资料位移参考]]></content>
      <categories>
        <category>java语法</category>
        <category>java中的&quot;~&quot;</category>
      </categories>
      <tags>
        <tag>java语法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[eclipse找不到源码]]></title>
    <url>%2F2019%2F03%2F13%2Feclipse%E6%89%BE%E4%B8%8D%E5%88%B0%E6%BA%90%E7%A0%81%2F</url>
    <content type="text"><![CDATA[想看看bitSet的源码，但是点进去却显示Source Not Found 点windows—&gt;preference—&gt;java进入如下界面： 然后用鼠标点击jre一下，使旁边的Edit获得焦点，然后点击Edit，进入如下界面： 最后选中jdk中的src.zip,点击确定，应用即可]]></content>
      <categories>
        <category>eclipse故障</category>
        <category>eclipse点进方法找不到源码</category>
      </categories>
      <tags>
        <tag>eclipse故障</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[对于QR生成的java源码学习(一):关于java语法内容]]></title>
    <url>%2F2019%2F03%2F11%2F%E5%AF%B9%E4%BA%8EQR%E7%94%9F%E6%88%90%E7%9A%84%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[java的一些基本语法在这里，然后QR生成的源码结构非常清晰，值得一读，所以在这里会零零散散记录一些关于源码里面的一些语法的笔记。 Object 与 Objects 的区别Object 是 Java 中所有类的基类，位于java.lang包。 Objects 是 Object 的工具类，位于java.util包。它从jdk1.7开始才出现，被final修饰不能被继承，拥有私有的构造函数。它由一些静态的实用方法组成，这些方法是null-save（空指针安全的）或null-tolerant（容忍空指针的），用于计算对象的hashcode、返回对象的字符串表示形式、比较两个对象。 Objects.requireNonNull(text); 其中源码是这样写的： public static &lt;T&gt; T requireNonNull(T obj) T：obj的相关类型 obj：要检查是否为空的参数 return：如果obj不为空就返回obj，如果是空就返回NullPointerException（空指针异常） 关于Matcher源码是这样的： NUMERIC_REGEX.matcher(text).matches() 先把text创建一个匹配此模式的给定输入的匹配器。返回的值再去与NUMERIC_REGEX这个模式(源码中定义的final字段)进行匹配 public Matcher matcher(CharSequence input) Pattern.matcher(CharSequence input) input：需要被转换为匹配模式的字符串 return：返回这个Pattern的新匹配器 public boolean matches() return：当且仅当整个区域序列匹配此匹配器的模式时才返回true bitSet一个long长64bit，所以 private final static int ADDRESS_BITS_PER_WORD = 6; private static int wordIndex(int bitIndex) { return bitIndex &gt;&gt; ADDRESS_BITS_PER_WORD; } 其中是在计算bitIndex个bit对应的是第几个long assertassert()对括号中的条件进行判定，如果条件为真则往下继续运行，条件为假则打印完错误信息然后程序停止运行。 nativenative是c++开发时候用的，java开发是不用它的，它是用来调用操作系统的一些函数的，然而操作系统的函数就是由c++写的，是没有办法看到它的源码的，java对它只能进行调用。是因为这些函数的实现体在DLL中，JDK的源代码中并不包含。 因为native是底层实现的，所以它的速度非常快。 cloneable接口和Serializable接口扩展Java语言提供的Cloneable接口和Serializable接口的代码非常简单，它们都是空接口，这种空接口也称为标识接口，标识接口中没有任何方法的定义，其作用是告诉JRE这些接口的实现类是否具有某个功能，如是否支持克隆、是否支持序列化等。——摘自论java中的浅克隆和深克隆 关于序列化序列化简单来说就保存对象在内存中的状态,也可以说是实例化变量。这是Java提供的用来保存 Object state，一种保存对象状态的机制。只有实现了serializable接口的类的对象才能被实例化。——-摘自序列化是什么 然后我谷歌了一会，理解的意思是，序列化就是把实例化的对象状态用二进制保存到一个文件之类的地方，用的时候再取出来。当然，这个接口只是一种申明，说在这里我要实现对某个实例对象进行序列化，而不包含去序列化东西的一个方法，序列化需要自己去实现。在bitSet里面就implement了Serializable这个接口。 或者又如以下的代码： import java.io.*; public class Box implements Serializable{ private int width; private int height; public void setWidth(int width){ this.width = width; } public void setHeight(int height){ this.height = height; } public static void main(String[] args){ Box myBox = new Box(); myBox.setWidth(50); myBox.setHeight(30); try{ FileOutputStream fs = new FileOutputStream(&quot;foo.ser&quot;); ObjectOutputStream os = new ObjectOutputStream(fs); os.writeObject(myBox); os.close(); }catch(Exception ex){ ex.printStackTrace(); } } } 如果去掉implements Serializable的话，那么下面的writeObject会报错。 6、相关注意事项 当一个父类实现序列化，子类自动实现序列化，不需要显式实现Serializable接口； 当一个对象的实例变量引用其他对象，序列化该对象时也把引用对象进行序列化； 并非所有的对象都可以序列化，,至于为什么不可以，有很多原因了,比如： 安全方面的原因，比如一个对象拥有private，public等field，对于一个要传输的对象，比如写到文件，或者进行rmi传输 等等，在序列化进行传输的过程中，这个对象的private等域是不受保护的。 资源分配方面的原因，比如socket，thread类，如果可以序列化，进行传输或者保存，也无法对他们进行重新的资源分 配，而且，也是没有必要这样实现。 关于克隆clone()方法public QrSegment(Mode md, int numCh, BitBuffer data) {//numCh=想在二维码中展示的字的长度。 mode = Objects.requireNonNull(md); Objects.requireNonNull(data); if (numCh &lt; 0) throw new IllegalArgumentException(&quot;Invalid value&quot;); numChars = numCh; this.data = data.clone(); // 做一个完整的副本（final data） } 这个clone()方法因为data是BitBuffer这个类，所以调用了BitBuffer这个类里面写的的clone()方法 public BitBuffer clone() { try { BitBuffer result = (BitBuffer)super.clone();//创建并返回这个对象的一个副本，“副本”的准确含义可能依赖于对象的类。 result.data = (BitSet)result.data.clone();//对BitBuffer这个对象里面成员变量再做一次克隆（到BitSet类中的clone()这个方法去了） return result; } catch (CloneNotSupportedException e) { throw new AssertionError(e); } } 为了进行深度克隆，第一次调用的clone()方法时java的Object这个对象的类的克隆，那个属于浅克隆。这个克隆方法是用来创建并返回这个对象的一个副本，“副本”的准确含义可能依赖于对象的类。 类Object： protected native Object clone() throws CloneNotSupportedException; 浅克隆方法中，如果克隆对象的成员变量是值类型，那么就会把值原原本本复制一份出来，但是如果成员变量是值引用类型，那么复制出来的也会是地址信息，而引用类型的成员对象并没有复制。所以会对引用类型的成员对象再去做一次克隆，让这个复制出来的东西是可以独立于那个克隆对象的东西。 类BitSet： public Object clone() { if (! sizeIsSticky) trimToSize(); try { BitSet result = (BitSet) super.clone(); result.words = words.clone(); result.checkInvariants(); return result; } catch (CloneNotSupportedException e) { throw new InternalError(e); } } 其中result.data指向的是BitSet这个被实例化过一个类，所以去对BitSet data进行了一次克隆，然后data的里面有words的引用，所以再对这个值做一次clone(). 关于在一段数据后循环添加0xEC和0x11这两个数for (int padByte = 0xEC; bb.bitLength() &lt; dataCapacityBits; padByte ^= 0xEC ^ 0x11) bb.appendBits(padByte, 8); 其中0xEC和0x11是8bit8bit循环添加在bb里面的通过padByte ^= 0xEC ^ 0x11异或，来控制每次添加的8bit，先0xEC然后0x11这样去填充数据编码部分，直到值填满（为什么不能16bit一起填进去？如果16bit的话就会导致填到最后悔有溢出的情况。） 关于QrSegment这个类QrSegment这个类被定义后包括的函数 public final Mode mode; /** The length of this segment&#39;s unencoded data. Measured in characters for * numeric/alphanumeric/kanji mode, bytes for byte mode, and 0 for ECI mode. * Always zero or positive. Not the same as the data&#39;s bit length. */ public final int numChars; // The data bits of this segment. Not null. Accessed through getData(). final BitBuffer data; 参考资料关于Object和Objects的区别 关于bitSet的源码解读 关于native的用法 关于序列化的详细说明]]></content>
      <categories>
        <category>对于QR生成的java源码学习</category>
        <category>java语法</category>
      </categories>
      <tags>
        <tag>java语法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python下划线]]></title>
    <url>%2F2019%2F03%2F07%2Fpython%E4%B8%8B%E5%88%92%E7%BA%BF%2F</url>
    <content type="text"><![CDATA[在python中经常会遇到下划线”_”的情况 单下划线”_”就是无关紧要的变量，就用”_”表示，因为这个值不需要再次引用。 也可以表达python REPL中最接近一根表达式的结果。 单前导下划线”_var”这是命名约定，就是前面加一个下划线就是暗示别人说这里是私有类，用通配符导入模块时候这个方法（或者变量）是不会跟着包一起导入进去的，但是常规方法调用这个方法（或者变量时候）是不受单个下划线命名约定的影响的。 单后导下划线”var_”就是让该变量名（或者方法名）来避免和python关键词产生冲突。 双前导下划线”__var”当在类上下文中使用，会触发”名称修饰”，由python解释器强制执行。就是在这个双下划线前面加上”_[包名]” 双前导和双末尾下划线 “var“表示python语言定义的特殊方法。 最好避免在自己的程序中使用以双下划线（“dunders”）开头和结尾的名称，以避免与将来Python语言的变化产生冲突。 参考资料参考网页]]></content>
      <categories>
        <category>python</category>
        <category>下划线</category>
      </categories>
      <tags>
        <tag>python用法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[了解二维码(四)：Reed-Solomon code]]></title>
    <url>%2F2019%2F03%2F05%2FRS-code%2F</url>
    <content type="text"><![CDATA[在前面我们学习了有限域和多项式，可是为什么要学习它们呢，是因为这是像Reed-Solomon这样的纠错码的主要见解：我们不是仅仅将消息视为一系列（ASCII）数字，而是将其视为遵循非常明确的有限域算法规则的多项式. 也就是通过多项式和有限域算法表示数据，我们给数据添加了一个结构，消息的值仍然不变，而且这个结构还能让我们通过它利用定义良好的数学规则对损坏的消息进行修复操作。 与BCH码类似，Reed-Solomon码通过将表示消息的多项式除以不可约的生成多项式来编码，然后余数是RS码，我们将其附加到原始消息。 我们之前曾说过，BCH码和大多数其他纠错码背后的原理是使用一个缩小的词典，其中包含非常不同的词，以便最大化词之间的距离，而更长的词有更大的距离：这里的原理是相同的，首先是因为我们用增加距离的附加符号（余数）来延长原始信息，其次因为余数几乎是唯一的（由于精心设计的不可约生成多项式），因此可以通过巧妙的算法利用它来推导部分原始消息。 总结一下，就像加密一样：我们的生成多项式是我们的编码字典，多项式除法是使用字典（生成多项式）将我们的消息转换为RS代码的运算符。（我们的消息是明文，按多项式除法使用编码字典这个算法而转化为RS代码的运算符） 加密：对原来为明文的文件或者数据按照某种算法进行处理，使之变成一段不可读的代码，这段代码一般被叫做密文。只有在输入对应的密钥之后才能显示出本来内容。 RS生成多项式RS码使用类似于BCH码的方法去生成多项式，生成多项式是$\,\left (x-a^{n} \right)\,$的乘积，在QR码中从$\,n=0\,$开始，例如： $\,g_{4}\, =\, \left (x-\alpha ^{0} \right )\left (x-\alpha ^{1} \right )\left (x-\alpha ^{2} \right )\left (x-\alpha ^{3} \right )= 01 x^{4} + 0f x^{3} + 36 x^{2} + 78 x + 40\,$ 这是一个计算了指定n个纠错符号的RS码需要的生成多项式。 def rs_generator_poly(nsym): g = [1] for i in range(0, nsym): g = gf_poly_mul(g, [1, gf_pow(2, i)]) return g 这个是根据nsym是判断多项式需要nsym个$\,\left (x-a^{n} \right)\,$的乘积 多项式除法除法中 其中除数与商之间的乘法就是用的在有限域中的乘法，如果乘积太大，就mod一个不可约多项式（通常是100011101）然后把得出的乘积控制在256的范围内，再继续往下计算。以下是其中一部分的乘法得出的乘积再放进除法公式中继续运算。 于是得出编码信息为12 34 56 37 e6 78 d9。 def gf_poly_div(dividend, divisor): &#39;&#39;&#39;Fast polynomial division by using Extended Synthetic Division and optimized for GF(2^p) computations (doesn&#39;t work with standard polynomials outside of this galois field, see the Wikipedia article for generic algorithm).&#39;&#39;&#39; # CAUTION: this function expects polynomials to follow the opposite convention at decoding: # the terms must go from the biggest to lowest degree (while most other functions here expect # a list from lowest to biggest degree). eg: 1 + 2x + 5x^2 = [5, 2, 1], NOT [1, 2, 5] msg_out = list(dividend) # Copy the dividend #normalizer = divisor[0] # precomputing for performance for i in range(0, len(dividend) - (len(divisor)-1)):# 因为余数得比除数小。所以就让余数的长度比除数小1. #msg_out[i] /= normalizer # for general polynomial division (when polynomials are non-monic), the usual way of using # synthetic division is to divide the divisor g(x) with its leading coefficient, but not needed here. coef = msg_out[i] # precaching if coef != 0: # log(0) is undefined, so we need to avoid that case explicitly (and it&#39;s also a good optimization). for j in range(1, len(divisor)): # in synthetic division, we always skip the first coefficient of the divisior, # because it&#39;s only used to normalize the dividend coefficient if divisor[j] != 0: # log(0) is undefined msg_out[i + j] ^= gf_mul(divisor[j], coef) # 这里因为伽罗瓦域中多项式除法的特殊性，所以直接跳过divisor[0]，因为第一个数是为了量定除数需要乘多少去与被除数求余。然后后面的商就依次根据divisor[j]去确定。 # (but xoring directly is faster): msg_out[i + j] += -divisor[j] * coef # The resulting msg_out contains both the quotient and the remainder, the remainder being the size of the divisor # (the remainder has necessarily the same degree as the divisor -- not length but degree == length-1 -- since it&#39;s # what we couldn&#39;t divide from the dividend), so we compute the index where this separation is, and return the quotient and remainder. separator = -(len(divisor)-1) return msg_out[:separator], msg_out[separator:] # 返回商和余数，再在后面的公式把商加在msg_out数组前头 然后出来了一个高效的编码方法： def rs_encode_msg(msg_in, nsym): &#39;&#39;&#39;Reed-Solomon 主要的编码功能, 用的是多项式长除法 (algorithm Extended Synthetic Division)&#39;&#39;&#39; if (len(msg_in) + nsym) &gt; 255: raise ValueError(&quot;Message is too long (%i when max is 255)&quot; % (len(msg_in)+nsym)) gen = rs_generator_poly(nsym) # Init msg_out with the values inside msg_in and pad with len(gen)-1 bytes (which is the number of ecc symbols). msg_out = [0] * (len(msg_in) + len(gen)-1) # Initializing the Synthetic Division with the dividend (= input message polynomial) msg_out[:len(msg_in)] = msg_in # Synthetic division main loop for i in range(len(msg_in)): # Note that it&#39;s msg_out here, not msg_in. Thus, we reuse the updated value at each iteration # (this is how Synthetic Division works: instead of storing in a temporary register the intermediate values, # we directly commit them to the output). coef = msg_out[i] # log(0) is undefined, so we need to manually check for this case. There&#39;s no need to check # the divisor here because we know it can&#39;t be 0 since we generated it. if coef != 0: # in synthetic division, we always skip the first coefficient of the divisior, because it&#39;s only used to normalize the dividend coefficient (which is here useless since the divisor, the generator polynomial, is always monic) for j in range(1, len(gen)): msg_out[i+j] ^= gf_mul(gen[j], coef) # equivalent to msg_out[i+j] += gf_mul(gen[j], coef) # At this point, the Extended Synthetic Divison is done, msg_out contains the quotient in msg_out[:len(msg_in)] # and the remainder in msg_out[len(msg_in):]. Here for RS encoding, we don&#39;t need the quotient but only the remainder # (which represents the RS code), so we can just overwrite the quotient with the input message, so that we get # our complete codeword composed of the message + code. msg_out[:len(msg_in)] = msg_in return msg_out 这段新的代码把编码和长除法功能加在了一起，语句更简短。 这种算法速度更快，但在实际应用中仍然很慢，特别是在Python中。 有一些方法可以通过使用各种技巧来优化速度，例如内联（而不是gf_mul，替换为操作以避免调用），通过预计算（gen和coef的对数，甚至通过生成乘法表 - 通过使用内存视图（比如通过更改所有列表），使用静态类型构造（将gf_log和gf_exp分配给array.array（’i’，[…]）），但似乎后者在Python中效果不佳 通过使用PyPy运行它，或者将算法转换为Cython或C扩展名]]></content>
      <categories>
        <category>QR</category>
        <category>了解二维码</category>
        <category>了解二维码(四)：Reed-Solomon code</category>
      </categories>
      <tags>
        <tag>QR</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于对数]]></title>
    <url>%2F2019%2F03%2F05%2F%E5%9F%BA%E4%BA%8E%E5%AF%B9%E6%95%B0%2F</url>
    <content type="text"><![CDATA[它是在伽罗瓦域中将2的幂次方计算出来并存在相应的表中，随时查找到2的不同的幂次方对应的不同的值，然后让乘法除法更加简单快捷。所以这个不属于位运算，只是一个算法的代码示例，以后等更了解一点这些了，再好好细分，现在就这样吧 基于对数其中的gf_mult_noLUT(x, 2, prim)源自俄罗斯农夫算法 基于对数的乘法（次幂的加法）但是我们怎么样才能知道10001001是α的几次幂呢？这个问题被称为离散对数（离散对数在一些特殊情况下可以快速计算。然而，通常没有具非常效率的方法来计算它们。） gf_exp = [0] * 512 # Create list of 512 elements. In Python 2.6+, consider using bytearray gf_log = [0] * 256 def init_tables(prim=0x11d): &#39;&#39;&#39;Precompute the logarithm and anti-log tables for faster computation later, using the provided primitive polynomial.&#39;&#39;&#39; # prim is the primitive (binary) polynomial. Since it&#39;s a polynomial in the binary sense, # it&#39;s only in fact a single galois field value between 0 and 255, and not a list of gf values. global gf_exp, gf_log gf_exp = [0] * 512 # 就是和gf_log相反的表（gf_log值是下标，gf_log的下标是它的值） gf_log = [0] * 256 # (把2的幂和它对应的幂会生成的值通过这个下标和对应的值的关系连在一起) # For each possible value in the galois field 2^8, we will pre-compute the logarithm and anti-logarithm (exponential) of this value x = 1 for i in range(0, 255): gf_exp[i] = x # compute anti-log for this value and store it in a table gf_log[x] = i # compute log at the same time x = gf_mult_noLUT(x, 2, prim) # If you use only generator==2 or a power of 2, you can use the following which is faster than gf_mult_noLUT(): #x &lt;&lt;= 1 # multiply by 2 (change 1 by another number y to multiply by a power of 2^y) #if x &amp; 0x100: #类似于x&gt; = 256，但速度要快得多 #(because 0x100 == 256) #x ^= prim # substract the primary polynomial to the current value (instead of 255, so that we get a unique set made of coprime numbers), this is the core of the tables generation #优化：反日志表的大小加倍，这样我们就不需要修改255来保持在边界内 #（因为我们主要使用这个表来增加两个GF数，不再增加）。 for i in range(255, 512): gf_exp[i] = gf_exp[i - 255] return [gf_log, gf_exp] 这段代码会生成一个表，这个表里面是0-256对应的2的这些次幂的答案，然后如果要计算乘法的话，对方给出了一个大值然后用gf_log[x]找出对应的次幂，再进行加法运算。最后的一个循环是为了防止运算出来的幂相加的值超过255，所以把上限改成了512.（$\,2^{255}\,=\,00000001$然后又开始新一轮的循环2次幂。） def gf_mul(x,y): if x==0 or y==0: return 0 return gf_exp[gf_log[x] + gf_log[y]]#这样就可以不用再多一步%255去防止gf_exp溢出了的运算了。 基于对数的除法def gf_div(x,y): if y==0: raise ZeroDivisionError() if x==0: return 0 return gf_exp[(gf_log[x] + 255 - gf_log[y])% 255] 如果x对应的次幂比y对应的要小的话，加上255找到之后对应的幂还是和本身一样，最后求255的模的意思是让幂保持在0-255之间。0-254内的数值与255-510内的值 基于对数的次幂def gf_pow(x, power): return gf_exp[(gf_log[x] * power) % 255] 基于对数的导数def gf_inverse(x): return gf_exp[255 - gf_log[x]] # gf_inverse(x) == gf_div(1, x) 参考资料参考网页 参考网页]]></content>
      <categories>
        <category>位运算代码示例</category>
        <category>基于对数乘除法</category>
      </categories>
      <tags>
        <tag>基于对数乘除法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多项式]]></title>
    <url>%2F2019%2F03%2F05%2F%E5%A4%9A%E9%A1%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[其实这个不是位运算，只是把作为多项式的加法和乘法代码示例来进行解释，这是在伽罗瓦域中的加法和乘法，所以其中的加法和乘法均为异或算法。 其中的乘法是根据基于对数的乘法来进行的计算，是把被乘数转换成2的幂次方，然后将2的幂次方直接进行相加，最后根据得出的幂次方相加的结果去得出的对数表中找到相应的结果。 多项式其中gf_mul(p[i], x)该方法源自基于对数的乘法 多项式的加法def gf_poly_add(p,q): r = [0] * max(len(p),len(q)) for i in range(0,len(p)): r[i+len(r)-len(p)] = p[i] for i in range(0,len(q)): r[i+len(r)-len(q)] ^= q[i]#让在伽罗瓦域内的q和p两个多项式相加 return r 多项式相加就是幂次相同的系数相加，所以该方法将两个多项式的不同幂的系数均按幂次大小顺序排序，然后按顺序进行相加。 多项式的乘法（和一个普通系数的乘法）def gf_poly_scale(p,x): r = [0] * len(p) for i in range(0, len(p)): r[i] = gf_mul(p[i], x)# 该方法见基于对数的乘法部分内 return r 就是按照普通多项式乘法进行相乘，让x系数和多项式中各级幂的系数在伽罗瓦域内和x相乘 两个多项式间的乘法def gf_poly_mul(p,q): &#39;&#39;&#39;Multiply two polynomials, inside Galois Field&#39;&#39;&#39; # Pre-allocate the result array r = [0] * (len(p)+len(q)-1) # Compute the polynomial multiplication (just like the outer product of two vectors, # we multiply each coefficients of p with all coefficients of q) for j in range(0, len(q)): for i in range(0, len(p)): r[i+j] ^= gf_mul(p[i], q[j]) # equivalent to: r[i + j] = gf_add(r[i+j], gf_mul(p[i], q[j])) # -- you can see it&#39;s your usual polynomial multiplication return r 就是两个普通的多项式相乘时候，系数分别相乘（比如$\,\left (5x^{2}+4x+1 \right )\cdot \left ( 7x^{2}+9x+1 \right )\,$）其中$\,\left (7x^{2} \right) \cdot \left ( 5x^{2}+4x+1 \right )\,$以此类推…… 然后其中i+j的意味着相同次幂的系数，所以在该代码中对他们进行了相加（异或）。 在该代码中展示的仅仅是在伽罗瓦域中的系数的乘法然后再相加，所以用的是循环i和j，让所有的系数都能互相乘并且相加。 秦九韶算法这也是对多项式求解的一种算法，就是从$\,f \left ( x \right)\,=\,a{n}x^{n}+a{n-1}x^{n-1}+…+a{2}x^{2}+a{1}x+1 \,$中快速得出$\,f \left ( x \right)\,$的解。 详细介绍 参考资料参考网页 参考网页]]></content>
      <categories>
        <category>位运算代码示例</category>
        <category>多项式的加法和乘法</category>
      </categories>
      <tags>
        <tag>多项式的加法和乘法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[秦九韶算法]]></title>
    <url>%2F2019%2F03%2F04%2F%E7%A7%A6%E4%B9%9D%E9%9F%B6%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[用秦九韶算法和普通的计算多项式的算法比起来更为快捷，效率更高 算法介绍普通方法对于多项式（$\,a{n}x^{n}+a{n-1}x^{n-1}+…+a{2}x^{2}+a{1}x+1\,$）的解是把x的幂次方得出的结果和a乘起来，最后再相加 而秦九韶的解法是将多项式中的x一层一层的提取出来：$\left ( \left (\left ( a{n}x+a{n-1} \right )x+a_{n-2} \right )x+… \right )x+1$. 也就相当于在程序中用递归： $\,f{1}\,=\,a{n}x+a_{n-1}\,$ $\,f{2}\,=\,f{1}x+a_{n-2}\,$ …… $\,f{n-1}=f{n-2}x+a_{1}\,$ $\,f{n}=f{n-1}x+1\,$ $\,f_{n}\,$为所求 自然效率会比普通的算法要快许多。 代码用例def gf_poly_eval(poly, x): &#39;&#39;&#39;基于有限域的秦九韶算法的代码（所以乘法和加法都是一样的意思--都是异或）.&#39;&#39;&#39; y = poly[0] for i in range(1, len(poly)): y = gf_mul(y, x) ^ poly[i] return y 代码中的gf_mul(x,y)是基于对数表中的乘法中，见笔记的基于对数表的乘法该处。 参考资料参考维基百科]]></content>
      <categories>
        <category>伽罗瓦域/有限域</category>
        <category>秦九韶算法</category>
      </categories>
      <tags>
        <tag>秦九韶算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多源异构数据采集及实体链接算法研究]]></title>
    <url>%2F2019%2F03%2F01%2F%E5%A4%9A%E6%BA%90%E5%BC%82%E6%9E%84%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86%E5%8F%8A%E5%AE%9E%E4%BD%93%E9%93%BE%E6%8E%A5%E7%AE%97%E6%B3%95%E7%A0%94%E7%A9%B6%2F</url>
    <content type="text"><![CDATA[老师叫我帮她整理两个方向的资料，我就边整理边做点笔记好了，多了解一点东西总是好的。 多源异构数据就是不同数据库中的数据，在企业信息化建设过程中，因为各业务系统建设和实施数据管理系统的阶段性、技术性和一些其他因素的影响，让企业在发展过程中大量采用不同存储方式的业务数据，而且采用的数据管理系统也不一样，从简单的文件数据库到复杂的网络数据库，它们构成了企业的异构数据源。 实体链接一个实体可以用多个文本表达（多词一义），同一文本可能表达出多个不同的实体（一词多义）。通过进行实体链接，就是让文本中的实体指称和知识库中的实体进行链接。能够让文本中的数据转化为带有实体标注的文本。进而帮助人和计算机理解文本的具体含义。 个人理解是实体链接就是让文本中的一个词对应一个具体的实体 参考资料参考博客 参考帖子 参考文献]]></content>
      <categories>
        <category>多源异构数据采集及实体链接算法研究</category>
      </categories>
      <tags>
        <tag>多源异构数据采集及实体链接算法研究</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[markdown插入公式]]></title>
    <url>%2F2019%2F02%2F27%2Fmarkdown%E6%8F%92%E5%85%A5%E5%85%AC%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[实测在该博客中提到的四种在markdown中插入公式的办法 办法1：借助在线公式编辑器 =======> 办法2：借助Google Chart服务器在需要插入公式的位置键入如下代码，并在“在此插入Latex公式”中改写成公式即可。 &lt;img src=&quot;http://chart.googleapis.com/chart?cht=tx&amp;chl= 在此插入Latex公式&quot; style=&quot;border:none;&quot;&gt; 办法3：借助forkosh服务器与上一方法类似 办法4：借助MathJax引擎！在首部添加脚本代码，然后就可以在该文内像在latex中一样书写公式 总结只有方法1和方法4可行，方法1代码多，但是书写简单，无需记住数学公式的参考代码，但是达不到我想要的效果。方法4简单方便。只要你记住数学公式的书写代码，就没有问题了。 但是他们都是会让数学公式独占一行，所以我谷歌了一下怎么办，根据这篇博文去更改了我博客hexo框架和next主题的设置 （还有根着这个博文改了一下渲染什么的，我也不知道有什么用.） 安装和配置下载插件 $ npm install hexo-math --save 在站点配置文件 _config.yml 中添加： math: engine: &#39;mathjax&#39; # or &#39;katex&#39; mathjax: # src: custom_mathjax_source config: # MathJax config 在 next 主题配置文件中 themes/next-theme/_config.yml 中将 mathJax 设为 true: # MathJax Support mathjax: enable: true per_page: false cdn: //cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML 使用就是在数学公式的书写代码前面后面各加一个$符号。 然后弄完了之后我的有些图片能显示有些图片不能，我也不知道为什么，所以我经过激烈的心理斗争，决定，算了，不用这个方法了，前面的方法也挺好用的。 最后的使用办法我找到了这个博客根据它里面教我的去执行 npm install hexo-math --save hexo math install 然后更改 用编辑器打开marked.js（在./node_modules/marked/lib/中） Step 1: escape: /^\([\`*{}[]()# +-.!_&gt;])/, 替换成 escape: /^\\([`*\[\]()# +\-.!_&gt;])/, 这一步是在原基础上取消了对\,{,}的转义(escape) Step 2: em: /^\b((?:[^]|_)+?)\b|^*((?:**|[\s\S])+?)*(?!*)/, 替换成 em:/^\*((?:\*\*|[\s\S])+?)\*(?!\*)/, 这样一来MathJax就能与marked.js共存了。 就这样，我又能很好地插入数学公式了。 数学公式参考文档 该文档提供的下载地址 如果该链接打不开，请进入参考文档去寻找正确地址。 用mathjax对公式进行渲染 公式编辑器]]></content>
      <categories>
        <category>hexo更新配置</category>
        <category>markdown插入公式</category>
      </categories>
      <tags>
        <tag>markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[离散对数(Discrete logarithm)]]></title>
    <url>%2F2019%2F02%2F27%2F%E7%A6%BB%E6%95%A3%E5%AF%B9%E6%95%B0%2F</url>
    <content type="text"><![CDATA[设g为素数p的模循环群的原根,那就意思是$\, g\, $的循环群的大小$\,=\, \Phi \left ( p \right )$,又因为$\,p\,$是素数，所以循环群大小为：$\, \left ( p\,-\,1 \right )$ 对任意的a，计算： $b=g^{a}\ mod \ p$正推是很容易的，但是在只知道b而去求a的情况下，是非常难的。 因为a、b均为整数，不像实数那么“连续”，故称离散对数。 参考博文 加密过程加密方法1—标准Diffie-Hellman算法A发送消息m（0&lt;m&lt;p）给B A选取一个随机数$\, c\, $作为自己的私钥，然后这个随机数$\, 1\, &lt; \, c\, &lt; \, q\, $并且与$\, q\,-\,1\, $互质。接着计算$\,X\, = \, m^{c} \, mod \, q\,$，把X的值发送给A B选取一个随机数$\, d\, $作为自己的私钥，这个随机数$\, 1\, &lt; \, c\, &lt; \, q\, $并且与$\, q\,-\,1\, $互质。然后拿着从A处得到的X值进行计算：$\, Y\, = \, X^{b}\, mod \, p\, $，得到Y值（其中可以把公式拆开来变成$ \, m^{cd} \, mod \, q\,$）并且把得到的Y发给A A对从B处发来的Y进行计算：$\, Z\, =\, Y^{-c}\, $（可以把公式拆开得到：$ \, m^{cd\left ( -c \right )} \, mod \, q\,$，因为其中$\,cc^{-1}\,≡\,1(mod \,p-1)$，因为(c,p-1)=1，所以逆元素$c^{-1}$必存在。参见群的定义） 然后把Z值发回给B，让B根据这个值得到被加密的消息m。$z^{d^{-1}}=m^{dd^{-1}}\,mod\,p= m\,$因为m&lt;p-1。$dd^{-1}$与前面$cc^{-1}$同理 加密方法2—T. ElGamal算法因为比较容易懂，所以就不打出来了，直接贴截图把，也可以进参考博文直接看。 这里只需要进行两次通信，但是通信的内容和加密方法1比起来要多了一个群元素。 加密方法3—密钥交换它就是相当于两边共享一个秘钥，然后用这个秘钥对信息进行加解密（对称加密） 这个方法比较容易被程序实现。 总结这个加密算法难被破解的原因在于$b=g^{a}\ mod \ p$在这个公式中，只知道其中的b，p就算知道g，反推a也是非常的难，因为数据量之大，是没办法运算完成的。]]></content>
      <categories>
        <category>离散对数</category>
        <category>离散对数加密解密</category>
      </categories>
      <tags>
        <tag>离散对数加密解密</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[双射单射满射]]></title>
    <url>%2F2019%2F02%2F26%2F%E5%8F%8C%E5%B0%84%E5%8D%95%E5%B0%84%E6%BB%A1%E5%B0%84%2F</url>
    <content type="text"><![CDATA[在数学定义中，单射、满射和双射是指根据其定义域和陪域的关联方式所区分的三类函数。 单射：指将不同的变量映射到不同的值的函数。(也就是一对一) 满射：指陪域等于值域的函数。即：对陪域中任意元素，都存在至少一个定义域中的元素与之对应。(每个定义域都有相应的值域与之对应—可多对一或一对一) 双射（也称一一对应或一一映射）：既是单射又是满射的函数。直观地说，一个双射函数形成一个对应，并且每一个输入值都有正好一个输出值以及每一个输出值都有正好一个输入值。 （每个定义域都有相应的值域与之对应—一对一） ——————-摘自维基百科]]></content>
      <categories>
        <category>数学基础知识</category>
        <category>双射单射满射</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>数学基础知识</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[原根]]></title>
    <url>%2F2019%2F02%2F26%2F%E5%8E%9F%E6%A0%B9%2F</url>
    <content type="text"><![CDATA[其中，如果正整数$(a,m)=1$和正整数$\,d\; \left ( d\leqslant m\, -\, 1 \right )$满足$a^{d}\,\equiv\ 1(mod\ m)$那么满足这个式子的正整数$\,d\,$最小正整数$\,x\,$，$\,x\,=\,Ord_{m}\left ( a \right )$。如果$\,x\,=\,\Phi \left ( m \right )$那么就说这个$\,a\,$是$\,m\,$的原根 参考定理 就是在值最小的时候满足欧拉定理的式子，同时还要和欧拉函数的值一样,才能称作式子中这两个互质的数，一个是模另一个原根。 所以，对于任意数m可以有很多个原根，也可以一个原根也没有（其中a是可变的） 存在原根的模乘法群称为循环群。 原根性质：]]></content>
      <categories>
        <category>离散对数</category>
        <category>原根</category>
      </categories>
      <tags>
        <tag>原根</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[互质关系]]></title>
    <url>%2F2019%2F02%2F22%2FMutRela%2F</url>
    <content type="text"><![CDATA[互质又称是互素，两个整数的公约数除了它们本身的乘积外只有1，那么称这两个数互质。 参考资料通过观察可以发现在以下的情况下，两个数一定会互质。 两个不同的素数一定互质。例如，2与7、13与19。 一个素数，另一个不为它的倍数，这两个数互质。例如，3与10、5与 26。 1和任何一个自然数都互质。如1和9908。 2的幂和任何一个奇数都互质。如32和75、256与315。 相邻两个自然数互质。如15与16。 相邻两个奇数互质。如49与51。 较大数是素数，则两个数互质。如97与88。 两数和是素数，则两个数互质。如52与45。 两数差是素数，两个数都不是两数差的倍数，则两个数互质。如140与171。 两数积是无平方数约数的数，则两个数互质。如154与195。 较大数除以较小数的余数是1或-1，则两个数互质。如440与63。 辗转相除法。如255与182。255－182=73，182－（73×2）=36，73－（36×2）=1，则（255，182）=1。故这两数互质。 p是大于1的整数，则p和p-1构成互质关系，比如57和56。 p是大于1的奇数，则p和p-2构成互质关系，比如17和15。 一个数的素因数都小于某数，另一个数素因数都大于同一个数，则两个数互质。如180与2431、5040与4301。 两数都是合数（二数差较大），较小数所有的素因数，都不是较大数的因数，这两个数互质。如357与715，357=3×7×17，而3、7和17都不是715的因数，故这两数互质。 两数都是合数（二数差较小），这两数之差的所有素因数都不是较小数的因数，这两个数互质。如85和78。85－78=7，7不是78的因数，故这两数互质。 素因数：一个整数会有很多个因数，其中因数约数只能由1和他本身相乘产生。 合数：（又叫合成数）每个大于1的整数如果不是质数就是合数。 1不是素数，最小的质数是2]]></content>
      <categories>
        <category>RSA公钥加密</category>
        <category>互质关系（互素关系）</category>
      </categories>
      <tags>
        <tag>互质关系（互素关系）</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[欧拉函数]]></title>
    <url>%2F2019%2F02%2F22%2F%E6%AC%A7%E6%8B%89%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[欧拉函数： 若正整数 a , n 互质，则 aφ(n) ≡ 1(mod n) 其中 φ(n) 是欧拉函数（1~n) 与 n 互质的数。 欧拉定理： 如果两个正整数互质，则n的欧拉函数φ(n) 可以让下面的等式成立 参考资料 互质关系 欧拉函数用来思考的问题：任意给定正整数n，请问在小于等于n的正整数之中，有多少个与n构成互质关系？（比如，在1到8之中，有多少个数与8构成互质关系？） n=1时候，φ(n=1)=1,因为1和任何数互质。 n为素数的时候，φ(n)=n-1，因为素数和每个小于自己的数都互质。 n=p^k,p为素数时候，p^k中存在很多和p有倍数关系的数字，1 x p，2 x p，……p^(k-1) x p。由列出的公式看出，一共有p^(k-1)个和p有倍数关系的数字，所以φ(p^k)=p^(k)-p^(k-1) 如果n能分解成两个互质的整数之积，n=p1 x p2,则φ(n) = φ(p1p2) = φ(p1)φ(p2).(即积的欧拉函数等于各个因子的欧拉函数之积。比如，φ(56)=φ(8×7)=φ(8)×φ(7)=4×6=24。) 以上这四个方法，可以任意运用来得出自己想要的结果 欧拉定理如果正整数a和n互为质数，那么n的欧拉公式φ(n)可以让下列公式成立： 这样，a^(φ(n))减掉1就能被n整除了。 而且，欧拉定理的特殊情况就是费马小定理 模反元素就是正整数a和n互为质数，那么一定存在b使得 ab ≡ 1(mod n)]]></content>
      <categories>
        <category>RSA公钥加密</category>
        <category>欧拉函数&amp;欧拉定理</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>数学基础知识</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[同余]]></title>
    <url>%2F2019%2F02%2F21%2F%E5%90%8C%E4%BD%99%2F</url>
    <content type="text"><![CDATA[同余是数论中的一种等价关系。符号是≡，有两个正整数，一起除以一个相同的正整数，得出的余数一样的话，那么称这两个正整数同余。 参考维基百科 就是，正整数a,b取模c的值是一样的，那么我们可以这样去表示它： a ≡ b(mod c) 可以读作a同余于b模c。 性质整除性a ≡ b(mod c) =&gt; cm = a-b =&gt; m | (a-b) [c属于Z] m | (a-b): (a-b)是m的倍数 保持基本运算 ## 传递性 a ≡ b(mod m) b ≡ d(mod m) =>a ≡ d(mod m) ## 放大缩小模数 ## 除法原理一 ## 除法原理二]]></content>
      <categories>
        <category>离散对数</category>
        <category>同余</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>离散对数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RSA算法]]></title>
    <url>%2F2019%2F02%2F21%2FRSA-key%2F</url>
    <content type="text"><![CDATA[RSA公钥算法是现在非常普遍的存在，因为它的高运算量所以导致难破解，其实最主要的原因是现有的计算机的运算能力还没有那么强，没办法对巨大的加密数进行因式分解。 目前公开破译的位数是768位，实际使用一般是1024位或是2048位，所以理论上特别的安全。证明方法 公私钥生成步骤 公钥私钥生成先选取两个质数q,p n = p * q 然后算出n的 欧拉函数 φ(n) φ(n)=(p-1)(q-1) 从1-φ(n)中选出一个质数e，这个e要和φ(n)互质 对e取反模 ed ≡ 1 (mod φ(n)) 根据同余的定义，这个式子可以延展为： ed - 1 = kφ(n) 根据已知的φ(n)和e得出d的值(会有很多组值，取其一即可)以此得出公钥(n,e) 私钥(n,d) 加密解密加密 m为需要被加密的信息 c为会生成的信息 m^e ≡ c(mod n) 解密c^d ≡ m(mod n) 证明验证解密公式成立对解密公式c^d ≡ m(mod n)进行验证 根据加密公式 m^e ≡ c(mod n) =&gt; m^e - c =kn =&gt;c = m^e -kn 把c代入我们要证明的解密公式 (m^e - kn)^d ≡ m(mod n) 因为kn能被n整除，所以在拆这种多项式的时候，能被n整除的数可以留下，因为只有不能被n整除的数才能够产生余数。所以得出下面的公式 m^ed ≡ m(mod n) 又因为ed等于kφ(n)+1，故得出如下公式 m^(kφ(n)+1) ≡ m(mod n) 所以，我们只要证明这个公式成立，就证明解密公式的成立，也就证明了RSA算法的成立。 两部分证明m与n互质根据欧拉定理得出如下公式 m^φ(n) ≡ 1(mod n) =&gt; m^φ(n)-1 = kn =&gt;m^φ(n) = kn + 1(m^φ(n))^h = (kn + 1)^h 而对(kn + 1)^h 对n取模为1，可以推出 (kn + 1)^h ≡ 1(mod n) =&gt; (m^φ(n))^h ≡ 1(mod n)=&gt; m^(kφ(n)+1) ≡ m(mod n) 该式子成立 m与n不互质m和n不互质时候，所以n和m一定有除1以外的公因子，又因为n等于质数p和质数q的乘积(两个质数之积是合数，但该合数只有四个因子，因数除了1和它本身外还有这两个质数因子。)所以，m必然等于kq或kp。 以m=kq为例，那么m一定和p互质(一个素数，另一个数不为它的倍数，那么两个数一定互质)——&gt;根据欧拉定理可得出如下公式： (kq)^φ(p) ≡ 1 (mod p) 因为p为质数，所以 φ(p)= p - 1 可以得出 (kq)^(p - 1) ≡ 1 (mod p) ((kq)^(p - 1))^h(q - 1) x kq ≡ kq (mod p) (kq)^(hφ(n) + 1) ≡ kq (mod p) 又因为(因为上式中的h可以为任意数字，所以假定h为下式中的h) ed ≡ 1(modφ(n)) → ed = hφ(n)+1 → ed = h(p−1)(q−1)+1 故 (kq)^ed ≡ kq (mod p) (kq)^ed - kq = tp 因为等式左边对q取模为零，所以右边一定也为零，所以tp中t一定是q的倍数，令t=uq (kq)^ed - kq = uqp 又因为n = pq, m = kq，所以 m^ed -m = un m^ed ≡m(modn) 又因为生成密钥的第五步中我们取e并求了他对φ(n)的模反元素d： ed≡1(modφ(n))→ed=hφ(n)+1 将ed代入上式得： m^(hφ(n)+1) ≡ m(modn) 故当m与n不互质时候，证明原式成功。]]></content>
      <categories>
        <category>RSA公钥加密</category>
        <category>RSA算法</category>
      </categories>
      <tags>
        <tag>RSA算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[欧几里得算法（了解了一下贝祖等式）]]></title>
    <url>%2F2019%2F02%2F20%2FEuclidean%2F</url>
    <content type="text"><![CDATA[它是求最大公约数的算法。 参考链接a x b =c c是a的倍数，a是c的约数。最大公约数就是能够整除几个自然数中的最大的一个 欧几里得算法则是用于计算两个整数的最大公约数，它又被叫做最大公约数 两个整数的最大公约数表示方法：GCD(a,b) 欧几里得的辗转相除法其实可以用来计算任意多整数的最大公约数。 算法描述：GCD(a,b)=c时候，除掉小学时候学的分解这两个数，取共有的公约数，然后把它们相乘之外，还可以用另外一种方法把c求出来——就是用a,b两个数中最大的那个数减去最小的那个数，然后那个最大的数就变成得出的差值，以此循环，直到有一个数变成零为止，另一个不为零的数就是它们的最大公约数。 用辗转相除法算最大公约数效率非常高。 eg: 252 105 的最大公约数 147 105（252-105） 42 105（147-105） 42 63 （105-42） 42 21 （63-42） 21 21 （随便哪边减掉哪边） 0 21 因为在这个辗转相除的过程中，它可以一个数大于另一个数大很多（比如42和105）这时候，105需要减掉2次42才能得到比42更小的数字，所以这里可以考虑除法求余的办法。105 mod 42=21，这样又快又准，还方便。 252 105（252 mod 105） 42 105（105 mod 42） 42 21 （42 mod 21） 0 21 （正好结果是0，所以21是最大公约数） 所以，ua+vb的值的集合，都是c的倍数。—-因为a和b的最大公约数是c，即都能被c整除，这个是贝祖等式提出的定义 a和b的最大公约数叫做a和b的理想的生成元素。这个最大公约数的定义导出了两个现代抽象代数的概念：主理想（由单个元素生成的理想） 以及主理想整环（其每一理想都是主理想的整环）。 GCD(a,b)=1那么这两个数一定互质]]></content>
      <categories>
        <category>RSA公钥加密</category>
        <category>欧几里得算法/辗转相除法及贝祖等式</category>
      </categories>
      <tags>
        <tag>欧几里得算法/辗转相除法简略介绍及贝祖等式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[费马小定理]]></title>
    <url>%2F2019%2F02%2F20%2FdiscreteLogarithm%2F</url>
    <content type="text"><![CDATA[要想清楚的了解费马，就要先了解同余。 费马小定理：若p为素数，a为整数，(a,p)=1(即两者只有一个公约数1)，则 a^(p-1)≡1（mod p） 如果n是一个素数（只能被1和自身整除的数字），a是小于n的任意正整数，那么a^n mod n 的结果和a mod n一样。a^(n)≡a（mod n） 参考博客 维基百科 费马检查：给一个整数n，然后随机取一个a，这个a要小于n，然后计算a取模n的结果并且用它去和a^n mod n的结果相比，如果两个结果不一样，那么这个n一定不是素数，两个结果一样的话，那么这个n几率很大是素数。通过检查越来越多的a值，结果还是一样的话，这个n是素数的可能性也越大。 费马检测是一个相对可靠的算法，而且在实现大数判断素数时可以提供相对高的效率来工作。 为什么说它相对可靠呢，是因为有些极其罕见的数字，也具备费马定理的特性，然鹅他们并不是素数。能够骗过费马检查的数称为 Carmichael 数。（科普时间）在 100 000 000 之内有 255 个 Carmichael 数，其中最小的几个是 561、1105、1729、2465、2821 和 6601。 费马检查却可以在几秒内判断这么大的数的素性。这一事实成为 Rivset、Shamir 和 Adleman (1977) 提出的一种构造“不可摧毁的密码”的技术基础，这一 RSA 算法已经成为提高电子通信安全性的一种使用广泛的技术]]></content>
      <categories>
        <category>数论</category>
        <category>费马小定理</category>
      </categories>
      <tags>
        <tag>数论</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[伽罗瓦域_乘法]]></title>
    <url>%2F2019%2F02%2F20%2FGaloisField-mult%2F</url>
    <content type="text"><![CDATA[其中，α=0000 0010转回十进制的数值就是2，所以，α^n时候，n每加一就是该二进制往左移一位。如果超了范围的话，就先左移一位，然后再模100011101，让它的值在固定的范围内。 除零之外的场的每个元素等于α的某个幂。 我们定义的元素α被称为伽罗瓦域的原始元素或生成元。]]></content>
      <categories>
        <category>伽罗瓦域/有限域</category>
        <category>乘法表</category>
      </categories>
      <tags>
        <tag>伽罗瓦域/有限域</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo deploy不报错但是无法显示]]></title>
    <url>%2F2019%2F02%2F20%2Fhexo-err%2F</url>
    <content type="text"><![CDATA[hexo g hexo s hexo d 错误描述：三步下来，hexo s这一步是没有错的，也能在本地预览已经生成好的静态页面，但是hexo d之后，不报错，但是就是没法正确部署到github page上面。而且还收到github发来的邮件，说是主题不被支持。 删掉.deploy_git，然后git clean ,接着hexo d -g重新生成这个文件夹，并且将页面部署到github page中]]></content>
      <categories>
        <category>hexo错误笔记</category>
        <category>hexo deploy</category>
      </categories>
      <tags>
        <tag>hexo err类型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[俄罗斯农夫算法]]></title>
    <url>%2F2019%2F02%2F20%2FRussianPeasant%2F</url>
    <content type="text"><![CDATA[俄罗斯农民乘法是在一个乘数和被乘数之间进行操作，降低运算需要花费的时间。 参考博客 参考代码来源 这个算法流程是：乘数和被乘数，一个乘2一个除2，如果被乘数为奇数，则它除以2后去掉余数。如果被乘数是偶数，则继续往下乘除。等被乘数除以2的结果为1的时候，运算结束，把被乘数为奇数的结果所对应的乘数乘以2的结果相加，最终结果为正确乘积。 52 x 25 104 12 208 6 416 3 832 1 ----------- 52+416+832=1300 以下是位运算代码示例： def gf_mult_noLUT(x, y, prim=0, field_charac_full=256, carryless=True): &#39;&#39;&#39;Galois Field integer multiplication using Russian Peasant Multiplication algorithm (faster than the standard multiplication + modular reduction). If prim is 0 and carryless=False, then the function produces the result for a standard integers multiplication (no carry-less arithmetics nor modular reduction).&#39;&#39;&#39; r = 0 while y: # while y is above 0 if y &amp; 1: r = r ^ x if carryless else r + x # y is odd, then add the corresponding x to r (the sum of all x&#39;s corresponding to odd y&#39;s will give the final product). Note that since we&#39;re in GF(2), the addition is in fact an XOR (very important because in GF(2) the multiplication and additions are carry-less, thus it changes the result!). y = y &gt;&gt; 1 # equivalent to y // 2 x = x &lt;&lt; 1 # equivalent to x*2 if prim &gt; 0 and x &amp; field_charac_full: x = x ^ prim # GF modulo: if x &gt;= 256 then apply modular reduction using the primitive polynomial (we just subtract, but since the primitive number can be above 256 then we directly XOR). return r ​其中y&amp;1是用来判断y是奇数还是偶数，if carryless是用来判断这个是普通乘法还是伽罗瓦乘法，然后做出相应的算法 prim &gt; 0是判断是不是伽罗瓦乘法，是的话，再对结果进行相应的处理 x &amp; field_charac_full这个是判断x是否大于field_charac_full，大于的话就模field_charac_full以控制x在相应范围内，小于的话就可以直接输出结果。]]></content>
      <categories>
        <category>位运算代码示例</category>
        <category>俄罗斯农夫算法</category>
      </categories>
      <tags>
        <tag>位运算代码示例</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[位运算_汉明距离]]></title>
    <url>%2F2019%2F02%2F19%2FBitOperation_Hamming%2F</url>
    <content type="text"><![CDATA[汉明距离是用来计算两个不同字符串之间不同的值有多少个。二进制中就是两个二进制相减，结果中1的个数 def hamming_weight(x): #不同bit的数量 weight = 0 while x &gt; 0: weight += x &amp; 1 x &gt;&gt;= 1 return weight def qr_decode_format(fmt): best_fmt = -1 best_dist = 15 for test_fmt in range(0, 32): test_code = (test_fmt &lt;&lt; 10) ^ qr_check_format(test_fmt &lt;&lt; 10)#得出（0-2^5）左移10位然后能被生成子整除的5bit编码 &#39;&#39;&#39; 计算汉明距离的公式 &#39;&#39;&#39; test_dist = hamming_weight(fmt ^ test_code) if test_dist &lt; best_dist: best_dist = test_dist best_fmt = test_fmt elif test_dist == best_dist: #如多个码字与fmt距离相同，则都不选（就是不止一个与原信息的汉明距离相同） best_fmt = -1 return best_fmt 用fmt^test_code算出fmt和test_code中二进制的不同，再去统计相减结果为1的个数，最后得出汉明距离。（也可以叫做计算出汉明权重） 汉明权重：指一个字符串中非零字符的个数；对于二进制串，即其中‘1’的个数。]]></content>
      <categories>
        <category>位运算代码示例</category>
        <category>汉明距离</category>
      </categories>
      <tags>
        <tag>位运算代码示例</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[位运算_除法]]></title>
    <url>%2F2019%2F02%2F19%2FBitOperation_divided%2F</url>
    <content type="text"><![CDATA[这个除法是普通的除法，用来求余的除法。 所以根据该链接中的代码举例: def qr_check_format(fmt): g = 0x537 # = 0b10100110111 in python 2.6+ for i in range(4,-1,-1): if fmt &amp; (1 &lt;&lt; (i+10)): #判断第一位是否为零（二进制除法不需要进位借位） fmt ^= g &lt;&lt; i #开始计算 return fmt 其中for i in range(4,-1,-1)里面i的范围是[4,0]的原因是：上述例子中举例用的生成器10100110111长度和用于和它进行相除的除数000111101011001长度相差为4，所以设置i的范围为[4,0]（其中生成器做被除数）]]></content>
      <categories>
        <category>位运算代码示例</category>
        <category>除法求余</category>
      </categories>
      <tags>
        <tag>位运算代码示例</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[位运算_乘法]]></title>
    <url>%2F2019%2F02%2F19%2FBitOperation_mult%2F</url>
    <content type="text"><![CDATA[伽罗瓦域的加减法运算都是用异或的方法运算的，所以它的乘法和普通的乘法也是不一样的。 其中乘法运算完成后，结果相加的步骤和普通乘法不一样，它用的是异或 所以根据该链接中的代码举例: def cl_mul(x,y): &#39;&#39;&#39;Bitwise carry-less multiplication on integers&#39;&#39;&#39; z = 0 i = 0 while (y&gt;&gt;i) &gt; 0: if y &amp; (1&lt;&lt;i): #判断y?=1 z ^= x&lt;&lt;i #判断x乘的是y的第几位 i += 1 return z]]></content>
      <categories>
        <category>位运算代码示例</category>
        <category>伽罗瓦域的乘法</category>
      </categories>
      <tags>
        <tag>位运算的代码示例</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[伽罗瓦域]]></title>
    <url>%2F2019%2F02%2F18%2FGaloisFields%2F</url>
    <content type="text"><![CDATA[有限域亦称伽罗瓦域（galois field），是仅含有限个元素的域,它是伽罗瓦(Galois,E.)于18世纪30年代研究代数方程根式求解问题时引出的.（摘自百度百科） 群：其中（D,）是一个群的话，则称G关于运算“ ”形成一个群，*是这个群的运算式。其中，D=那么说明，D这个群是由g这个生成元组成的。 集合+运算=群 给一个集合中的元素定义一种运算“乘法”（这个“乘法”不是数字运算的乘法，而只是借用了这个名字，因此加上了引号），如果这个集合中的元素和这个“乘法”满足： 封闭性：集合中任两个元素相“乘”的结果在这个集合之内； 结合律：这个“乘法”满足(ab)c=a(bc)； 单位元：集合中存在某个元素e，对于任意集合中的其它元素a有ea=ae=a，e被称为单位元； 逆元：对于集合中任意元素a，一定存在集合中的另外一个元素a^(-1)，使得aa^(-1)=a^(-1)a=e，a与a-1互为逆元。 此时，这个集合与这个运算组合在一起被称为“群”。 此下是一个来自知乎上一篇笔记的例子 在里面的ab=ac（a^(-1)ab=a^(-1)ac），推出b=c的过程中，用到了**逆元存在**这个概念），还用到了**单位元存在**这个概念 ba=ca（baa^(-1)=caa^(-1)）推出b=c的过程用到了**结合率**的概念 ### 交换群 首先明白这样一个代数结构 [双射](https://aimasa.github.io/categories/%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E5%8F%8C%E5%B0%84%E5%8D%95%E5%B0%84%E6%BB%A1%E5%B0%84/)就是值域和定义域一对一的映射，每个定义域都有唯一一个与之对应的值域 接着这个是交换群的概念 我的理解是，在交换群中，每个数都有它通过相同运算对应的结果，无一例外，就连e也能通过这个运算得到在群内的结果 ### 循环群 在讲到循环群的时候，这个[笔记](https://zhuanlan.zhihu.com/p/30384157)里面出现了阶的定理，我目前还不是很清楚阶的定理和循环群的定理有什么关联(如果这个群里面存在阶，就可以称这个群是有限群，否则则成为无限群) 我们给它一个符号 o(a)=n 然后循环群就是每个元素都能写成其中某个元素的i次幂的形式，这个元素就是这个群的生成元。每个循环群都是阿贝尔群 ### 子群 我的理解就是大群里面的小群，然后这个小群有着群需要的一切要素。 环与域：在一个集合上定义两种运算“加法”和“乘法”，如果这个集合在这个“加法”下成群，而在这个“乘法”下只满足“封闭性”与“结合律”，则称这个集合与这两种运算构成一个“环”；如果这个集合去除“加法”群下的单位元后形成的新集合在“乘法”下成群，则称这个集合与这两种运算构成一个“域”。显然，“域”是一种特殊的“环”。 ————————————————————————————-摘自zhaohaotong的博文 有限域GF(p)： 在密码学中，有限域GF(p)是一个很重要的域，其中p为素数。简单来说，GF(p)就是 mod p，因为一个数模p后，结果在[0, p-1]之间。对于元素a和b，那么(a+b) mod p和(a*b)mod p，其结果都是域中的元素。GF(p)里面的加法和乘法都是平时用的加法和乘法。GF(p)的加法和乘法单位元分别是0和1，元素的加法和乘法逆元都很容易理解和求得. 有限域GF(2^8)：现在重点讲一下GF(2^n)，特别是GF(2^8)，因为8刚好是一个字节的比特数。 前面说到， GF(p)，p得是一个素数，才能保证集合中的所有元素都有加法和乘法逆元(0除外)。但我们却很希望0到255这256个数字也能组成一个域。因为很多领域需要用到。mod 256的余数范围就是0到255，但256不是素数。小于256的最大素数为251，所以很多人就直接把大于等于251的数截断为250。在图像处理中，经常会这样做。但如果要求图像无损的话，就不能截断。 貌似已经到了死胡同，救星还是有的，那就是GF(p^n)，其中p为素数。在这里我们只需令p为2，n为8，即GF(2^8)。 ——————————————————————————————摘自luotuo44博文 在伽罗瓦域里面，加法和减法都是异或运算，所以两者是相等的，而其他域里面是不会这样的。]]></content>
      <categories>
        <category>伽罗瓦域/有限域</category>
        <category>基础定义</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>数学基础知识</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python_左移]]></title>
    <url>%2F2019%2F01%2F30%2Fpython_ShiftLeft%2F</url>
    <content type="text"><![CDATA[都是移位操作，三个符号和两个符号的区别是： “&gt;&gt;” 右移,高位补符号位 “&gt;&gt;&gt;” 无符号右移,高位补0； “&lt;&lt;” 左移 左移一位表示乘2，二位就表示4，就是2的n次方 “^”是异或 a&amp;b时候返回的值是直接赋给a的]]></content>
      <categories>
        <category>Python</category>
        <category>&lt;&lt;、&gt;&gt;、^、&amp;</category>
      </categories>
      <tags>
        <tag>python 语法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python_range的用法]]></title>
    <url>%2F2019%2F01%2F30%2Fpython_rangeUse%2F</url>
    <content type="text"><![CDATA[简单的讲了一下range的用法和array[::]的一些用法 参考博文array = [1, 2, 5, 3, 6, 8, 4] 其实这里的顺序标识是 [1, 2, 5, 3, 6, 8, 4] (0，1，2，3，4，5，6) (-7,-6,-5,-4,-3,-2,-1) [::]情况那么两个[::]会是什么那？ array[::2][1, 5, 6, 4] array[2::][5, 3, 6, 8, 4] array[::3][1, 3, 4] array[::4][1, 6] 如果想让他们颠倒形成reverse函数的效果 array[::-1][4, 8, 6, 3, 5, 2, 1] array[::-2][4, 6, 5, 1] [:]情况如果[:]只有一个的时候，那么： array[:-2][8, 4] array[-2:][1, 2, 5, 3, 6] array[2:][5, 3, 6，8,4] array[:2][1,2] (后面的-x是从-1开始计数) 参考博文:函数原型：range（start， end， scan): 参数含义： start:计数从start开始。默认是从0开始。例如range（5）等价于range（0， 5）; end:技术到end结束，但不包括end.例如：range（0， 5） 是[0, 1, 2, 3, 4]没有5 scan：每次跳跃的间距，默认为1。例如：range（0， 5） 等价于 range(0, 5, 1) 所以，两个冒号时候，array[::]其中第一个数是数列的起始位置，第二个数是数列的最终位置，第三个是从第一位置往下数间隔的长度（如果为负数，则是倒过来往前数字符） 在range()中，有三个值，第三个值如果是负数则是减少，正数是增加]]></content>
      <categories>
        <category>Python</category>
        <category>range()&amp;array[::]</category>
      </categories>
      <tags>
        <tag>python的用法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[about_blockchain]]></title>
    <url>%2F2019%2F01%2F26%2Fabout_blockchain%2F</url>
    <content type="text"><![CDATA[blockchain 因为之前我没弄懂电子签章的问题，然后问旁边的同学，他很仔细的给了我解释，还帮我找了一篇论文，让我看看前两页，所以在阅读这篇论文时候在此做个笔记。 电子签名在区块链上生成的签名被称为“数字”而不是“电子”。电子签名是“附加的电子声音，符号或过程，或在逻辑上与合同或其他记录相关联，由有意图的人采用“签署记录“（也就是证明自己是自己的东西，并且赋予认定）（referred to：提到） 数字签名数字签名是一种特殊的电子签名，它可以加密被签名的文档并并有助于在后续场合验证其身份，它们是在数字环境中创建的，为公钥加密数据库提供验证和传输层（这样拿到这个数字签名的对方，可以用私钥进行解密，得到摘要并且对自己手中的文档进行一次hash算法，对两者进行比对，这样就能判别该文档是否被第三方篡改过，验证其安全性）]]></content>
      <categories>
        <category>blockchain</category>
      </categories>
      <tags>
        <tag>blockchain</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[了解二维码(三):BCH解码器]]></title>
    <url>%2F2019%2F01%2F23%2FBCH%2F</url>
    <content type="text"><![CDATA[这是一类通用的纠错码，BCH码：现代里德 - 所罗门码的父族，以及有基本的检测和校正机制。格式化信息用BCH码编码，该BCH码允许检测和校正一定数量的比特错误。检查编码信息的过程类似于长除法过程，只是使用异或代替减法（a remainder of zero：余数为零） BCHBCH错误检测当格式代码被所谓的代码生成器“分割”时，格式代码应产生的余数为零。QR格式代码使用生成器10100110111. （ demonstrated：示范）（0x前缀表示该数字是十六进制，0b是二进制）用fmt与生成子相除，返回余数 def qr_check_format(fmt): g = 0x537 # = 0b10100110111 in python 2.6+ for i in range(4,-1,-1): if fmt &amp; (1 &lt;&lt; (i+10)): #判断第一位是否为零（二进制除法不需要进位借位） fmt ^= g &lt;&lt; i #开始计算 return fmt 其中for i in range(4,-1,-1)里面i的范围是[4,0]的原因是：上述例子中举例用的生成器10100110111长度和用于和它进行相除的除数000111101011001长度相差为4，所以设置i的范围为[4,0] 1字=2字节(1 word = 2 byte) 1字节=8位(1 byte = 8bit) 这个函数可以用于编码生成5bit的编码信息（就是需要被生成器整除的编码信息） encoded_format = (format&lt;&lt;10) ^ qr_check_format(format&lt;&lt;10) 它利用上面的计算余数的函数得出format&lt;&lt;10除以生成器的余数，然后反推出在信息为format&lt;&lt;10的情况下除以生成器时候余数为零的5bit的编码信息。 如果记格式信息为F，生成子为G，(F&lt;&lt;10)/G的商为Q、余数为R (即F&lt;&lt;10 == Q*G + R)，则最终的编码信息 C = (F &lt;&lt; 10) ^ ((F &lt;&lt; 10) mod G) = (QG + R) - R = QG 从而C应当是能够被G整除的。如果收到的C不能被G整除，说明传输出错了。 BCH纠错汉明距离是使用在数据传输差错控制编码里面的，汉明距离是一个概念，它表示两个（相同长度）字对应位不同的数量，我们以d（x,y）表示两个字x,y之间的汉明距离。对两个字符串进行异或运算，并统计结果为1的个数，那么这个数就是汉明距离。 def qr_check_format(fmt): g = 0x537 # = 0b10100110111 in python 2.6+ for i in range(4, -1, -1): if fmt &amp; (1 &lt;&lt; (i+10)): fmt ^= g &lt;&lt; i return fmt def hamming_weight(x): #不同bit的数量 weight = 0 while x &gt; 0: weight += x &amp; 1 x &gt;&gt;= 1 return weight def qr_decode_format(fmt): best_fmt = -1 best_dist = 15 for test_fmt in range(0, 32): test_code = (test_fmt &lt;&lt; 10) ^ qr_check_format(test_fmt &lt;&lt; 10)#得出（0-2^5）左移10位然后能被生成子整除的5bit编码 test_dist = hamming_weight(fmt ^ test_code) if test_dist &lt; best_dist: best_dist = test_dist best_fmt = test_fmt elif test_dist == best_dist: #如多个码字与fmt距离相同，则都不选（就是不止一个与原信息的汉明距离相同） best_fmt = -1 return best_fmt 代码中用fmt ^ test_code，然后统计结果中1的比特的个数，以此来比较fmt和test_code的汉明距离，倘若有多个与fmt的汉明距离一样的test_code，那么就相当于没有可以用于匹配的值，如果只有一个值的话，那么那个最大相似度的值则就是fmt被损坏前的值 （overflow：溢出；Naively：天真地） We’d like to define addition, subtraction, multiplication, and division for 8-bit bytes and always produce 8-bit bytes as a result, so as to avoid any overflow. Naively, we might attempt to use the normal definitions for these operations, and then mod by 256 to keep results from overflowing. 伽罗瓦域乘法和减法mod2^8就是让加减乘除里面的结果小于2^8，在0-255的区间里面。具体参见笔记伽罗瓦域乘法部分 在伽罗瓦域的乘法中，两个数相乘，它的值可能大于2^8，所以在进行乘法后，会对得出的结果进行取模（就是求余），而其中除数为100011101（0x11d） 100011101（0x11d）是Reed-Solomon代码的通用本原多项式。100011101表示8度多项式，其是“不可约的”（意味着它不能表示为两个较小多项式的乘积）。 素数多项式的附加信息（可以跳过）：什么是素数多项式？ 它相当于素数，但在伽罗瓦域中。 请记住，Galois Field使用的值为2的倍数作为生成器。 当然，在标准算术中，素数不能是2的倍数，但在伽罗瓦域中，它是可能的。 为什么我们需要素数多项式？ 因为要保持在场的边界，我们需要计算Galois场上方任何值的模数。 为什么我们不用Galois Field大小模数？ 因为我们最终会得到许多重复值，并且我们希望在字段中拥有尽可能多的唯一值，因此在使用素数多项式进行模数或XOR时，数字始终只有一个投影。 另外我们可以发现，用加法也能得出我们想要的结果：$\, 2^{x}\, \cdot \, 2^{y}\, =\, 2^{x+y}\, $ 基于对数的乘法（次幂的加法）但是我们怎么样才能知道10001001是α的几次幂呢？这个问题被称为离散对数（离散对数在一些特殊情况下可以快速计算。然而，通常没有具非常效率的方法来计算它们。） 详细内容请看基于对数的乘除法 多项式维基百科中在介绍RS码前还介绍了伽罗瓦域的多项式，这可能会带来一点混淆，因为伽罗华域的元素本身也是多项式（译注：是系数仅为0、1的多项式） —-直接摘自翻译文档 详细介绍代码 参考资料参考网页 参考网页]]></content>
      <categories>
        <category>QR</category>
        <category>了解二维码</category>
        <category>了解二维码(三):BCH解码器</category>
      </categories>
      <tags>
        <tag>QR</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[了解二维码(二):二维码的编码方式]]></title>
    <url>%2F2019%2F01%2F21%2FQR_detail%2F</url>
    <content type="text"><![CDATA[了解二维码的编码方式 QR Code码(Quick Response Code)有自动纠错功能，具有超高速识读特点。用CCD二维条码识读设备，每秒可识读30个含有100个字符的QR Code码符号。参考博文链接 QR码支持的编码内容参考博文链接，参考博文链接：该链接中有很详细讲二维码的各部分和它的原理，也有很详细的根据一串字符串生成二维码的算法 数据编码针对不同的数据，QR码设计了 不同的数据编码编码方式 ，我们可以根据数据的种类选择合适的编码方式进行编码。 数字编码（Numeric） ：可编码0-9，10个数字，如果需要编码的数字的个数不是3的倍数，最后剩下的1或2位数会被转成4或7bits，其它的每3位数字会根据不同版本被编成 10，12，14bits（编成多长还得看二维码的尺寸） 字符编码（Alphanumeric) ：可编码0-9,大写的A-Z（没有小写）,以及9个其他的字符(space $ % * + – . / :)编码的过程是把字符两两分组，然后转成下表的45进制，然后转成11bits的二进制，如果最后有一个落单(说明该字符串长度为奇数)的，那就转成6bits的二进制。而编码模式和字符的个数需要根据不同的Version尺寸编成9, 11或13个二进制 8位字节模式(8-bit Byte)：可编码JIS X 0201的8位Latin/Kana字符集 除此之外，QR还提供了其他的编码方式，每一个编码方式都有其独有的id进行标识，这些标识会记录在数据区的前端，使得解码器可以根据二维码使用的编码方式对数据进行解码 QR码支持编码的内容包括纯数字、数字和字符混合编码、8位字节码和包含汉字在内的多字节字符。其中： 数字：每三个为一组压缩成10bit。 字母数字混合:每两个为一组，压缩成11bit。 8bit字节数据：无压缩直接保存。 多字节字符：每一个字符被压缩成13bit。 在QR的图像介绍中说过关于QR数据存储有关的知识，在QR中1码字对应8比特。以下是QR码中总比特的计算方法 补齐码补齐码不同版本和不同纠错级，所容纳的比特数也不同，不同版本和不同纠错级所容纳的比特数见附录四。而补齐码就是在我们确定好QR码的版本和纠错级后，判断数据编码的比特数在此版本和纠错级下能够容纳的数据编码比特数是否相等。不是的话，那么就补11101100 00010001进行填充，如果一次填充还不足的话，可循环再次填充。直到其与比特数相同 数据编码=编码模式+字符长度+编码的数据+结束码+凑8bits整+补齐码。 摘自简书(稍做修改，便于我理解) 纠错码纠错码的等级越高，纠错能力也会越高，这样就会需要更多的纠错码，就会导致能够存储的数据变少。纠错码一共有四个等级，L(7%) 01,M(15%) 00,Q(25%) 11,R(35%) 10 括号里的百分比是能够修正的字符比例 因为变脏，变破损的部位不一定只是码字部位，还有别的地方，所以，在QR码中，还是用相对于全部码字的比率来描述纠错率。 纠错级别的比率，是指全部码字与可以纠错的码字的比率。 纠错码可以纠正两种错误： （错误码位置已知）拒读错误：就是扫描二维码时候有的字符没扫到或者扫描到了却读取不出来，就需要纠错码上场了，这种错误需要一个纠错码 （错误位置未知）替代错误：就是有的字符输入错误，但是不知道是哪个字符，所以就需要纠错码的帮助，需要两个纠错码。 记笔记：虽然纠错码在数学上可能看起来令人生畏，但大多数数学运算都是高等级的（Galois Fields除外，但事实上对于任何程序员来说都是简单和通用的：它只是对整数模运算操作数）。 然而，纠错码背后的数学智慧的复杂性隐藏了非常直观的目标和机制。 让我们以一种我们可以“猜测”数据是否被破坏的方式构建数据，只需“修复”结构就可以了。在数学上，我们使用来自伽罗瓦域的多项式来实现这种结构。（get corrupted：被破坏） 纠错码的主要思路是，我们可以使用较小的一组精心挑选的单词，而不是使用整个单词词典，一个“简化的词典”，这样的每个单词都和别的单词都不一样。（我的理解是，这一组单词是没有重复的词汇，所以每个单词都是独一无二的），我们只需在我们的简化字典中查找 检测哪些单词被破坏（因为它们不在我们的简化字典中） 通过查找字典中最相似的单词来纠正损坏的单词。 这部分我的理解是可以把需要放进去的消息去掉重复的字符，做成一个简易词典，然后在一些词因为破损而没法顺利读取出来时候，就用这个简易词典里面的字符和这些词进行比对，其中差异最小的词就被自动认定为这个词破损前的样子 但是如果简化词典里面有this和that两个单词，但是被损坏只能读取出来的部分是th**(precisely:准确的；separability:分离性) 这个差异，或者更准确地说是我们字典的任何2个单词之间的不同字母的最小数量，被称为我们字典的最大汉明距离。 确保字典的任何2个单词在同一位置仅共享最少数量的字母称为最大可分离性。 最大可分离性：两个单词之间极少部分相同 比如： 请注意，如果词典中的每个单词与其他单词的差异至少为5个字符，因此距离为5.这允许在已知位置中最多4个错误，这些错误称为擦除或未知位置中的2个错误需要更正。【因为如果位置错误有五个的话，就会出现没法用简化词典比对出这个破损的词是什么】 8字符中6个字符的子集有28个[C(8,6)]，所以遍历28个6字符的子集，因为距离为5，所以只有一个能匹配（在被损坏的单词少于或者等于2的时候） 可以看到冗余在恢复丢失信息方面的优势：冗余字符可帮助您恢复原始数据。 前面的例子显示了粗略的纠错方案如何起作用。 Reed-Solomon的核心思想是类似的，将冗余数据附加到基于Galois Field数学的消息中。 原始纠错解码器类似于上面的错误示例，搜索对应于有效消息的接收消息的子集，并选择具有最多匹配的子集作为纠正消息。 这对于较大的消息是不实际的，因此开发了数学算法以在合理的时间内执行纠错。 格式信息掩码掩码过程是被用来避免可能会让扫描器混乱的标志特征出现（比如大区域的黑块，让扫描器无法识别其中内容），所以用掩码反转某些模块（让白色变成黑色，黑色变成白色），而那些特定功能的模块则单独存在，不受掩码的影响。 红色的区域编码了格式信息，并使用了一个固定的掩码模式 使用异或操作可以轻松应用（或者删除）掩码转换（很多编程语言里面用插入符号^表示）逆时针读取二维码中的左上角的定位器模式，我们能够得到下面的比特序列，白色表示0，黑色表示1。（校正图形盖住的部位不需要读取二进制数） 所以：Input：101101101001011Mask ：101010000010010output：000111101011001 格式信息格式信息有两个相同的副本，所以即使其中一份被损坏还是能够有机会识别出来的。第二份副本被分成两部分，放在另外两个定位器周围，并且都还是以逆时针方向读取。 格式信息的前两比特是用来给出用于消息数据的纠错码的纠错等级信息。 格式信息接下来的三位是选择要在数据区中使用的掩码模式，接下来的这张图把这些掩码模式列出来了，包括了根据位置算出的模块为黑色的数学公式（i和j分别是行号和列号，左上角以0开头）。 剩下的十位格式化信息用于对格式信息本身的错误校验。 （duplicate：更正） 从右下角开始读取数据位，并以Z字形图案向上移动两个右侧列。 前三个字节是01000000 11010010 01110101.接下来的两列是向下读取的，因此下一个字节是01000111.到达底部后，向上读取后面的两列。 以这种上下方式一直到符号的左侧（必要时跳过定位模式）。 这是用十六进制表示法表示出来的完整信息。 Message data bytes: 40 d2 75 47 76 17 32 06 27 26 96 c6 c6 96 70 ecError correction bytes: bc 2a 90 13 6b af ef fd 4b e0 解码最后的步骤是把解读信息比特，把它变成可读的信息。前四个比特指示信息应该怎么解码。QR码使用几种不同的编码模式，以至于不同种类的信息能够有效的被存储。（summarize：总结）在模式指示码之后的是长度字段，告诉解码器有多少字符被存储。这个字符的长度取决于指定的编码方案。 [8 bits per character==每个字符八位]上面的长度字段大小仅适用于较小的QR码 所以可以根据上图得出紧跟着0100后面的8个比特的字符串0000 1101是讲的是该存储信息的长度，表明有十三个字符，所以后面跟的00100111和01010100（分别是”‘“和”T”的ascii码）等等十三个字符。 在最后一个数据位之后是另一个4位模式指示符，它可以和第一个4位模式指示符不一样，从而允许在一个QR码中混合多个编码方案，如果没有其他数据了，用0000结尾（如果存储空间不够，可以省略这个标记） 为了使我们的QR码解码器可靠，我们需要能够纠正错误。 本文的下一部分将描述如何通过构造BCH解码器，更具体地说是Reed-Solomon解码器来纠正错误。 二维码之解码器]]></content>
      <categories>
        <category>QR</category>
        <category>了解二维码</category>
        <category>了解二维码(二):二维码的编码方式</category>
      </categories>
      <tags>
        <tag>QR</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[了解二维码(一):二维码的组成部分解释与介绍]]></title>
    <url>%2F2019%2F01%2F21%2FQR_infor%2F</url>
    <content type="text"><![CDATA[QR图形介绍 二维码一共有40个尺寸。官方叫版本Version。Version 1是21 x 21的矩阵，Version 2是 25 x 25的矩阵，Version 3是29的尺寸，每增加一个version，就会增加4的尺寸，公式是： (V-1)x4 + 21（V是版本号） 最高Version 40，(40-1)*4+21 = 177，所以最高是177 x 177 的正方形。 功能图形起到定位的作用：参考博客链接，参考博客链接 位置探测图形：最大的正方形就是位置探测图形（由三个黑白相间的大正方形嵌套组成，分别位于二维码左上角、右上角、左下角，目的是为了确定二维码的大小和位置。）这个图形的大小是固定的，不会因为二维码的版本而改变。(它的旁边还有八个加七个的由白块组成的白边，为了更好的定位而存在的) 定位图形：连接着位置探测图形的有规律的黑白相间的那条线（由两条黑白相间的直线组成，便于确定二维码的角度，纠正扭曲。） 定位符是因为二维码有40个版本尺寸,当尺寸过大后需要有根标准线，不然扫描的时候可能会扫歪。 ，它的长度很容易计算出来，一共两条线，用二维码的长度减掉两个位置探测图形的长度就可以得出每条线的长度了。 校正图形：和位置探测图形比起来比较小，和定位图形的黑白相间的小正方形比起来要大的正方形（仅在版本2以上存在，由三个黑白相间的小正方形嵌套组成，便于确定中心，纠正扭曲。） 每个版本的存储数据容量不一样,版本越高就意味着数据容量越大，纠错能力越强 这个图形的大小是固定的，不会因为二维码的版本而改变。 Alignment Patterns(对齐模式)：也是用于定位，只有version2以上才有用。 数据区记录了具体的数据信息，纠错信息与版本信息： 数据和纠错码：把数据码和纠错码的各个8位一组的十进制数（codewords）交替放在一起（跟我的理解是一样的，把数据分组，然后每组数据后面跟一个纠错码），所以就算有图片在二维码中间，二维码还是能扫描出记录在里面的内容(记录了数据信息和相应的纠错码，纠错码的存在使得当二维码的数据出现允许范围内的错误时，也可以正确解码。) 存储容错级别L(7%),M(15%),Q(25%),R(35%) 版本信息：就是记录二维码的规格(仅在版本7以上存在，记录具体的版本信息。)需要预留两块3 x 6的区域存放一些版本信息 格式信息：记录使用的数据掩码和纠错等级，和额外的自身BCH容错码。一条格式信息有15个bit，还有一条格式信息是这条信息的副本，为了防止格式信息被破坏。 Dark Module：这是二维码的标志，每个二维码都有。 此外二维码的外围还留有一圈空白区，主要是为了便于识别而存在。其中在位置探测图形周围有一圈白边（一个单位宽），这是分隔符，位于每个定位标识和编码区域之间用于区分。 纠错码和编码信息除了上述说的这些外，就还只有纠错码和编码了。 那么，QR是怎么对数据码加上纠错码的？首先，我们需要对数据码进行分组，也就是分成不同的Block，然后对各个Block进行纠错编码。 Number of Error Code Correction Blocks ：需要分多少个块。 Error Correction Code Per Blocks：每一个块中的code个数，所谓的code的个数，也就是有多少个8bits的字节。 参考博文 参考博文 QR码中，不同版本不同纠错级别都有相对应的数据存储容量，输入的字符越多，那相对应的QR码就要越大。 以下这个表是根据版本以及纠错级别对应的最佳的输入的数据的字符个数]]></content>
      <categories>
        <category>QR</category>
        <category>了解二维码</category>
        <category>了解二维码(一):二维码的组成部分解释与介绍</category>
      </categories>
      <tags>
        <tag>QR</tag>
      </tags>
  </entry>
</search>
